[{"title":"Linux学习-文件系统目录结构","date":"2021-01-27T15:42:00.000Z","path":"2021/01/27/Linux学习-文件系统目录结构/","text":"1.基本介绍linux的文件系统是采用级层式的树状目录结构，在此结构中的最上层是根目录“/”，然后在此目录下再创建其他的目录。 一句经典的话：在Linux世界里，一切皆文件。 2.目录结构详解","tags":[{"name":"linux","slug":"linux","permalink":"https://sunshine-zwq.gitee.io/tags/linux/"}]},{"title":"Linux学习-VMware安装CentOS6","date":"2021-01-27T02:17:38.000Z","path":"2021/01/27/Linux学习-VMware安装CentOS6/","text":"1.centos镜像下载地址https://archive.kernel.org/centos-vault/6.8/isos/x86_64/CentOS-6.8-x86_64-bin-DVD1.iso http://vault.centos.org/6.8/isos/x86_64/CentOS-6.8-x86_64-bin-DVD1to2.torrent 2.安装步骤（1）创建新的虚拟机，选择“典型（推荐）” （2）选择“稍后安装操作系统” （3）选择“Linux”和“CentOS 64位” （4）自定义虚拟机名称、选择存放的目录位置 （5）最大磁盘大小保持默认 20 GB，选择“将虚拟磁盘拆分成多个文件” （6）点击“自定义硬件”，进入硬件参数设置 （7）内存选择“2 GB” （8）处理器选择 2 * 2 （9）新 CD/DVD 选择“使用ISO映像文件”，点击浏览选择下载好的 CentOS-6.8-x86_64-bin-DVD1.iso 文件 （10）网络适配器，选择“NAT 模式” 网络连接模式的区别： 桥连接：虚拟机可以和其他的系统通信，但可能会造成 ip 冲突 NAT：网络地址转换方式，虚拟机可以访问外网，不会造成 ip 冲突 主机模式：虚拟机是一个独立的主机，不能访问外网 （11）其他保持默认配置，点击“关闭”回到之前页面，点击“完成” （12）点击“开启此虚拟机” （13）选择第一个按回车开始安装配置 （14）是否对CD媒体进行测试，直接跳过“Skip” （15）点击“Next” （16）选择“中文（简体）” （17）选择语言键盘“美国英语式” （18）选择“基本存储设备” （19）选择“是，忽略所有数据” （20）自定义计算机命名 （21）选择时区“亚洲/上海” （22）设置 root 用户的密码 （23）选择“创建自定义布局” （24）创建分区 （25）/boot分区，200MB （26）swap分区，2048MB （27）/分区，使用全部可用空间 （28）分区设置完成，下一步 （29）选择“格式化” （30）选择“将修改写入磁盘” （31）直接下一步 （32）选择“现在自定义”，下一步 （33）Web服务、可扩展文件系统支持，对应右边全部不勾选 （34）基本系统，只勾选“兼容程序库”和“基本” （35）应用程序，只勾选“互联网浏览器” （36）开发、弹性存储、数据库、服务器，对应右边全部不勾选 （37）桌面，除了KDE桌面，其他全部勾选 （38）系统管理、虚拟化、负载平衡器、高可用性，对应右边全部不勾选 （39）语言支持，勾选“中文支持” （40）完成配置，开始安装CentOS （41）等待安装完成，大概需要20分钟 （42）安装完成，点击“重新引导” （43）点击“前进” （44）选择同意 （45）不创建用户，直接点“前进”跳过 （46）日期和时间 （47）取消勾选“启用Kdump”，点击“完成”，弹出框点击“是” （48）系统重启，重启完成后，用 root 用户登录 （49）至此，centos 安装完成。 3.连接网络上述 centos 安装完成后，还不能联网。想要联网，点击右上角的如图图标，选择“System eth0”即可正常联网。 上述做法，需要在每次系统启动后，都点击设置一下，如果希望自动联网，可进行如下设置。 系统 -&gt; 首选项 -&gt; 网络连接 选择System eth0，点击“编辑” 勾选“自动连接”，IPv4 设置选择“自动”，点击“应用”即可，以后系统开机之后就会自动联网。 4.安装vmtoolsvmtools 的作用：可以直接复制粘贴命令在母机(windows)和虚拟机(linux)之间。 安装步骤： （1）点击 VMware 的“虚拟机”，然后点击“安装 VMware Tools” （2）这个时候虚拟机底部会出现如图黄色条，点击一下即弹出 VMware Tools 文件夹，右键复制 VMwareTools-10.1.6-5214329.tar.gz （3）在文件系统中打开 /opt 目录，右键点击“粘贴”把复制的文件粘贴进来 （4）桌面右键，“在终端中打开”，进入 /opt 目录，然后解压文件，命令如下 12cd /opttar -zxvf VMwareTools-10.1.6-5214329.tar.gz （5）解压出来的目录名称是 vmware-tools-distrib，进入这个目录，然后执行目录下的 vmware-install.pl 12cd vmware-tools-distrib/./vmware-install.pl （6）之后一路按回车使用默认配置即可，直到安装完成 （7）安装完成后，要 reboot 重启才会生效。重启后就可以相互复制命令了。","tags":[{"name":"linux","slug":"linux","permalink":"https://sunshine-zwq.gitee.io/tags/linux/"}]},{"title":"Dubbo入门","date":"2021-01-07T09:21:42.000Z","path":"2021/01/07/Dubbo入门/","text":"1.分布式基础理论1.1 什么是分布式系统《分布式系统原理与范型》定义：“分布式系统是若干独立计算机的集合，这些计算机对于用户来说就像单个相关系统”。 分布式系统（distributed system）是建立在网络之上的软件系统。 随着互联网的发展，网站应用的规模不断扩大，常规的垂直应用架构已无法应对，分布式服务架构以及流动计算架构势在必行，亟需一个治理系统确保架构有条不紊的演进。 1.2 发展演变 单一架构应用 当网站流量很小时，只需一个应用，将所有功能都部署在一起，以减少部署节点和成本。此时，用于简化增删改查工作量的数据访问框架(ORM)是关键。 适用于小型网站，小型管理系统，将所有功能都部署到一个功能里，简单易用。 缺点： 性能扩展比较难 协同开发问题 不利于升级维护 垂直应用架构 当访问量逐渐增大，单一应用增加机器带来的加速度越来越小，将应用拆成互不相干的几个应用，以提升效率。此时，用于加速前端页面开发的Web框架(MVC)是关键。 通过切分业务来实现各个模块独立部署，降低了维护和部署的难度，团队各司其职更易管理，性能扩展也更方便，更有针对性。 缺点： 公用模块无法重复利用，开发性的浪费 分布式服务架构 当垂直应用越来越多，应用之间交互不可避免，将核心业务抽取出来，作为独立的服务，逐渐形成稳定的服务中心，使前端应用能更快速的响应多变的市场需求。此时，用于提高业务复用及整合的分布式服务框架(RPC)是关键。 流动计算架构 当服务越来越多，容量的评估，小服务资源的浪费等问题逐渐显现，此时需增加一个调度中心基于访问压力实时管理集群容量，提高集群利用率。此时，用于提高机器利用率的资源调度和治理中心(SOA)[ Service Oriented Architecture]是关键。 1.3 RPC什么叫 RPC ? RPC【Remote Procedure Call】是指远程过程调用，是一种进程间通信方式，他是一种技术的思想，而不是规范。它允许程序调用另一个地址空间（通常是共享网络的另一台机器上）的过程或函数，而不用程序员显式编码这个远程调用的细节。即程序员无论是调用本地的还是远程的函数，本质上编写的调用代码基本相同。 RPC 基本原理 RPC两个核心模块：通讯，序列化。 2.Dubbo 核心概念2.1 简介Apache Dubbo (incubating) |ˈdʌbəʊ| 是一款高性能、轻量级的开源Java RPC框架，它提供了三大核心能力：面向接口的远程方法调用，智能容错和负载均衡，以及服务自动注册和发现。 官网：http://dubbo.apache.org/ 2.2 基本概念 服务提供者（Provider）：暴露服务的服务提供方，服务提供者在启动时，向注册中心注册自己提供的服务。 服务消费者（Consumer）: 调用远程服务的服务消费方，服务消费者在启动时，向注册中心订阅自己所需的服务，服务消费者，从提供者地址列表中，基于软负载均衡算法，选一台提供者进行调用，如果调用失败，再选另一台调用。 注册中心（Registry）：注册中心返回服务提供者地址列表给消费者，如果有变更，注册中心将基于长连接推送变更数据给消费者。 监控中心（Monitor）：服务消费者和提供者，在内存中累计调用次数和调用时间，定时每分钟发送一次统计数据到监控中心。 Ø 调用关系说明 服务容器负责启动、加载、运行服务提供者。 服务提供者在启动时，向注册中心注册自己提供的服务。 服务消费者在启动时，向注册中心订阅自己所需的服务。 注册中心返回服务提供者地址列表给消费者，如果有变更，注册中心将基于长连接推送变更数据给消费者。 服务消费者，从提供者地址列表中，基于软负载均衡算法，选一台提供者进行调用，如果调用失败，再选另一台调用。 服务消费者和提供者，在内存中累计调用次数和调用时间，定时每分钟发送一次统计数据到监控中心。","tags":[{"name":"Dubbo","slug":"Dubbo","permalink":"https://sunshine-zwq.gitee.io/tags/Dubbo/"}]},{"title":"jvm高级-常见问题","date":"2021-01-01T07:40:10.000Z","path":"2021/01/01/jvm高级-常见问题/","text":"1.GC Roots理解 面试题：JVM 垃圾回收的时候如何确定垃圾？是否知道什么是 GC Roots (1).什么是垃圾？ 简单的来说就是内存中已经不再使用到的空间就是垃圾。 (2).要进行垃圾回收，如何判断一个对象是否可以被回收？ ①引用计数法 ②枚举根节点做可达性分析（根搜索路径） 为了解决引用计数法的循环引用问题，Java 使用了可达性分析的方法。 所谓的“GC Roots”或者说 tracing GC 的“根集合”就是一组必须活跃的引用。 基本思路就是通过一系列名为“GC Roots”的对象作为起始点，开始向下搜索，如果一个对象到 GC Roots 没有任何引用链相连时，则说明此对象不可用。也即给定一个集合的引用作为根出发，通过引用关系遍历对象图，能被遍历到的（可到达的）对象就被判定为存活；没有被遍历到的就自然被判定为死亡。 Java 中可以作为 GC Roots 的对象： 虚拟机栈（栈帧中的局部变量区，也叫局部变量表）中引用的对象 方法区中的类静态属性引用的对象 方法区中常量引用的对象 本地方法栈 JNI（Native方法）引用的对象 2.JVM参数配置 面试题：你说你做过 JVM 调优和参数配置，请问如何盘点查看 JVM 系统默认值 2.1 JVM的参数类型(1).标配参数（从Java1.0开始就有） -version -help java -showversion (2).X参数（了解即可） -Xint：解释执行 -Xcomp：第一次使用就编译成本地代码 -Xmixed：混合模式 (3).XX参数 Boolean 类型 用法：-XX:+属性值 或者 -XX:-属性值。+ 表示开启，- 表示关闭 场景 是否打印 GC 收集细节：-XX:-PrintGCDetails 或 -XX:+PrintGCDetails 是否使用串行垃圾回收器：-XX:-UseSerialGC 或 -XX:+UseSerialGC KV 设值类型 用法：-XX:属性key=属性值value 场景 设置JVM元空间大小：-XX:MetaspaceSize=128m 经历多少次GC晋升到老年代中的最大年龄：-XX:MaxTenuringThreshold=15 两个经典参数的坑题 Q：两个经典参数 -Xms 和 -Xmx 是属于什么类型参数？ A：属于KV键值对类型的缩写形式： -Xms 等价于 -XX:InitialHeapSize， -Xmx 等价于 -XX:MapHeapSize 2.2 查看当前运行程序的配置①命令 jps -l 获取所有java进程的pid ②命令 jinfo -flag 参数名 pid 获取参数的当前值 查看所有的参数配置：jinfo -flags pid 其中，Non-default VM flags 是非默认的 JVM 参数，Command line 是命令行里指定的参数。 2.3 查看JVM默认值(1).-XX:+PrintFlagsInitial：主要查看初始默认值，能够在Java程序未运行时查看 1java -XX:+PrintFlagsInitial (2).-XX:+PrintFlagsFinal：主要查看修改更新的参数值 1java -XX:+PrintFlagsFinal -version 其中，:= 代表被修改过后的值 PrintFlagsFinal举例，运行java命令的同时打印出参数： (3).-XX:+PrintCommandLineFlags：打印命令行参数 1java -XX:+PrintCommandLineFlags -version 3.常见JVM参数 面试题：你平常工作用过的 JVM 常用基本配置参数有哪些？ -Xms：初始大小内存，默认为物理内存1/64，等价于：-XX:InitialHeapSize -Xmx：最大分配内存，默认为物理内存1/4，等价于：-XX:MaxHeapSize -Xss：设置单个线程栈的大小，一般默认为512k-1024k（依赖平台），但是JVM该参数默认为0，代表的是使用默认值，而不是说单个线程的大小为0，等价于：-XX:ThreadStackSize -Xmn：设置年轻代大小，一般不调节该参数 -XX:MetaspaceSize：设置元空间大小。元空间并不在虚拟机中，而是使用本地内存。默认情况下，元空间的大小仅受本地内存限制 -XX:+PrintGCDetails：输出详细GC收集日志信息 -XX:SurvivorRatio：设置新生代中Eden和s0/s1空间的比例，默认是-XX:SurivivorRatio=8，即Eden:s0:s1=8:1:1， -XX:SurvivorRatio=4 -&gt; Eden:s0:s1=4:1:1 -XX:NewRatio：配置年轻代和老年代在堆结构中的占比，默认是-XX:NewRatio=2，即新生代占1，老年代占2， -XX:NewRatio=4 -&gt; 新生代占1，老年代占4，NewRatio所设置的数值为老年代占的比例，新生代始终为1 -XX:MaxTenuringThreshold：设置垃圾的最大年龄，默认值为15。如果设置为0的话，则年轻代对象不经过Survivor区，直接进入年老代。 典型设置案例： 12-Xms128m -Xmx4096m -Xss1024k -XX:MetaspaceSize=512m -XX:+PrintCommandLineFlags-XX:+PrintGCDetails -XX:+UseSerialGC 4.Java四大引用 面试题：强引用、软引用、弱引用、虚引用分别是什么？ 详见链接：Java中的强引用、软引用、弱引用、虚引用 5.OOM 面试题：请谈谈你对 OOM 的认识 5.1 Java异常和错误的继承体系 5.2 常见Error(1) java.lang.StackOverflowError 栈溢出异常，通常发生在递归调用且未添加终止条件时。使用 -Xss 参数可以更改栈的大小。 1234567891011public class StackOverflowErrorDemo &#123; public static void main(String[] args) &#123; stackOverflowError(); &#125; private static void stackOverflowError() &#123; stackOverflowError();// Exception in thread \"main\" java.lang.StackOverflowError &#125;&#125; (2) java.lang.OutOfMemoryError: Java heap space 当new大对象或者不断new新对象，导致new出来的内存超过了heap的大小，会导致OOM: java heap space异常 123456789101112/** * 演示OOM：java heap size * VM -Xms5m -Xmx5m -XX:+PrintGCDetails * * @author sherman */public class JavaHeapSpace &#123; public static void main(String[] args) &#123; // Exception in thread \"main\" java.lang.OutOfMemoryError: Java heap space byte[] bytes = new byte[80 * 1024 * 1024]; &#125;&#125; (3) java.lang.OutOfMemoryError: GC overhead limit exceeded GC回收时间过长，过长的定义：超过98%的时间用来做GC并且回收了不到2%的堆内存，连续多次GC仍然出现这种情况时，才会抛出该异常。 如果多次出现GC回收时间过长情况，但是并不抛出异常则会出现：GC清理的内存很快又会被再次填满，迫使再次GC，形成恶性循环，CPU使用率一直在100%，而GC却没有任何效果。 1234567891011121314151617181920212223/** * 演示GC overhead limit exceeded异常 * * -Xms10m -Xmx10m -XX:+PrintGCDetails -XX:MaxDirectMemorySize=5m * * 注意上面Xms和Xmx值不能太小，否则还没到达GC limit的限制就直接溢出了，抛出java heap space异常 * * @author sherman */public class GCOverLimit &#123; public static void main(String[] args) &#123; int i = 0; List&lt;String&gt; lists = new ArrayList&lt;&gt;(); try &#123; while (true) &#123; // Exception in thread \"main\" java.lang.OutOfMemoryError: GC overhead limit exceeded lists.add(String.valueOf(i++).intern()); &#125; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; &#125;&#125; (4) java.lang.OutOfMemoryError: Direct buffer memory 在 NIO 程序中，经常需要使用 ByteBuffer 来读取或者写入数据，这是一种基于通道 (Channel) 和缓冲区 (Buffer) 的 IO 方式。它可以使用Native函数库直接分配堆外内存，然后通过一个存储在 Java 堆里面的 DirectByteBuffer 对象作为这块内存引用进行操作。这样能够在一些场景中显著提高性能，因为可以避免在 Java 堆和 Native 堆中来回复制数据： ByteBuffer.allocate(capacity)：第一种方式是分配 JVM 堆内存，属于 GC 管辖范围，由于需要拷贝所以速度较慢； ByteBuffer.allocateDirect(capacity)：这种方式是分配 OS 本地内存，不属于 GC 管辖范围，由于不需要内存拷贝所以速度相对较快； 但是如果不断分配本地内存，堆内存很少使用，那么 JVM 就不需要执行 GC，DirectBuffer 对象们就不会被收，这时候堆内存充足，但是本地内存可能已经使用完毕，再次尝试分配本地内存就会出现OOM，程序直接崩溃： 123456789101112131415/** * 演示Direct Buffer Memory错误 * * -Xms5m -Xmx5m -XX:+PrintGCDetails -XX:MaxDirectMemorySize=5m * * @author sherman */public class DirectBufferMemory &#123; public static void main(String[] args) &#123; // 默认应该是1/4系统内存 System.out.println(\"配置的堆外内存为：\" + (sun.misc.VM.maxDirectMemory()) / (double) 1024 / 1024 + \"MB\"); // Exception in thread \"main\" java.lang.OutOfMemoryError: Direct buffer memory ByteBuffer.allocateDirect(6 * 1024 * 1024); &#125;&#125; (5) java.lang.OutOfMemoryError: unable to create new native thread 高并发请求服务器时，经常出现如下异常：java.lang.OutOfMemoryError：unable to create new native thread，准确的讲该 native thread 异常与对应的平台有关。 导致原因： 应用创建了太多的线程，超过了系统承载极限 对应的服务器不允许你的进程创建过多的线程，linux默认允许单个进程可以创建线程数1024个 解决方案： 想办法降低进程创建线程的数量，分析程序是否真的需要创建那么多的线程； 如果应用真的需要创建很多线程，需要修改linux默认配置，扩大linux默认限制； 123456789101112131415161718192021/** * 演示OOM：unable to create new native thread * 注意：在Windows上运行这个程序容易出现假死现象！！！ * * @author sherman */public class UnableCreateNewNativeThread &#123; public static void main(String[] args) &#123; for (int i = 0; ; ++i) &#123; System.out.println(\"+++++++\" + i + \"+++++++\"); // Exception in thread \"main\" java.lang.OutOfMemoryError: unable to create new native thread new Thread(() -&gt; &#123; try &#123; Thread.sleep(Integer.MAX_VALUE); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;).start(); &#125; &#125;&#125; 服务器级别调参调优（设置最大线程数）： 123# vim /etc/security/limits.d/90-nproc.conf:* soft nproc 1024root soft nproc unlimited 可以看出，除了root，其他用户都限制在1024个。 假如我们想让 z3 这个用户的可生成线程数多一些，可以配置如下： (6) java.lang.OutOfMemoryError: Metaspace 用 java -XX:+PrintFlagsInitial 命令查看本机的初始化参数，-XX:MetaspaceSize 默认为 21810376B（大约20.8M） 1234D:\\develop\\idea\\IdeaProjects\\test-server&gt;java -XX:+PrintFlagsInitial | findstr -i metaspacesize uintx InitialBootClassLoaderMetaspaceSize = 4194304 &#123;product&#125; uintx MaxMetaspaceSize = 4294967295 &#123;product&#125; uintx MetaspaceSize = 21810376 &#123;pd product&#125; Metaspace 是 Java8 及其以后版本中使用的，用来代替永久代。Metaspace 是方法区在 HotSpot 中的实现，它与永久带最大的区别是：Metaspace 并不在 JVM 内存中而是直接使用本地内存。也就是说在 Java8 中，class metadata (the virtual machines internal presentation of Java class)，被存储在叫做 Metaspace 的 Native Memory 中。 永久代（Metaspace）存储的信息： JVM加载的类信息 常量池 静态变量 即时编译后的代码 因为 Metaspace 中存储了类信息，所以如果不断产生新的类，就会不断向 Metaspace 中写入数据，就有可能导致 Metaspace 区域溢出。 123456789101112131415161718192021222324252627282930/** * 演示MetaspaceSize错误 * * -XX:MetaspaceSize=8m -XX:MaxMetaspaceSize=8m */public class MetaspaceOOMTest &#123; static class OOMTest&#123;&#125; public static void main(String[] args) &#123; int i = 0;// 模拟计数多少次以后发生异常 try&#123; while (true)&#123; i++; Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(OOMTest.class); enhancer.setUseCache(false); enhancer.setCallback(new MethodInterceptor() &#123; @Override public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable &#123; return methodProxy.invokeSuper(o, args); &#125; &#125;); enhancer.create(); &#125; &#125;catch (Throwable e)&#123; System.out.println(\"***********多少次后发生了异常：\" + i); e.printStackTrace(); &#125; &#125;&#125; 运行结果： 12345678***********多少次后发生了异常：326java.lang.OutOfMemoryError: Metaspace at org.springframework.cglib.core.AbstractClassGenerator.generate(AbstractClassGenerator.java:345) at org.springframework.cglib.proxy.Enhancer.generate(Enhancer.java:492) at org.springframework.cglib.core.AbstractClassGenerator$ClassLoaderData.get(AbstractClassGenerator.java:114) at org.springframework.cglib.core.AbstractClassGenerator.create(AbstractClassGenerator.java:291) at org.springframework.cglib.proxy.Enhancer.createHelper(Enhancer.java:480) at org.springframework.cglib.proxy.Enhancer.create(Enhancer.java:305) 6.垃圾收集器 面试题： (1).GC垃圾回收算法和垃圾收集器的关系？分别是什么请你谈谈 (2).怎么查看服务器默认的垃圾收集器是哪个？生产上如何配置垃圾收集器的？谈谈你对垃圾收集器的理解 GC算法（引用计数、复制、标记清除、标记整理）是内存回收的方法论，垃圾收集器是算法的落地实现。目前没有完美的的垃圾回收器，更没有万能的垃圾收集器，只能根据具体的应用选择合适的收集器，进行分代收集。 6.1 四种主要垃圾收集器 串行垃圾回收器(Serial)：为单线程环境设置并且只使用一个线程进行垃圾回收，会暂停所有的用户线程，不适合服务器环境 并行垃圾回收器(Parallel)：Serial垃圾回收器的多线程版本，会开启多个线程进行垃圾回收，仍然会暂停所有的用户线程，速度较快，适用于科学计算或者大数据处理等弱交互场景 并发垃圾回收器(CMS)：用户线程和垃圾回收线程同时执行（不一定是并行，可能是交替执行），不需要暂停用户线程，互联网公司多用它，适用于对响应时间要求严格的应用 G1垃圾回收器：将堆内存分割成不同的区域（Region）然后并发对其进行垃圾回收，并不存在明显的新生代和老年代 Serial和Parallel垃圾回收器都会产生STW(Stop The World)问题，CMS并不会产生该问题，但是CMS的GC过程可能更加复杂，导致抢占应用程序的CPU资源。 6.2 查看默认的垃圾收集器1java -XX:+PrintCommandLineFlags -version JVM 默认的垃圾回收器（7种，有一种已经废弃）： UseSerialGC &lt;——–&gt; UseSerialOldGC UseParallelGC &lt;——–&gt; UseParallelOldGC UseParNewGC &lt;——–&gt; UseConcMarkSweepGC UseG1GC 6.3 七大垃圾收集器 新生代收集器：Serial、ParNew、Parallel Scavenge 老年代收集器：Serial Old、Parallel Old、CMS 整堆收集器：G1 JVM垃圾回收器日志中参数说明: DefNew: Default New Generation Tenured: Old ParNew: Parallel New Generation PSYoungGen: Parallel Scavenge ParOldGen: Parallel Old Generation JVM 中 Server / Client 模式： 32 位 Windows 操作系统，无论硬件如何默认使用 Client 的 JVM 模式； 32 位其它操作系统，2G 内存同时拥有 2 个 cpu 及以上的硬件资源使用的是 Server 模式，否则 Client 模式； 64 位操作系统只有 Server 模式 串行收集器 Serial/Serial Copying一个单线程的收集器，在进行垃圾收集时，必须暂停其他所有的工作线程(STW)直到它收集结束。 串行收集器是最古老、最稳定以及效率高的收集器，垃圾收集过程中可能会产生较长的停顿，对于限定单个 CPU 的环境来说，没有线程交互的开销可以获得最高的单线程垃圾回收效率。因此，Serial 垃圾收集器依然是 JVM 运行在 Client 模式下默认的新生代垃圾收集器。 对应 JVM 参数：-XX:+UseSerialGC 说明：开启 SerialGC 后，默认使用的配套 GC 是：Serial(Young区使用) + Serial Old(Old区使用)的收集器组合，表示新生代和老年代都会使用串行垃圾回收器，新生代使用复制算法，老年代使用标记-整理算法。 配置运行说明：DefNew + Tenured 测试代码： 1234567891011public class GCDemo &#123; public static void main(String[] args) &#123; String str = \"Atlantis\"; while (true) &#123; // 每执行下面语句，会在堆里创建新的对象 str += str + new Random().nextInt(88888888) + new Random().nextInt(999999999); &#125; &#125;&#125; 测试 JVM 参数配置： 1-Xms10m -Xmx10m -XX:+PrintGCDetails -XX:+UseSerialGC 运行结果： 并行收集器 ParNew使用多线程进行垃圾回收，是 Serial 收集器新生代的并行多线程版本，在进行垃圾回收时仍然会出现 STW 问题直至它收集结束。它是很多 JVM 运行在 Server 模式下的新生代默认垃圾收集器。 对应 JVM 参数： -XX:+UseParNewGC 说明：开启ParNewGC后，默认使用的配套GC是：ParNew(Young区使用) + Serial Old(Old区使用)的垃圾收集器组合，相对于 Serial来说只会影响新生代，不影响老年代。新生代使用复制算法，老年代使用标记-整理算法。但是，ParNew + Serial Old 在 Java8 已经不被推荐使用：Using the ParNew young collector with Serial old collector is deprecated and will likely be removed in future release。更推荐的组合是：ParNew + CMS 备注：-XX:ParallelGCThreads 参数可以限制线程的数量，默认开启和 CPU 数目相同的线程数 配置运行说明：ParNew + Tenured 测试 JVM 参数配置： 1-Xms10m -Xmx10m -XX:+PrintGCDetails -XX:+UseParNewGC 运行结果： 并行收集器 Parallel ScavengeParallel Scavenge 收集器类似于 ParNew，也是一个新生代并行垃圾收集器，使用复制算法，俗称吞吐量优先收集器。相对于 ParNew 收集器而言，Parallel Scavenge 是在新生代和老年代都是并行多线程处理的垃圾回收器，它是 Java8 默认的垃圾回收器。 它重点关注的是：可控制的吞吐量(吞吐量 = 运行用户代码时间 / (运行用户代码时间 + 垃圾收集时间))。高吞吐量意味着高效利用 CPU 的时间，它多用于在后台运算而不需要太多的交互任务。 自适应调节策略也是 Parallel Scavenge 收集器与 ParNew 收集器的一个重要区别。自适应策略：JVM 会根据当前系统的运行情况收集性能监控信息，动态调节这些参数以提供最合适的停顿时间(-XX:MaxPauseGCMillis)或最大吞吐量。 对应 JVM 参数：-XX:+UseParallelGC 或 -XX:+UseParallelOldGC 可以相互激活； 说明：开启该参数后，新生代使用复制算法，老年代使用标记-整理算法； 备注：-XX:ParallelGCThreads=N 表示开启多少个 GC 线程，如果CPU核数&gt;8, N = 5/8，否则N=CPU核数； 配置运行说明：PSYoungGen + ParOldGen 测试 JVM 参数配置： 123-Xms10m -Xmx10m -XX:+PrintGCDetails -XX:+UseParallelGC或-Xms10m -Xmx10m -XX:+PrintGCDetails -XX:+UseParallelOldGC 运行结果： 串行收集器 Serial OldSerial Old 收集器是 Serial 收集器的老年代版本，同样是单线程收集器，使用标记-整理算法，该收集器是 Client 模式下 JVM 默认的老年代垃圾收集器。 在Server模式下，Serial Old收集器的主要作用有： 在 JDK1.6 之前，在老年代和新生代 Parallel Scavenge 配合使用； 作为 ParNew + CMS 的后备收集器； 注意：在 Java8 中不能使用 JVM 参数 -XX:+UseSerialOldGC 来开启 Serial Old 收集器（已被优化掉）。 并行收集器 Parallel OldParallel Old 收集器是 Parallel Scavenge(PS) 的老年代版本，使用多线程的标记-整理算法，Parallel Old 是 JDK1.6 才开始提供的。在 JDK1.6 之前，新生代使用 PS 收集器只能在老年代配合 Serial Old 收集器，只能保证在新生代的吞吐量有限，无法保证整体的吞吐量。 Parallel Old 正是为了在老年代同样提供吞吐量优先的垃圾回收器，如果系统对吞吐量要求较高，在 JDK1.8 及以后版本都是使用 Parallel Scavenge + Parallel Old 垃圾收集器组合。 对应 JVM 参数：-XX:+UseParallelOldGC 和 -XX:+UseParallelGC 相互激活 并发标记清除收集器 CMSCMS 收集器是标记-清除 GC 算法的落地实现，是一种以获得最短停顿时间为目标的收集器，适合应用在互联网站或者 B/S 系统的服务器上，这类应用尤其重视服务器的响应速度，希望系统停顿时间最短，CMS 非常适合堆内存大，CPU 核数多的服务器应用，也是 G1 收集器出现之前大型应用的首选收集器。 对应 JVM 参数：-XX:+UseConcMarkSweepGC，同时会自动开启 -XX:+UseParallelGC，开启该参数后，会自动使用: ParNew(Young区使用) + CMS(Old区使用) + Serial Old的收集器组合，Serial Old 将作为 CMS 出错后的备用收集器； 收集过程： 初始标记(CMS initial mark)：只是标记一下 GC Roots 能够直接关联的对象，速度很快，但是存在STW； 并发标记(CMS concurrent mark)：进行 GC Roots 跟踪过程，和用户线程一起工作，没有 STW 过程，主要是标记过程，会标记全部对象； 重新标记(CMS remark)：为了修正在并发标记期间，因为用户程序继续运行而导致标记产生变动的那一部分对象的标记记录，仍然存在 STW 过程。因为并发标记时，用户线程亦然可以运行，因此在正式清理之前，再一次修正工作。 并发清除(CMS concurrent sweep)：清除 GC Roots 不可达对象，和用户线程一起工作，不需要暂停工作线程，根据标记结果，直接清除对象。由于耗时最长的并发标记和并发清除过程中，GC 线程和用户线程可以同时工作，因此总体上来看 CMS 收集器的内存回收和用户线程是一起并发地执行。 优缺点： （优）并发收集停顿低，它本身就是以最短停顿时间为目标的垃圾回收器； （缺）并发执行对 CPU 资源压力较大：由于并发执行，CMS 在垃圾回收时会与应用线程同时增加对堆内存的占用，也就是说，CMS 必须要在老年代堆内存用尽之前完成垃圾回收，否则 CMS 回收失败，将会触发担保机制。此时 Serial Old 收集器会作为后备收集器，以 STW 的方式进行一次 GC，造成较大的停顿时间； （缺）CMS 收集器是标记-清除算法的落地实现，就标记-清除算法而言本身存在内存碎片的问题，老年代的空间会随着应用时长被逐步耗尽，最后不得不通过担保机制对堆内存进行一次压缩，CMS 提供了参数：-XX:CMSFullGCsBeforeCompaction(默认0, 表示每次都进行内存整理)来指定多少次 CMS 收集之后，再进行一次压缩的 Full GC。 配置运行说明：ParNew + CMS + Serial Old 测试 JVM 参数配置： 1-Xms10m -Xmx10m -XX:+PrintGCDetails -XX:+UseConcMarkSweepGC 运行结果： G1 垃圾收集器以前收集器的特点： 年轻代和老年代是各自独立且连续的内存块 年轻代收集使用单 eden + S0 + S1 进行复制算法 老年代收集必须扫描整个老年代区域 都是以尽可能少而快速地执行 GC 为设计原则 G1 垃圾收集器简介： G1(Gabage-First) 收集器，是一款面向服务端应用的收集器，应用在多处理器和大容量内存环境中，在实现高吞吐量的同时，尽可能地满足垃圾收集暂停时间的要求。另外，它还具有以下特性： 像 CMS 收集器一样，能与应用程序线程并发执行 整理空闲空间更快 需要更多的时间来预测 GC 停顿时间 不希望牺牲大量的吞吐性能 不需要更大的Java Heap G1 收集器的设计目标是取代 CMS 收集器。它同 CMS 相比，在以下方面表现得更出色： G1 是一个有整理内存过程的垃圾收集器，不会产生很多内存碎片 G1 的 Stop The World(STW)更可控，G1在停顿时间上添加了预测机制，用户可以指定期望停顿时间 为了去除 CMS 的内存碎片问题，同时又保留 CMS 垃圾收集器低暂停时间的特点，Java7 发布了新的垃圾收集器 - G1 垃圾收集器，在 2012 年的 jdk1.7u4 可用。oracle 在 jdk9 中将 G1 变成默认的垃圾收集器以替代 CMS。 主要改变是，Eden、Survivor 和 Tenured 等内存区域不再是连续的了，而是变成了一个个大小一样的 region，每个 region 从 1M 到 32M 不等。一个 region 有可能是属于 Eden、Survivor 或者 Tenured 内存区域。 G1 垃圾收集器特点： G1 能充分利用多 CPU、多核环境硬件优势，尽量缩短STW。 G1 整体上采用标记-整理算法，局部是通过复制算法，不会产生内存碎片。 宏观上看 G1 之中不再区分年轻代和老年代。把内存划分为多个独立的子区域（Region），可以近似理解为一个围棋的棋盘。 G1 收集器里面将整个的内存区都混合在一起了，但其本身依然在小范围内要进行年轻代和老年代的区分，保留了新生代和老年代，但它们不再是物理隔离的，而是一部分 Region 的集合且不需要 Region 是连续的，也就是说依然会采用不同的 GC 方式来处理不同的区域。 G1 虽然也是分代收集器，但整个内存分区不存在物理上的年轻代和老年代的区别，也不需要完全独立的 survivor(to space)堆做复制准备。G1 只有逻辑上的分代概念，或者说每个分区都可能随 G1 的运行在不同代之间前后切换。 底层原理： 底层原理是 Region 区域化垃圾收集器：最大好处是化整为零，避免全内存扫描，只需要按照区域来进行扫描即可。 回收步骤： 4步过程： 常用配置参数： -XX:+UseG1GC -XX:G1HeapRegionSize=n：设置 G1 区域的大小。值是2的幂，范围是 1MB 到 32MB。目标是根据最小的 Java 堆大小划分出约 2048 个区域。 -XX:MaxGCPauseMillis=n：最大 GC 停顿时间，这是个软目标，JVM 将尽可能（但不保证）停顿小于这个时间。 -XX:InitiantingHeapOccupancyPercent=n：堆占用了多少的时候就触发 GC，默认为45 -XX:ConcGCThreads=n：并发 GC 使用的线程数 -XX:G1ReservePercent=n：设置作为空闲空间的预留内存百分比，以降低目标空间溢出的风险，默认值为 10% 和 CMS 相比的优势： G1 不会产生内存碎片 可以精确控制停顿。该收集器是把整个堆（新生代、老生代）划分为多个固定大小的区域，每次可以根据允许停顿的时间去收集垃圾最多的区域。 6.4 如何选择垃圾收集器 7.其他JVM 结合 SpringBoot 微服务优化： java -server jvm的各种参数 -jar jar/war包名字 例如： 1java -server -Xms1024m -Xmx1024m -XX:+UseG1GC -jar test-1.0-SNAPSHOT.jar","tags":[{"name":"java","slug":"java","permalink":"https://sunshine-zwq.gitee.io/tags/java/"},{"name":"面试","slug":"面试","permalink":"https://sunshine-zwq.gitee.io/tags/%E9%9D%A2%E8%AF%95/"},{"name":"jvm","slug":"jvm","permalink":"https://sunshine-zwq.gitee.io/tags/jvm/"}]},{"title":"Java中的强引用、软引用、弱引用、虚引用","date":"2020-12-30T06:37:38.000Z","path":"2020/12/30/Java中的强引用、软引用、弱引用、虚引用/","text":"Java提供了四种引用，分别是：强引用、软引用、弱引用、虚引用，它们的关系图为： 1.强引用（默认支持模式）当内存不足时，JVM 开始垃圾回收，对于强引用的对象，就算是出现了 OOM 也不会对该对象进行回收。 强引用是我们最常见的普通对象引用，只要还有强引用指向一个对象，就表明对象还“活着”，垃圾收集器不会碰这种对象。把一个对象赋给一个引用变量，这个引用变量就是一个强引用。当一个对象被强引用变量引用时，它处于可达状态，它是不可能被垃圾回收机制回收的，即使该对象以后永远都不会用到 JVM 也不会回收。因此强引用是造成 Java 内存泄漏的主要原因之一。 对于一个普通的对象，如果没有其他的引用关系，只要超过了引用的作用域或者显式地将相应（强）引用赋值为null，一般认为就是可以被垃圾收集的了（当然具体回收时机还是要看垃圾收集策略）。 1234567891011121314151617/** * 演示强引用 * * @author sherman */public class StrongReference &#123; public static void main(String[] args) &#123; Object obj1 = new Object();// 这样定义的默认就是强引用 Object obj2 = obj1;// obj2引用赋值 obj1 = null;// 置空 System.gc(); /** * obj2属于强引用，不会回收 */ System.out.println(obj2); &#125;&#125; 2.软引用软引用是一种相对强引用弱化了一些的引用，需要用 java.lang.ref.SoftReference 类来实现，可以让对象豁免一些垃圾收集。 对于只有软引用的对象来说， 当系统内存充足时，软引用不会回收； 当系统内存不足时，软引用会被回收，回收后内存仍然不足，就抛出异常； 软引用通常用在对内存敏感的程序中，例如高速缓存中就有用到软引用。内存够用的时候就保留，不够用就回收！ 12345678910111213141516171819202122232425/** * 演示软引用 * VM: -Xms5m -Xmx5m -XX:+PrintGCDetails * * @author sherman */public class SoftReferenceDemo &#123; public static void main(String[] args) &#123; Object obj1 = new Object(); SoftReference&lt;Object&gt; softReference = new SoftReference(obj1); System.out.println(obj1); System.out.println(softReference.get()); obj1 = null; try &#123; byte[] bytes = new byte[20 * 1024 * 1024]; &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; finally &#123; System.out.println(obj1); System.out.println(softReference.get()); &#125; &#125;&#125; 运行结果： 可以看出，在内存不够用时，软引用被回收了。 3.弱引用弱引用需要用 java.lang.ref.WeakReference 类来实现，它比软引用的生存期更短。 对于只有弱引用的对象来说，只要垃圾回收机制一运行，不管 JVM 的内存空间是否足够，都会回收该对象占用的内存。 12345678910111213141516171819202122/** * 演示弱引用 * * @author sherman */public class WeakReferenceDemo &#123; public static void main(String[] args) &#123; Object obj1 = new Object(); WeakReference&lt;Object&gt; wr = new WeakReference&lt;&gt;(obj1); System.out.println(obj1); System.out.println(wr.get()); obj1 = null; /** * 弱引用活不到下一次gc，因此即使内存充足，弱引用也会被回收 */ System.gc(); System.out.println(obj1); System.out.println(wr.get()); &#125;&#125; 运行结果： 1234java.lang.Object@506e1b77java.lang.Object@506e1b77nullnull 软引用和弱引用的适用场景： 有一个应用需要读取大量的本地图片： 如果每次读取图片都从硬盘读取则会严重影响性能 如果一次都加载到内存中有可能造成内存溢出 此时可以通过软引用或者弱引用来解决该问题。 设计思路：用一个HashMap来保存图片路径和相应图片对象关联的软引用之间的映射关系，当系统内存不足时，JVM 会自动回收这些缓存图片对象所占用的空间，从而有效地避免了OOM的问题。 Map&lt;String, SoftReference&gt; imgCache = new HashMap&lt;String, SoftReference(); WeakHashMap WeakHashMap 和 HashMap 一样也是一个散列表，但是它的键是“弱键”，其类型是 WeakReference，对于“弱键”，其对应的映射的存在并不会阻止垃圾回收器对该键的丢弃。 也就是说，该弱键是可被终止的。当某个键被终止时，其对应的键值对映射就会从散列表中移除。 1234567891011121314151617181920212223242526272829/** * @author sherman */public class WeakHashMapDemo &#123; public static void main(String[] args) &#123; Map&lt;Integer, Object&gt; weakHashMap = new WeakHashMap&lt;&gt;(); Map&lt;Integer, Object&gt; hashMap = new HashMap&lt;&gt;(); /** * 注意这里两个map不能共用一对key-value，会相互影响 */ Integer key1 = new Integer(250); String value1 = \"value1\"; Integer key2 = new Integer(250); String value2 = \"value2\"; weakHashMap.put(key1, value1); hashMap.put(key2, value2); System.out.println(\"weakHashMap: \" + weakHashMap); System.out.println(\"hashMap: \" + hashMap); key1 = null; key2 = null; System.gc(); System.out.println(\"==========================\"); System.out.println(\"weakHashMap: \" + weakHashMap); System.out.println(\"hashMap: \" + hashMap); &#125;&#125; 运行结果： 12345weakHashMap: &#123;250&#x3D;value1&#125;hashMap: &#123;250&#x3D;value2&#125;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;weakHashMap: &#123;&#125;hashMap: &#123;250&#x3D;value2&#125; 4.虚引用虚引用需要 java.lang.ref.PhantomReference 类来实现，如果一个对象仅持有虚引用，那么它和没有任何引用一样，调用 get() 方法总返回 null，在任何时候都可能被垃圾回收器回收，虚引用必须和引用队列(ReferenceQueue)联合使用： 作用：跟踪对象被垃圾回收的状态。当该对象被垃圾收集器回收的时候收到一个系统通知或者后续添加进一步处理，即当一个对象进入 finalization 阶段，可以被 gc 回收，用来实现比 finalization 更加灵活的机制； 具体流程：创建引用时候可以指定关联的队列，当GC释放对象的时候会将引用的对象添加到引用队列中，如果程序发现某个虚引用对象已经被加入到引用队列中，那么就可以在引用对象的内存回收之前采取必要的措施，这就相当于一种通知机制； 123456789101112131415161718192021222324252627282930/** * 演示PhantomReference * * @author sherman */public class PhantomReferenceDemo &#123; public static void main(String[] args) throws InterruptedException &#123; Object obj = new Object(); ReferenceQueue&lt;Object&gt; referenceQueue = new ReferenceQueue&lt;&gt;(); PhantomReference&lt;Object&gt; phantomReference = new PhantomReference&lt;&gt;(obj, referenceQueue); System.out.println(obj); /** * PhantomReference任何时候get都是null */ System.out.println(phantomReference.get()); System.out.println(referenceQueue.poll()); System.out.println(\"===============\"); /** * obj=null，gc之后，引用的对象会被添加到引用队列中， * 因此最后的poll方法能够获取到值 */ obj = null; System.gc(); Thread.sleep(100); System.out.println(obj); System.out.println(phantomReference.get()); System.out.println(referenceQueue.poll()); &#125;&#125; 运行结果： 1234567java.lang.Object@506e1b77nullnull&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;nullnulljava.lang.ref.PhantomReference@4fca772d 5.总结","tags":[{"name":"java","slug":"java","permalink":"https://sunshine-zwq.gitee.io/tags/java/"},{"name":"gc","slug":"gc","permalink":"https://sunshine-zwq.gitee.io/tags/gc/"}]},{"title":"JDK中bin目录下常用命令","date":"2020-12-29T02:09:10.000Z","path":"2020/12/29/JDK中bin目录下常用命令/","text":"java 用于启动一个java应用程序，这个java应用程序必须要有入口函数main方法。 用法：java [-options] class [args…] (执行类) 或 java [-options] -jar jarfile [args…] (执行 jar 文件) 选项： -D&lt;名称&gt;=&lt;值&gt;：设置系统属性 -version：输出产品版本并退出 -client 或 -server：设置虚拟机使用的运行模式 javac 用于java程序编译。 用法: javac &lt;options&gt; &lt;source files&gt; javap 反编译工具，也可以查看class文件中的信息。 用法: javap &lt;options&gt; &lt;classes&gt; 选项： -v -verbose：输出附加信息 -c：对代码进行反汇编 jinfo 用于打印特定JVM实例的配置信息。 用法: jinfo [option] pid jps 用于查看运行的JVM实例以及进程号。 用法：jps [ options ] [ hostid ] 选项： -l：查看运行的JVM的全限定名 jstack 用于打印指定进程的调用堆栈信息 用法：jstack [ option ] pid jvisualvm JDK提供的图形化jstat工具。可以监控本地的JVM实例，也可以通过JMX或RMI的方式监控远程的JVM实例。","tags":[{"name":"java","slug":"java","permalink":"https://sunshine-zwq.gitee.io/tags/java/"},{"name":"jdk","slug":"jdk","permalink":"https://sunshine-zwq.gitee.io/tags/jdk/"}]},{"title":"jvm基础-GC垃圾回收","date":"2020-12-26T06:37:08.000Z","path":"2020/12/26/jvm基础-GC垃圾回收/","text":"1.GC垃圾收集机制对于GC垃圾收集机制，我们需要记住以下几点： 次数上频繁收集Young区。 次数上较少收集Old区。 基本不动元空间。 JVM在进行GC时，并非每次都对上面三个内存区域一起回收的，大部分时候回收的都是指新生代。因此GC按照回收的区域又分了两种类型，一种是普通GC（minor GC），一种是全局GC（major GC or Full GC）。 Minor GC和Full GC的区别： （1）普通GC（minor GC）：只针对新生代区域的GC，指发生在新生代的垃圾收集动作，因为大多数Java对象存活率都不高，所以Minor GC非常频繁，一般回收速度也比较快。 （2）全局GC（major GC or Full GC）：指发生在老年代的垃圾收集动作，出现了Major GC，经常会伴随至少一次的Minor GC（但并不是绝对的）。Major GC的速度一般要比Minor GC慢上10倍以上。 2.GC日志信息详解通过 java 命令后添加参数-XX:+PrintGCDetails查看。 （1）YGC相关参数： （2）FGC相关参数： 3.GC四大算法3.1 如何判断Java中对象是否存活？通过根搜索方法判断。根搜索方法是通过一些GCRoots对象作为起点，从这些节点开始往下搜索，搜索通过的路径成为引用链（ReferenceChain），当一个对象没有被GCRoots的引用链连接的时候，说明这个对象是不可用的。 GCRoots对象包括： 虚拟机栈（栈帧中的本地变量表）中的引用的对象。 方法区域中的类静态属性引用的对象。 方法区域中常量引用的对象。 方法栈中JNI（Native方法）的引用的对象。 3.2 四大算法(1) 引用计数算法引用计数算法是给每个对象设置一个计数器，当有地方引用这个对象的时候，计数器+1，当引用失效的时候，计数器-1，当计数器为0的时候，JVM就认为该对象不再被使用，是“垃圾”了。 引用计数实现简单，效率高；但是不能解决循环引用问问题（A对象引用B对象，B对象又引用A对象，但是A，B对象已不被任何其他对象引用），同时每次计数器的增加和减少都带来了很多额外的开销，所以在JDK1.1之后，这个算法已经不再使用了。 (2) 复制算法（Copying）：适用于新生代原理分析 虚拟机把新生代分为了三部分：1个Eden区和2个Survivor区（分别叫from和to），默认比例为8:1:1。 一般情况下，新创建的对象都会被分配到Eden区（一些大对象特殊处理），这些对象经过第一次Minor GC后，如果仍然存活，将会被移到Survivor区。对象在Survivor区中每熬过一次Minor GC，年龄 +1，当它的年龄增加到一定程度时（默认是 15 ，通过-XX:MaxTenuringThreshold来设定参数），就会被移动到年老代中。 因为新生代中的对象基本都是朝生夕死（被GC回收率90%以上），所以在新生代的垃圾回收算法使用的是复制算法。 复制算法的基本思想就是将内存分为两块，每次只用其中一块（from），当这一块内存用完，就将还活着的对象复制到另外一块上面。 我们来举个例子，在GC开始的时候，对象只会存在于Eden区和名为from的Survivor区，Survivor区to是空的。紧接着进行GC，Eden区中所有存活的对象都会被复制到to，而在from区中，仍存活的对象会根据他们的年龄值来决定去向。年龄达到一定值（默认15）的对象会被移动到老年代中，没有达到阈值的对象会被复制到to区域。经过这次GC后，Eden区和from区已经被清空。这个时候，from和to会交换他们的角色，也就是新的to就是上次GC前的from，新的from就是上次GC前的to。不管怎样，都会保证名为to的Survivor区域是空的。Minor GC会一直重复这样的过程，直到to区被填满，to区被填满之后，会将所有对象移动到老年代中。 -XX:MaxTenuringThreshold，设置对象在新生代中存活的次数。 误区：虚拟机并不是永远地要求对象的年龄必须达到了MaxTenuringThreshold才能晋升老年代，如果在Survivor空间中相同年龄所有对象大小的总和大于Survivor空间的一半，年龄大于或等于该年龄的对象就可以直接进入老年代，无须等到MaxTenuringThreshold中要求的年龄。 因为Eden区对象一般存活率较低，一般的，使用两块10%的内存作为空闲和活动区间，而另外80%的内存，则是用来给新建对象分配内存的。一旦发生GC，将10%的from活动区间与另外80%中存活的Eden区对象转移到10%的to空闲区间，接下来，将之前90%的内存全部释放，以此类推。 上面动画中，Area空闲代表to，Area激活代表from，绿色代表不被回收的，红色代表被回收的。 优缺点 优点 ：不会产生内存碎片，效率高。缺点 ：耗费内存空间。 如果对象的存活率很高，我们可以极端一点，假设是100%存活，那么我们需要将所有对象都复制一遍，并将所有引用地址重置一遍。复制这一工作所花费的时间，在对象存活率达到一定程度时，将会变的不可忽视。 所以从以上描述不难看出，复制算法要想使用，最起码对象的存活率要非常低才行，而且最重要的是，我们必须要克服50%内存的浪费。 (3) 标记清除（Mark-Sweep）：适用于老年代原理分析 标记清除算法，主要分成标记和清除两个阶段，先标记出要回收的对象，然后统一回收这些对象，如下图： 简单来说，标记清除算法就是当程序运行期间，若可以使用的内存被耗尽的时候，GC线程就会被触发并将程序暂停，随后将要回收的对象标记一遍，最终统一回收这些对象，完成标记清理工作接下来便让应用程序恢复运行。 主要进行两项工作，第一项则是标记，第二项则是清除。 标记：从引用根节点开始标记遍历所有的GC Roots， 先标记出要回收的对象。 清除：遍历整个堆，把标记的对象清除。 优缺点 优点 ：不需要额外的内存空间。缺点 ：需要暂停整个应用，会产生内存碎片；两次扫描，耗时严重。 简单来说，它的缺点就是效率比较低（递归与全堆对象遍历），而且在进行GC的时候，需要停止应用程序，这会导致用户体验非常差劲。 而且这种方式清理出来的空闲内存是不连续的，这点不难理解，我们的死亡对象都是随机分布在内存当中，现在把它们清除之后，内存的布局自然会零碎不连续。而为了应付这一点，JVM就不得不维持一个内存的空闲列表，这又是一种开销。并且在分配数组对象的时候，需要去内存寻找连续的内存空间，但此时的内存空间太过零碎分散，因此资源耗费加大。 (4) 标记压缩（Mark-Compact）：适用于老年代原理分析 简单来说，就是先标记，后整理，如下图所示： 优缺点 优点 ：没有内存碎片。缺点 ：需要移动对象的成本，效率也不高（不仅要标记所有存活对象，还要整理所有存活对象的引用地址）。 标记清除压缩 3.3 分代收集算法当前商业虚拟机都是采用分代收集算法，它根据对象存活周期的不同将内存划分为几块，一般是把Java堆分为新生代和老年代，然后根据各个年代的特点采用最适当的垃圾收集算法。在新生代中，每次垃圾收集都发现有大批对象死去，只有少量存活，就选用复制算法，而老年代因为对象存活率高，没有额外空间对它进行分配担保，就必须使用标记清除或者标记压缩算法来进行回收。 4.总结4.1 年轻代（Young Gen）年轻代特点是内存空间相对老年代较小，对象存活率低。 复制算法的效率只和当前存活对象大小有关，因而很适用于年轻代的回收。而复制算法的内存利用率不高的问题，可以通过虚拟机中的两个Survivor区设计得到缓解。 4.2 老年代（Tenure Gen）老年代的特点是内存空间较大，对象存活率高。 这种情况，存在大量存活率高的对象，复制算法明显变得不合适。一般是由标记清除或者是标记清除与标记整理的混合实现。 （1）标记阶段（Mark） 的开销与存活对象的数量成正比。这点上说来，对于老年代，标记清除或者标记整理有一些不符，但可以通过多核/线程利用，对并发、并行的形式提高标记效率。（2）清除阶段（Sweep） 的开销与所管理内存空间大小形正相关。但Sweep“就地处决”的特点，回收的过程没有对象的移动。使其相对其他有对象移动步骤的回收算法，仍然是效率最好的。但是需要解决内存碎片问题。（3）整理阶段（Compact） 的开销与存活对象的数据成开比。如上一条所描述，对于大量对象的移动是很大开销的，做为老年代的第一选择并不合适。 基于上面的考虑，老年代一般是由标记清除或者是标记清除与标记整理的混合实现。以虚拟机中的CMS回收器为例，CMS是基于Mark-Sweep实现的，对于对象的回收效率很高。而对于碎片问题，CMS采用基于Mark-Compact算法的Serial Old回收器做为补偿措施：当内存回收不佳（碎片导致的Concurrent Mode Failure时），将采用Serial Old执行Full GC以达到对老年代内存的整理。 5.常见问题(1).GC四种算法哪个好？ 没有哪个算法是能一次性解决所有问题的，因为JVM垃圾回收使用的是分代收集算法，没有最好的算法，只有根据每一代他的垃圾回收的特性用对应的算法。例如新生代使用复制算法，老年代使用标记清除和标记整理算法。所以说，没有最好的垃圾回收机制，只有最合适的。 (2).请说出各个垃圾回收算法的优缺点 （1）内存效率： 复制算法 &gt; 标记清除算法 &gt; 标记整理算法（此处的效率只是简单的对比时间复杂度，实际情况不一定如此）。（2）内存整齐度： 复制算法 = 标记整理算法 &gt; 标记清除算法。（3）内存利用率： 标记整理算法 = 标记清除算法 &gt; 复制算法。 可以看出，效率上来说，复制算法是当之无愧的老大，但是却浪费了太多内存，而为了尽量兼顾上面所提到的三个指标，标记整理算法相对来说更平滑一些，但效率上依然不尽如人意，它比复制算法多了一个标记的阶段，又比标记清除多了一个整理内存的过程。 参考链接：GC四大算法","tags":[{"name":"java","slug":"java","permalink":"https://sunshine-zwq.gitee.io/tags/java/"},{"name":"jvm","slug":"jvm","permalink":"https://sunshine-zwq.gitee.io/tags/jvm/"}]},{"title":"jvm基础-体系结构及底层原理","date":"2020-12-26T01:38:58.000Z","path":"2020/12/26/jvm基础-体系结构及底层原理/","text":"1. JVM体系结构如下图，JVM 是运行在操作系统之上的，它与硬件没有直接交互。 JVM 体系结构图： 2. 类装载器 ClassLoader类装载器 ClassLoader 是负责加载class文件的，将class文件字节码内容加载到内存中，并将这些内容转换成方法区中的运行时数据结构。ClassLoader只负责文件的加载，至于它是否可运行，则由Execution Engine决定。 在这里需要区分一下class与Class。小写的class，是指编译 Java 代码后所生成的以.class为后缀名的字节码文件。而大写的Class，是 JDK 提供的java.lang.Class，可以理解为封装类的模板。多用于反射场景，例如 JDBC 中的加载驱动，Class.forName(&quot;com.mysql.jdbc.Driver&quot;); 接下来我们来观察下图，Car.class字节码文件被ClassLoader类装载器加载并初始化，在方法区中生成了一个Car Class的类模板，而我们平时所用到的实例化，就是在这个类模板的基础上，形成了一个个实例，即car1，car2。反过来讲，我们可以对某个具体的实例进行getClass()操作，就可以得到该实例的类模板，即Car Class。再接着，我们对这个类模板进行getClassLoader()操作，就可以得到这个类模板是由哪个类装载器进行加载的。 Tip：扩展一下，JVM并不仅仅只是通过检查文件后缀名是否是.class来判断是否加载，最主要的是通过class文件中特定的文件标示，即下图test.class文件中的cafe babe。 2.1 有哪些类装载器？（1）虚拟机自带的加载器 启动类加载器（Bootstrap），也叫根加载器，加载%JAVAHOME%/jre/lib/rt.jar。 扩展类加载器（Extension），加载%JAVAHOME%/jre/lib/ext/*.jar，例如javax.swing包。 应用程序类加载器（AppClassLoader），也叫系统类加载器，加载%CLASSPATH%的所有类。 （2）用户自定义的加载器 用户可以自定义类的加载方式，但必须是Java.lang.ClassLoader的子类。 2.2 双亲委派和沙箱安全接下来，我们通过下面代码来观察这几个类加载器。首先，我们先看自定义的MyObject，首先通过getClassLoader()获取到的是AppClassLoader，然后getParent()得到ExtClassLoader，再getParent()竟然是null？可能大家会有疑惑，不应该是Bootstrap加载器么？这是因为，BootstrapClassLoader是使用C++语言编写的，Java在加载的时候就成了null。 我们再来看Java自带的Object，通过getClassLoader()获取到的加载器直接就是BootstrapClassLoader，如果要想getParent()的话，因为是null值，所以就会报java.lang.NullPointerException空指针异常。 输出中，sun.misc.Launcher是JVM相关调用的入口程序。 那为什么会出现这个情况呢？这就需要我们来了解类加载器的加载顺序和机制了，即双亲委派和沙箱安全 。 （1）双亲委派，当一个类收到了类加载请求，它首先不会尝试自己去加载这个类，而是把这个请求委派给父类去完成，因此所有的加载请求都应该传送到启动类加载器中，只有当父类加载器反馈自己无法完成这个请求的时候（在它的加载路径下没有找到所需加载的Class），子类加载器才会尝试自己去加载。 采用双亲委派的一个好处是，比如加载位于rt.jar包中的类java.lang.Object，不管是哪个加载器加载这个类，最终都是委派给顶层的启动类加载器进行加载，确保哪怕使用了不同的类加载器，最终得到的都是同样一个Object对象。 （2）沙箱安全机制，是基于双亲委派机制上采取的一种JVM的自我保护机制，假设你要写一个java.lang.String的类，由于双亲委派机制的原理，此请求会先交给BootStrapClassLoader试图进行加载，但是BootStrapClassLoader在加载类时首先通过包和类名查找rt.jar中有没有该类，有则优先加载rt.jar包中的类，因此就保证了java的运行机制不会被破坏，确保你的代码不会污染到Java的源码。 所以，类加载器的加载顺序如下： 当AppClassLoader加载一个class时，它首先不会自己去尝试加载这个类，而是把类加载请求委派给父类加载器ExtClassLoader去完成。 当ExtClassLoader加载一个class时，它首先也不会自己去尝试加载这个类，而是把类加载请求委派给BootStrapClassLoader去完成。 如果BootStrapClassLoader加载失败（例如在$JAVA_HOME/jre/lib里未查找到该class），会使用ExtClassLoader来尝试加载。 若ExtClassLoader也加载失败，则会使用AppClassLoader来加载，如果AppClassLoader也加载失败，则会报出异常ClassNotFoundException。 Tip：rt.jar是什么？做了哪些事？这些暂且不提，那你有没有想过，为什么可以在idea这些开发工具中可以直接去使用String、ArrayList、甚至一些JDK提供的类和方法？观察下面动图就可以知道，原来这些都在rt.jar中定义好了，且直接被启动类加载器进行加载了。rt即Runtime。 3. 本地方法栈 Native Method Stack本地方法接口（Native Interface），其作用是融合不同的编程语言为 Java 所用，它的初衷是用来融合 C/C++ 程序的，Java 诞生的时候是 C/C++ 流行时期，要想立足，就得调用 C/C++ 程序，于是 Java 就在内存中专门开辟了一块区域处理标记为 native 的代码。 而本地方法栈（Native Method Stack），就是在一个 Stack 中登记这些 native 方法，然后在执行引擎Execution Engine执行时加载本地方法库native libraies。 接下来，我们通过下图的多线程部分源码来理解什么是native方法。首先我们观察start()的源码，发现它其实并没有做什么复杂的操作，只是单纯的调用了start0()这个方法，然后我们去观察start0()的源码，发现它只是一个使用了native关键字修饰的一个方法（private native void start0();），但只有声明却没有具体的实现！ 为什么？我们都知道Thread是Class关键字修饰的类（class Thread implements Runnable），而不是接口。一般来说，类中的方法都要有定义和实现，接口里面才有方法的定义声明。这就是native方法的独特之处，说白了，被native关键字修饰的方法，基本上和我们，甚至和 Java 都没啥关系了，因为它要去调用底层操作系统或者第三方语言的库函数，所以我们不需要去考虑它具体是如何实现的。 4. 程序计数器 Program Counter Register程序计数器（Program Counter Register），也叫PC寄存器。每个线程启动的时候，都会创建一个PC寄存器。PC寄存器里保存当前正在执行的JVM指令的地址。 每一个线程都有它自己的PC寄存器，也是该线程启动时创建的。 简单来说，PC寄存器就是保存下一条将要执行的指令地址的寄存器，其内容总是指向下一条将被执行指令的地址，这里的地址可以是一个本地指针，也可以是在方法区中相对应于该方法起始指令的偏移量。 每个线程都有一个程序计数器，是线程私有的，就是一个指针，指向方法区中的方法字节码（用来存储指向下一条指令的地址,也即将要执行的指令代码），由执行引擎Execution Engine读取下一条指令，是一个非常小的内存空间，几乎可以忽略不记。 这块内存区域很小，它是当前线程所执行的字节码的行号指示器，字节码解释器通过改变这个计数器的值来选取下一条需要执行的字节码指令。 PC寄存器一般用以完成分支、循环、跳转、异常处理、线程恢复等基础功能。不会发生内存溢出（OutOfMemory，OOM）错误。 如果执行的是一个native方法，那这个计数器是空的。 5. 方法区 Method Area方法区（Method Area），是供各线程共享的运行时内存区域，它存储了每一个类的结构信息。例如运行时常量池（Runtime Constant Pool）、字段和方法数据、构造函数和普通方法的字节码内容。 上面说的是规范（定义的一种抽象概念），实际在不同虚拟机里实现是不一样的，最典型的就是永久代（PermGen space）和元空间（Meta space）。 实例变量存在堆内存中，和方法区无关。 6. 栈 Stack 栈管运行，堆管存储！ 栈（Stack），也叫栈内存，主管Java程序的运行，在线程创建时创建。其生命期是跟随线程的生命期，是线程私有的，线程结束栈内存也就是释放。 对于栈来说，不存在垃圾回收的问题，只要线程一结束该栈就Over。 6.1 栈存储什么数据？栈主要存储8种基本类型的变量、对象的引用变量、以及实例方法。 这里引出一个名词，栈帧，什么是栈帧？每个方法执行的同时都会创建一个栈帧，用于存储局部变量表、操作数栈、动态链接、方法出口等信息，每个方法从调用直至执行完毕的过程，就对应着一个栈帧在虚拟机中入栈到出栈的过程。 简单来说，栈帧对应一个方法的执行和结束，是方法执行过程的内存模型。 其中，栈帧主要保持了3类数据： 本地变量（Local Variables）：输入参数和输出参数，以及方法内的变量。 栈操作（Operand Stack）：记录出栈、入栈的操作。 栈帧数据（Frame Data）：包括类文件、方法等。 栈的大小是根据JVM有关，一般在256K~756K之间，约等于1Mb左右。 6.2 栈的运行原理观察下图，在java中，test()和main()都是方法，而在栈中，称为栈帧。在栈中，main()都是第一个入栈的。栈的顺序为：main()入栈 –&gt; test()入栈 –&gt; test()出栈 –&gt; main()出栈。 根据代码和运行结果可以知道，main()想要出栈，则必须test()先出栈。那么怎么证明呢？观察下面代码，我们在test()方法中添加了一条语句Thread.sleep(Integer.MAX_VALUE);，来让test()无法进行出栈操作，进而导致main()也无法出栈。运行代码发现，运行结果如我们所料，程序一直停留在test()入栈，无法进行其他操作。 我们接着观察下图，在图中一个栈中有两个栈帧，分别是Stack Frame1和Stack Frame2，对应方法1和方法2。其中Stack Frame2是最先被调用的方法2，所以它先入栈。然后方法2又调用了方法1，所以Stack Frame1处于栈顶位置。执行完毕后，依次弹出Stack Frame1和Stack Frame2，然后线程结束，栈释放。所以，每执行一个方法都会产生一个栈帧，并保存到栈的顶部，顶部的栈帧就是当前所执行的方法，该方法执行完毕后会自动出栈。 总结如下，栈中的数据都是以栈帧（Stack Frame）的格式存在，栈帧是一个内存区块，是一个数据集，是一个有关方法（Method）和运行期数据的数据集，当一个方法A被调用时就产生了一个栈帧F1，并被压入到栈中，方法A中又调用了方法B，于是产生栈帧F2也被压入栈中，方法B又调用方法C，于是产生栈帧F3也被压入栈中······执行完毕后，遵循“先进后出，后进先出”的原则，先弹出F3栈帧，再弹出F2栈帧，再弹出F1栈帧。 6.3 栈溢出 StackOverflowError大家肯定对栈溢出耳熟，那栈溢出是怎么产生的呢？ 请看下面代码，test()方法里面又调用了test()方法，即自己调用自己，也叫递归。同时，栈是一个内存块，它是有大小长度的，而我们观察代码发现，只要代码一运行，test()方法就会一直进行入栈操作，而没有出栈操作，结果肯定会超出栈的大小，进而造成栈溢出错误，即java.lang.StackOverflowError。 java.lang.StackOverflowError是错误Error，不是异常Exception！ 7. 栈、堆、方法区的交互关系栈、堆、方法区三者的关系如下图，其中reference是引用类型。 举个例子，比如MyObject myObject = new MyObject();，等号左边MyObject myObject的myObject就是引用，在Java栈里面。等号右边的new MyObject()，new出来的MyObject实例对象在堆里面。简单来说，就是Java栈中的引用myObject指向了堆中的MyObject实例对象。 8. 堆 Heap8.1 堆体系结构一个JVM实例只存在一个堆内存，堆内存的大小是可以调节的。类加载器读取了类文件之后，需要把类、方法、常量变量放到堆内存中，保持所有引用类型的真实信息，方便执行器执行。 其中，堆内存分为3个部分： Young Generation Space，新生区、新生代 Tenure Generation Space，老年区、老年代 Permanent Space，永久区、元空间 Java7之前，堆结构图如下，而Java8则只将永久区变成了元空间。 总结一下，堆内存在逻辑上分为新生+养老+元空间，而堆内存在物理上分为新生+养老。 8.2 对象在堆中的生命周期那么如何直观的了解对象在堆中的生命周期呢？ （1）首先，新生区是类的诞生、成长、消亡的区域。一个类在这里被创建并使用，最后被垃圾回收器收集，结束生命。 （2）其次，所有的类都是在Eden Space被new出来的。而当Eden Space的空间用完时，程序又需要创建对象，JVM的垃圾回收器则会将Eden Space中不再被其他对象所引用的对象进行销毁，也就是垃圾回收（Minor GC）。此时的GC可以认为是轻量级GC。 （3）然后将Eden Space中剩余的未被回收的对象，移动到Survivor 0 Space，以此往复，直到Survivor 0 Space也满了的时候，再对Survivor 0 Space进行垃圾回收，剩余的未被回收的对象，则再移动到Survivor 1 Space。Survivor 1 Space也满了的话，再移动至Tenure Generation Space。 （4）最后，如果Tenure Generation Space也满了的话，那么这个时候就会被垃圾回收（Major GC or Full GC）并将该区的内存清理。此时的GC可以认为是重量级GC。如果Tenure Generation Space被GC垃圾回收之后，依旧处于占满状态的话，就会产生我们场景的OOM异常，即OutOfMemoryError。 8.3 Minor GC的过程Survivor 0 Space，幸存者0区，也叫from区；Survivor 1 Space，幸存者1区，也叫to区。 其中，from区和to区的区分不是固定的，是互相交换的，意思是说，在每次GC之后，两者会进行交换，谁空谁就是to区。 （1）Eden Space、from复制到to，年龄+1。 首先，当Eden Space满时，会触发第一次GC，把还活着的对象拷贝到from区。而当Eden Space再次触发GC时，会扫描Eden Space和from，对这两个区进行垃圾回收，经过此次回收后依旧存活的对象，则直接复制到to区（如果对象的年龄已经达到老年的标准，则移动至老年代区），同时把这些对象的年龄+1。 （2）清空Eden Space、from 然后，清空Eden Space和from中的对象，此时的from是空的。 （3）from和to互换 最后，from和to进行互换，原from成为下一次GC时的to，原to成为下一次GC时的from。部分对象会在from和to中来回进行交换复制，如果交换15次（由JVM参数MaxTenuringThreshold决定，默认15），最终依旧存活的对象就会移动至老年代。 总结一句话，GC之后有交换，谁空谁是to。 这样也是为了保证内存中没有碎片，所以Survivor 0 Space和Survivor 1 Space有一个要是空的。 8.4 HotSpot虚拟机的内存管理 不同对象的生命周期不同，其中98%的对象都是临时对象，即这些对象的生命周期大多只存在于Eden区。 实际而言，方法区（Method Area）和堆一样，是各个线程共享的内存区域，它用于存储虚拟机加载的：类信息+普通常量+静态常量+编译器编译后的代码等等。虽然JVM规范将方法区描述为堆的一个逻辑部分，但它却还有一个别名叫做Non-Heap（非堆内存），目的就是要和堆区分开。 对于HotSpot虚拟机而言，很多开发者习惯将方法区称为 “永久代（Permanent Gen）” 。但严格来说两者是不同的，或者说只是使用永久代来实现方法区而已，永久代是方法区（可以理解为一个接口interface）的一个实现，JDK1.7的版本中，已经将原本放在永久代的字符串常量池移走。（字符串常量池，JDK1.6在方法区，JDK1.7在堆，JDK1.8在元空间。） 如果没有明确指明，Java虚拟机的名字就叫做HotSpot。 8.5 永久区永久区是一个常驻内存区域，用于存放JDK自身所携带的Class，Interface的元数据（也就是上面文章提到的rt.jar等），也就是说它存储的是运行环境必须的类信息，被装载进此区域的数据是不会被垃圾回收器回收掉的，关闭JVM才会释放此区域所占用的内存。 （1）JDK1.7 （2）JDK1.8 在JDK1.8中，永久代已经被移除，被一个称为元空间的区域所取代。元空间的本质和永久代类似。 元空间与永久代之间最大的区别在于： 永久带使用的JVM的堆内存，但是java8以后的元空间并不在虚拟机中而是使用本机物理内存。 因此，默认情况下，元空间的大小仅受本地内存限制。类的元数据放入native memory，字符串池和类的静态变量放入Java堆中，这样可以加载多少类的元数据就不再由MaxPermSize控制, 而由系统的实际可用空间来控制。 8.6 堆参数调优在进行堆参数调优前，我们可以通过下面的代码来获取虚拟机的相关内存信息。 12345678910public class JVMMemory &#123; public static void main(String[] args) &#123; // 返回 Java 虚拟机试图使用的最大内存量 long maxMemory = Runtime.getRuntime().maxMemory(); System.out.println(\"MAX_MEMORY = \" + maxMemory + \"（字节）、\" + (maxMemory / (double) 1024 / 1024) + \"MB\"); // 返回 Java 虚拟机中的内存总量 long totalMemory = Runtime.getRuntime().totalMemory(); System.out.println(\"TOTAL_MEMORY = \" + totalMemory + \"（字节）、\" + (totalMemory / (double) 1024 / 1024) + \"MB\"); &#125;&#125; 运行结果如下： 这个3607.5MB和243.5MB是怎么算出来的？看下图就明白了，默认虚拟机最大内存为物理内存的1/4，而初始分配的内存为物理内存的1/64。 IDEA中如何配置JVM内存参数？在【Run】-&gt;【Edit Configuration…】-&gt;【VM options】中，输入参数-Xms1024m -Xmx1024m -XX:+PrintGCDetails，然后保存退出。 运行结果如下： JVM的初始内存和最大内存一般怎么配？ 答：初始内存和最大内存一定是一样大，理由是避免GC和应用程序争抢内存，进而导致内存忽高忽低产生停顿。 8.7 堆溢出 OutOfMemoryError现在我们来演示一下OOM，首先把堆内存调成10M后，再一直new对象，导致Full GC也无法处理，直至撑爆堆内存，进而导致OOM堆溢出错误，程序及结果如下： 12345678910import java.util.Random;public class OOMTest &#123; public static void main(String[] args) &#123; String str = \"Atlantis\"; while (true) &#123; // 每执行下面语句，会在堆里创建新的对象 str += str + new Random().nextInt(88888888) + new Random().nextInt(999999999); &#125; &#125;&#125; 如果出现java.lang.OutOfMemoryError: Java heap space异常，说明Java虚拟机的堆内存不够，造成堆内存溢出。原因有两点： ①Java虚拟机的堆内存设置太小，可以通过参数-Xms和-Xmx来调整。 ②代码中创建了大量对象，并且长时间不能被GC回收（存在被引用），可能存在内存泄露问题。 9. 执行引擎Execution EngineExecution Engine执行引擎负责解释命令，提交操作系统执行。 参考链接：JVM的体系结构及底层原理","tags":[{"name":"java","slug":"java","permalink":"https://sunshine-zwq.gitee.io/tags/java/"},{"name":"jvm","slug":"jvm","permalink":"https://sunshine-zwq.gitee.io/tags/jvm/"}]},{"title":"Java并发编程常见问题-AQS","date":"2020-12-21T05:36:30.000Z","path":"2020/12/21/Java并发编程常见问题-AQS/","text":"1.为什么需要 AQS？AQS 的作用和重要性是什么？AQS 的重要性 看看 AQS 被用在了哪些类里面： 如图所示，AQS 在 ReentrantLock、ReentrantReadWriteLock、Semaphore、CountDownLatch、ThreadPoolExcutor 的 Worker 中都有运用（JDK 1.8），AQS 是这些类的底层原理。 而以上这些类，很多都是我们经常使用的类，所以说 JUC 包里很多重要的工具类背后都离不开 AQS 框架，因此 AQS 的重要性不言而喻。 学习 AQS 的思路 AQS 类的内部结构要比一般的类复杂得多，里面有很多细节，不容易完全掌握，所以如果我们一上来就直接看源码，容易把自己给绕晕，容易陷入细节不能自拔，导致最后铩羽而归。 其实我们大多数的程序员都是业务开发者，而不是 JDK 开发者，所以平时并不需要自己来开发类似于 ReentrantLock 这样的工具类，所以通常而言，我们不会直接使用到 AQS 来进行开发，因为 JDK 已经提供了很多封装好的线程协作工具类，像前面讲解的 ReentrantLock、Semaphore 就是 JDK 提供给我们的，其内部就用到了 AQS，而这些工具类已经基本足够覆盖大部分的业务场景了，这就使得我们即便不了解 AQS，也能利用这些工具类顺利进行开发。 既然我们学习 AQS 的目的不是进行代码开发，那我们为什么还需要学习 AQS 呢？我认为，我们学习 AQS 的目的主要是想理解其背后的原理、学习设计思想，以提高技术并应对面试。所以本课时的主要目的是从宏观的角度去解读 AQS，比如知道为什么需要 AQS、AQS 有什么作用，在了解了宏观思想之后，再去分析它的内部结构，学习起来就轻松多了。 锁和协作类有共同点：阀门功能 ReentrantLock 和 Semaphore，二者之间有没有什么共同点？ 其实它们都可以当做一个阀门来使用。比如我们把 Semaphore 的许可证数量设置为 1，那么由于它只有一个许可证，所以只能允许一个线程通过，并且当之前的线程归还许可证后，会允许其他线程继续获得许可证。其实这点和 ReentrantLock 很像，只有一个线程能获得锁，并且当这个线程释放锁之后，会允许其他的线程获得锁。那如果线程发现当前没有额外的许可证时，或者当前得不到锁，那么线程就会被阻塞，并且等到后续有许可证或者锁释放出来后，被唤醒，所以这些环节都是比较类似的。 除了上面讲的 ReentrantLock 和 Semaphore 之外，我们会发现 CountDownLatch、ReentrantReadWriteLock 等工具类都有类似的让线程“协作”的功能，其实它们背后都是利用 AQS 来实现的。 为什么需要 AQS 原因是，上面刚讲的那些协作类，它们有很多工作是类似的，所以如果能把实现类似工作的代码给提取出来，变成一个新的底层工具类（或称为框架）的话，就可以直接使用这个工具类来构建上层代码了，而这个工具类其实就是 AQS。 有了 AQS 之后，对于 ReentrantLock 和 Semaphore 等线程协作工具类而言，它们就不需要关心这么多的线程调度细节，只需要实现它们各自的设计逻辑即可。 如果没有 AQS 如果没有 AQS，那就需要每个线程协作工具类自己去实现至少以下内容，包括： 状态的原子性管理 线程的阻塞与解除阻塞 队列的管理 这里的状态对于不同的工具类而言，代表不同的含义，比如对于 ReentrantLock 而言，它需要维护锁被重入的次数，但是保存重入次数的变量是会被多线程同时操作的，就需要进行处理，以便保证线程安全。不仅如此，对于那些未抢到锁的线程，还应该让它们陷入阻塞，并进行排队，并在合适的时机唤醒。所以说这些内容其实是比较繁琐的，而且也是比较重复的，而这些工作目前都由 AQS 来承担了。 如果没有 AQS，就需要 ReentrantLock 等类来自己实现相关的逻辑，但是让每个线程协作工具类自己去正确并且高效地实现这些内容，是相当有难度的。AQS 可以帮我们把 “脏活累活” 都搞定，所以对于 ReentrantLock 和 Semaphore 等类而言，它们只需要关注自己特有的业务逻辑即可。 AQS 的作用 AQS 是一个用于构建锁、同步器等线程协作工具类的框架，有了 AQS 以后，很多用于线程协作的工具类就都可以很方便的被写出来，有了 AQS 之后，可以让更上层的开发极大的减少工作量，避免重复造轮子，同时也避免了上层因处理不当而导致的线程安全问题，因为 AQS 把这些事情都做好了。总之，有了 AQS 之后，我们构建线程协作工具类就容易多了。 2.AQS 的内部原理是什么样的？AQS 最核心的三大部分就是状态、队列和期望协作工具类去实现的获取/释放等重要方法。 state 状态 如果我们的 AQS 想要去管理或者想作为协作工具类的一个基础框架，那么它必然要管理一些状态，而这个状态在 AQS 内部就是用 state 变量去表示的。它的定义如下： 1234/** * The synchronization state. */private volatile int state; 而 state 的含义并不是一成不变的，它会根据具体实现类的作用不同而表示不同的含义，下面举几个例子。 比如说在信号量里面，state 表示的是剩余许可证的数量。如果我们最开始把 state 设置为 10，这就代表许可证初始一共有 10 个，然后当某一个线程取走一个许可证之后，这个 state 就会变为 9，所以信号量的 state 相当于是一个内部计数器。 再比如，在 CountDownLatch 工具类里面，state 表示的是需要“倒数”的数量。一开始我们假设把它设置为 5，当每次调用 CountDown 方法时，state 就会减 1，一直减到 0 的时候就代表这个门闩被放开。 下面我们再来看一下 state 在 ReentrantLock 中是什么含义，在 ReentrantLock 中它表示的是锁的占有情况。最开始是 0，表示没有任何线程占有锁；如果 state 变成 1，则就代表这个锁已经被某一个线程所持有了。 这就是 state 在不同类中不同含义的一个具体表现。我们举了三个例子，如果未来有新的工具要利用到 AQS，它一定也需要利用 state，为这个类表示它所需要的业务逻辑和状态。 下面我们再来看一下关于 state 修改的问题，因为 state 是会被多个线程共享的，会被并发地修改，所以所有去修改 state 的方法都必须要保证 state 是线程安全的。可是 state 本身它仅仅是被 volatile 修饰的，volatile 本身并不足以保证线程安全，所以我们就来看一下，AQS 在修改 state 的时候具体利用了什么样的设计来保证并发安全。 我们举两个和 state 相关的方法，分别是 compareAndSetState 及 setState，它们的实现已经由 AQS 去完成了，也就是说，我们直接调用这两个方法就可以对 state 进行线程安全的修改。下面就来看一下这两个方法的源码是怎么实现的。 先来看一下 compareAndSetState 方法的代码，如下所示： 123protected final boolean compareAndSetState(int expect, int update) &#123; return unsafe.compareAndSwapInt(this, stateOffset, expect, update);&#125; 方法里面只有一行代码，即 return unsafe.compareAndSwapInt(this, stateOffset, expect, update)，它利用了 Unsafe 里面的 CAS 操作，利用 CPU 指令的原子性保证了这个操作的原子性。 setState 方法的源码，如下所示： 123protected final void setState(int newState) &#123; state = newState;&#125; state 的定义代码： 1234/** * The synchronization state. */private volatile int state; 可以看出，state 是 int 类型的，属于基本类型，并且这里的 setState 方法内是对 state 直接赋值的，它不涉及读取之前的值，也不涉及在原来值的基础上再修改，所以我们仅仅利用 volatile 就可以保证在这种情况下的并发安全，这就是 setState 方法线程安全的原因。 FIFO 队列 FIFO 队列，即先进先出队列，这个队列最主要的作用是存储等待的线程。假设很多线程都想要同时抢锁，那么大部分的线程是抢不到的，那怎么去处理这些抢不到锁的线程呢？就得需要有一个队列来存放、管理它们。所以 AQS 的一大功能就是充当线程的“排队管理器”。 当多个线程去竞争同一把锁的时候，就需要用排队机制把那些没能拿到锁的线程串在一起；而当前面的线程释放锁之后，这个管理器就会挑选一个合适的线程来尝试抢刚刚释放的那把锁。所以 AQS 就一直在维护这个队列，并把等待的线程都放到队列里面。 这个队列内部是双向链表的形式，其数据结构看似简单，但是要想维护成一个线程安全的双向队列却非常复杂，因为要考虑很多的多线程并发问题。来看一下 AQS 作者 Doug Lea 给出的关于这个队列的一个图示： 在队列中，分别用 head 和 tail 来表示头节点和尾节点，两者在初始化的时候都指向了一个空节点。头节点可以理解为“当前持有锁的线程”，而在头节点之后的线程就被阻塞了，它们会等待被唤醒，唤醒也是由 AQS 负责操作的。 获取/释放方法 获取和释放相关的重要方法，是协作工具类的逻辑的具体体现，需要每一个协作工具类自己去实现，所以在不同的工具类中，它们的实现和含义各不相同。 (1).获取方法 获取操作通常会依赖 state 变量的值，根据 state 值不同，协作工具类也会有不同的逻辑，并且在获取的时候也经常会阻塞，下面来看几个具体的例子。 比如 ReentrantLock 中的 lock 方法就是其中一个“获取方法”，执行时，如果发现 state 不等于 0 且当前线程不是持有锁的线程，那么就代表这个锁已经被其他线程所持有了。这个时候，当然就获取不到锁，于是就让该线程进入阻塞状态。 再比如，Semaphore 中的 acquire 方法就是其中一个“获取方法”，作用是获取许可证，此时能不能获取到这个许可证也取决于 state 的值。如果 state 值是正数，那么代表还有剩余的许可证，数量足够的话，就可以成功获取；但如果 state 是 0，则代表已经没有更多的空余许可证了，此时这个线程就获取不到许可证，会进入阻塞状态，所以这里同样也是和 state 的值相关的。 再举个例子，CountDownLatch 获取方法就是 await 方法（包含重载方法），作用是“等待，直到倒数结束”。执行 await 的时候会判断 state 的值，如果 state 不等于 0，线程就陷入阻塞状态，直到其他线程执行倒数方法把 state 减为 0，此时就代表现在这个门闩放开了，所以之前阻塞的线程就会被唤醒。 (2).释放方法 释放方法是站在获取方法的对立面的，通常和刚才的获取方法配合使用。我们刚才讲的获取方法可能会让线程阻塞，比如说获取不到锁就会让线程进入阻塞状态，但是释放方法通常是不会阻塞线程的。 比如在 Semaphore 信号量里面，释放就是 release 方法（包含重载方法），release() 方法的作用是去释放一个许可证，会让 state 加 1；而在 CountDownLatch 里面，释放就是 countDown 方法，作用是倒数一个数，让 state 减 1。所以也可以看出，在不同的实现类里面，他们对于 state 的操作是截然不同的，需要由每一个协作类根据自己的逻辑去具体实现。 拓展资源： 第一个资源是 AQS 作者本人 Doug Lea 所写的一篇论文，这篇论文自然是非常宝贵的学习资料，点击这里查看； 第二个是来自 Javadoop 博客对于 AQS 的源码分析的文章，感兴趣的话也可以阅读，点击这里查看。 3.AQS 在 CountDownLatch 等类中的应用原理是什么？AQS 用法 如果想使用 AQS 来写一个自己的线程协作工具类，通常而言是分为以下三步，这也是 JDK 里利用 AQS 类的主要步骤： 第一步，新建一个自己的线程协作工具类，在内部写一个 Sync 类，该 Sync 类继承 AbstractQueuedSynchronizer，即 AQS； 第二步，想好设计的线程协作工具类的协作逻辑，在 Sync 类里，根据是否是独占，来重写对应的方法。如果是独占，则重写 tryAcquire 和 tryRelease 等方法；如果是非独占，则重写 tryAcquireShared 和 tryReleaseShared 等方法； 第三步，在自己的线程协作工具类中，实现获取/释放的相关方法，并在里面调用 AQS 对应的方法，如果是独占则调用 acquire 或 release 等方法，非独占则调用 acquireShared 或 releaseShared 或 acquireSharedInterruptibly 等方法。 你可能注意到了，上面的第二步是根据某些条件来重写特定的一部分方法，这个做法好像之前很少遇到过，或者说你可能会想，是不是有更好的做法？比如通过实现接口的方式，因为实现某一个接口之后，自然就知道需要重写其中哪些方法了，为什么要先继承类，然后自己去判断选择哪些方法进行重写呢？这不是自己给自己设置障碍吗？ 关于这个问题的答案，其实在 AQS 的原作者 Doug Lea 的论文中已经进行了说明，他认为如果是实现接口的话，那每一个抽象方法都需要实现。比如你把整个 AQS 作为接口，那么需要实现的方法有很多，包括 tryAcquire、tryRelease、tryAcquireShared、tryReleaseShared 等，但是实际上我们并不是每个方法都需要重写，根据需求的不同，有选择的去实现一部分就足以了，所以就设计为不采用实现接口，而采用继承类并重写方法的形式。 那可能你又有疑问了，继承类后，是不强制要求重写方法的，所以如果我们一个方法都不重写，行不行呢？答案是，如果不重写刚才所讲的 tryAcquire 等方法，是不行的，因为在执行的时候会抛出异常，我们来看下 AQS 对这些方法的默认的实现就知道了。 下面有四个方法的代码，分别是 tryAcquire、tryRelease、tryAcquireShared 和 tryReleaseShared 方法： 123456789101112protected boolean tryAcquire(int arg) &#123; throw new UnsupportedOperationException();&#125;protected boolean tryRelease(int arg) &#123; throw new UnsupportedOperationException();&#125;protected int tryAcquireShared(int arg) &#123; throw new UnsupportedOperationException();&#125;protected boolean tryReleaseShared(int arg) &#123; throw new UnsupportedOperationException();&#125; 可以看到它们内部只有一行实现代码，就是直接抛出异常，所以要求我们在继承 AQS 之后，必须把相关方法去重写、覆盖，这样未来我们写的线程协作类才能正常的运行。 AQS 在 CountDownLatch 的应用 在 CountDownLatch 里面有一个子类，该类的类名叫 Sync，这个类正是继承自 AQS。下面给出了 CountDownLatch 部分代码的截取： 12345678910111213141516171819202122232425262728293031public class CountDownLatch &#123; /** * Synchronization control For CountDownLatch. * Uses AQS state to represent count. */ private static final class Sync extends AbstractQueuedSynchronizer &#123; private static final long serialVersionUID = 4982264981922014374L; Sync(int count) &#123; setState(count); &#125; int getCount() &#123; return getState(); &#125; protected int tryAcquireShared(int acquires) &#123; return (getState() == 0) ? 1 : -1; &#125; protected boolean tryReleaseShared(int releases) &#123; // Decrement count; signal when transition to zero for (;;) &#123; int c = getState(); if (c == 0) return false; int nextc = c-1; if (compareAndSetState(c, nextc)) return nextc == 0; &#125; &#125; &#125; private final Sync sync; //省略其他代码...&#125; 可以很明显看到最开始一个 Sync 类继承了 AQS，这正是上一节所讲的“第一步，新建一个自己的线程协作工具类，在内部写一个 Sync 类，该 Sync 类继承 AbstractQueuedSynchronizer，即 AQS”。而在 CountDownLatch 里面还有一个 sync 的变量，正是 Sync 类的一个对象。 同时，我们看到，Sync 不但继承了 AQS 类，而且还重写了 tryAcquireShared 和 tryReleaseShared 方法，这正对应了“第二步，想好设计的线程协作工具类的协作逻辑，在 Sync 类里，根据是否是独占，来重写对应的方法。如果是独占，则重写 tryAcquire 或 tryRelease 等方法；如果是非独占，则重写 tryAcquireShared 和 tryReleaseShared 等方法”。 这里的 CountDownLatch 属于非独占的类型，因此它重写了 tryAcquireShared 和 tryReleaseShared 方法，那么这两个方法的具体含义是什么呢？别急，接下来就让我们对 CountDownLatch 类里面最重要的 4 个方法进行分析，逐步揭开它的神秘面纱。 构造函数 首先来看看构造函数。CountDownLatch 只有一个构造方法，传入的参数是需要“倒数”的次数，每次调用 countDown 方法就会倒数 1，直到达到了最开始设定的次数之后，相当于是“打开了门闩”，所以之前在等待的线程可以继续工作了。 我们具体来看下构造函数的代码： 1234public CountDownLatch(int count) &#123; if (count &lt; 0) throw new IllegalArgumentException(\"count &lt; 0\"); this.sync = new Sync(count);&#125; 从代码中可以看到，当 count &lt; 0 时会抛出异常，当 count &gt; = 0，即代码 this.sync = new Sync( count ) ，往 Sync 中传入了 count，这个里的 Sync 的构造方法如下： 123Sync(int count) &#123; setState(count);&#125; 该构造函数调用了 AQS 的 setState 方法，并且把 count 传进去了，而 setState 正是给 AQS 中的 state 变量赋值的，代码如下： 123protected final void setState(int newState) &#123; state = newState;&#125; 所以我们通过 CountDownLatch 构造函数将传入的 count 最终传递到 AQS 内部的 state 变量，给 state 赋值，state 就代表还需要倒数的次数。 getCount 接下来介绍 getCount 方法，该方法的作用是获取当前剩余的还需要“倒数”的数量，getCount 方法的源码如下： 123public long getCount() &#123; return sync.getCount();&#125; 该方法 return 的是 sync 的 getCount： 123int getCount() &#123; return getState();&#125; 我们一步步把源码追踪下去，getCount 方法调用的是 AQS 的 getState： 123protected final int getState() &#123; return state;&#125; 如代码所示，protected final int getState 方法直接 return 的就是 state 的值，所以最终它获取到的就在 AQS 中 state 变量的值。 countDown 我们再来看看 countDown 方法，该方法其实就是 CountDownLatch 的“释放”方法，下面来看下源码： 123public void countDown() &#123; sync.releaseShared(1);&#125; 在 countDown 方法中调用的是 sync 的 releaseShared 方法： 1234567public final boolean releaseShared(int arg) &#123; if (tryReleaseShared(arg)) &#123; doReleaseShared(); return true; &#125; return false;&#125; 可以看出，releaseShared 先进行 if 判断，判断 tryReleaseShared 方法的返回结果，因此先把目光聚焦到 tryReleaseShared 方法中，tryReleaseShared 源码如下所示 ： 1234567891011protected boolean tryReleaseShared(int releases) &#123; // Decrement count; signal when transition to zero for (;;) &#123; int c = getState(); if (c == 0) return false; int nextc = c-1; if (compareAndSetState(c, nextc)) return nextc == 0; &#125;&#125; 方法内是一个 for 的死循环，在循环体中，最开始是通过 getState 拿到当前 state 的值并赋值给变量 c，这个 c 可以理解为是 count 的缩写，如果此时 c = 0，则意味着已经倒数为零了，会直接会执行下面的 return false 语句，一旦 tryReleaseShared 方法返回 false，再往上看上一层的 releaseShared 方法，就会直接跳过整个 if (tryReleaseShared(arg)) 代码块，直接返回 false，相当于 releaseShared 方法不产生效果，也就意味着 countDown 方法不产生效果。 再回到 tryReleaseShared 方法中往下看 return false 下面的语句，如果 c 不等于 0，在这里会先把 c-1 的值赋给 nextc，然后再利用 CAS 尝试把 nextc 赋值到 state 上。如果赋值成功就代表本次 countDown 方法操作成功，也就意味着把 AQS 内部的 state 值减了 1。最后，是 return nextc == 0，如果 nextc 为 0，意味着本次倒数后恰好达到了规定的倒数次数，门闩应当在此时打开，所以 tryReleaseShared 方法会返回 true，那么再回到之前的 releaseShared 方法中，可以看到，接下来会调用 doReleaseShared 方法，效果是对之前阻塞的线程进行唤醒，让它们继续执行。 如果结合具体的数来分析，可能会更清晰。假设 c = 2，则代表需要倒数的值是 2，nextc = c-1，所以 nextc 就是 1，然后利用 CAS 尝试把 state 设置为 1，假设设置成功，最后会 return nextc == 0，此时 nextc 等于 1，不等于 0，所以返回 false，也就意味着 countDown 之后成功修改了 state 的值，把它减 1 了，但并没有唤醒线程。 下一次执行 countDown时，c 的值就是 1，而 nextc = c - 1，所以 nextc 等于 0，若这时 CAS 操作成功，最后 return nextc == 0，所以方法返回 true，一旦 tryReleaseShared 方法 return true，则 releaseShared 方法会调用 doReleaseShared 方法，把所有之前阻塞的线程都唤醒。 await 接着我们来看看 await 方法，该方法是 CountDownLatch 的“获取”方法，调用 await 方法会把线程阻塞，直到倒数为 0 才能继续执行。await 方法和 countDown 是配对的，追踪源码可以看到 await 方法的实现： 123public void await() throws InterruptedException &#123; sync.acquireSharedInterruptibly(1);&#125; 它会调用 sync 的 acquireSharedInterruptibly ，并且传入 1。acquireSharedInterruptibly 方法源码如下所示： 1234567public final void acquireSharedInterruptibly(int arg) throws InterruptedException &#123; if (Thread.interrupted()) throw new InterruptedException(); if (tryAcquireShared(arg) &lt; 0) doAcquireSharedInterruptibly(arg);&#125; 可以看到，它除了对于中断的处理之外，比较重要的就是 tryAcquireShared 方法。这个方法很简单，它会直接判断 getState 的值是不是等于 0，如果等于 0 就返回 1，不等于 0 则返回 -1。 123protected int tryAcquireShared(int acquires) &#123; return (getState() == 0) ? 1 : -1;&#125; getState 方法获取到的值是剩余需要倒数的次数，如果此时剩余倒数的次数大于 0，那么 getState 的返回值自然不等于 0，因此 tryAcquireShared 方法会返回 -1，一旦返回 -1，再看到 if (tryAcquireShared(arg) &lt; 0) 语句中，就会符合 if 的判断条件，并且去执行 doAcquireSharedInterruptibly 方法，然后会让线程进入阻塞状态。 我们再来看下另一种情况，当 state 如果此时已经等于 0 了，那就意味着倒数其实结束了，不需要再去等待了，就是说门闩是打开状态，所以说此时 getState 返回 0，tryAcquireShared 方法返回 1 ，一旦返回 1，对于 acquireSharedInterruptibly 方法而言相当于立刻返回，也就意味着 await 方法会立刻返回，那么此时线程就不会进入阻塞状态了，相当于倒数已经结束，立刻放行了。 这里的 await 和 countDown 方法，正对应了一开始所介绍的“第三步，在自己的线程协作工具类中，实现获取/释放的相关方法，并在里面调用 AQS 对应的方法，如果是独占则调用 acquire 或 release 等方法，非独占则调用 acquireShared 或 releaseShared 或 acquireSharedInterruptibly 等方法。” AQS 在 CountDownLatch 的应用总结 当线程调用 CountDownLatch 的 await 方法时，便会尝试获取“共享锁”，不过一开始通常获取不到锁，于是线程被阻塞。“共享锁”可获取到的条件是“锁计数器”的值为 0，而“锁计数器”的初始值为 count，当每次调用 CountDownLatch 对象的 countDown 方法时，也可以把“锁计数器” -1。通过这种方式，调用 count 次 countDown 方法之后，“锁计数器”就为 0 了，于是之前等待的线程就会继续运行了，并且此时如果再有线程想调用 await 方法时也会被立刻放行，不会再去做任何阻塞操作了。","tags":[{"name":"java","slug":"java","permalink":"https://sunshine-zwq.gitee.io/tags/java/"},{"name":"并发编程","slug":"并发编程","permalink":"https://sunshine-zwq.gitee.io/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"},{"name":"面试","slug":"面试","permalink":"https://sunshine-zwq.gitee.io/tags/%E9%9D%A2%E8%AF%95/"}]},{"title":"Java并发编程常见问题-线程协作","date":"2020-12-21T00:58:41.000Z","path":"2020/12/21/Java并发编程常见问题-线程协作/","text":"1.信号量能被 FixedThreadPool 替代吗？Semaphore 信号量 从图中可以看出，信号量的一个最主要的作用就是，来控制那些需要限制并发访问量的资源。具体来讲，信号量会维护“许可证”的计数，而线程去访问共享资源前，必须先拿到许可证。线程可以从信号量中去“获取”一个许可证，一旦线程获取之后，信号量持有的许可证就转移过去了，所以信号量手中剩余的许可证要减一。 同理，线程也可以“释放”一个许可证，如果线程释放了许可证，这个许可证相当于被归还给信号量了，于是信号量中的许可证的可用数量加一。当信号量拥有的许可证数量减到 0 时，如果下个线程还想要获得许可证，那么这个线程就必须等待，直到之前得到许可证的线程释放，它才能获取。由于线程在没有获取到许可证之前不能进一步去访问被保护的共享资源，所以这就控制了资源的并发访问量，这就是整体思路。 应用实例、使用场景 来看一个具体的场景： 在这个场景中，我们的服务是中间这个方块儿，左侧是请求，右侧是我们所依赖的那个慢服务。出于种种原因（比如计算量大、依赖的下游服务多等），右边的慢服务速度很慢，并且它可以承受的请求数量也很有限，一旦有太多的请求同时到达它这边，可能会导致它这个服务不可用，会压垮它。所以我们必须要保护它，不能让太多的线程同时去访问。 先来看一看，在通常的场景下，我们用一个普通线程池能不能做到这件事情。 123456789101112131415161718192021public class SemaphoreDemo1 &#123; public static void main(String[] args) &#123; ExecutorService service = Executors.newFixedThreadPool(50); for (int i = 0; i &lt; 1000; i++) &#123; service.submit(new Task()); &#125; service.shutdown(); &#125; static class Task implements Runnable &#123; @Override public void run() &#123; System.out.println(Thread.currentThread().getName() + \"调用了慢服务\"); try &#123; //模拟慢服务 Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; 在这段代码中，有一个固定 50 个线程的线程池，然后给线程池提交 1000 个任务，并且每一个任务所执行的内容，就是去休眠 3 秒钟，来模拟调用这个慢服务的过程。我们启动这个程序，会发现打印出来的结果如下所示： 12345678pool-1-thread-2调用了慢服务pool-1-thread-4调用了慢服务pool-1-thread-3调用了慢服务pool-1-thread-1调用了慢服务pool-1-thread-5调用了慢服务pool-1-thread-6调用了慢服务...（包含了pool-1-thread-1到pool-1-thread-50这50个线程） 它会从线程 1 一直到线程 50 都去调用这个慢服务，当然实际调用顺序每次都会不一样，但是这 50 个线程都会去几乎同时调用这个慢服务，在这种情况下，就会导致我们的慢服务崩溃。 所以，必须严格限制能够同时到达该服务的请求数。比如，我们想限制同时不超过 3 个请求来访问该服务，该怎么实现呢？并且这里有一点值得注意，我们的前提条件是，线程池中确实有 50 个线程，线程数肯定超过了 3 个，那么怎么进一步控制这么多的线程不同时访问慢服务呢？我们可以通过信号量来解决这个问题。 正常情况下获取许可证 这张图的方框代表一个许可证为 3 的信号量，每一个绿色的长条代表一个许可证（permit）。现在我们拥有 3 个许可证，并且信号量的特点是非常“慷慨”，只要它持有许可证，别人想请求的话它都会分发的。假设此时 Thread 1 来请求了，在这种情况下，信号量就会把一个许可证给到这边的第一个线程 Thread 1。于是 Thread 1 获得了许可证，变成了下图这个样子： Thread 1 拿到许可证之后就拥有了访问慢服务的资格，它紧接着就会去访问我们的慢服务，同时，我们的信号量手中持有的许可证也减为了 2。假设这个慢服务速度很慢，可能长时间内不返回，所以在没返回之前，Thread 1 也会不释放许可证，在此期间第二个线程又来请求了： 同理，此时由于信号量手中持有两个许可证，还是可以满足 Thread 2 的需求的，所以就把第二个许可证给了第二个线程。这样一来，第二个线程也拿到了我们的许可证，可以访问右边的慢服务了，如图所示： 同理，在前两个线程返回前，第三个线程也过来了，也是按照同样的方式获得了许可证，并且访问慢服务： 没许可证时，会阻塞前来请求的线程 至此，信号量中的许可证已经没有了，因为原有的 3 个都分给这 3 个线程了。在这种情况下，信号量就可以进一步发挥作用了，此时假设第 4 个线程再来请求找信号量拿许可证，由于此时线程 1、线程 2、线程 3 都正在访问“慢服务”，还没归还许可证，而信号量自身也没有更多的许可证了，所以在这个时候就会发生这样的一种情况： 线程 4 在找我们用 acquire 方法请求许可证的时候，它会被阻塞，意味着线程 4 没有拿到许可证，也就没有被允许访问“慢服务”，也就是说此时“慢服务”依然只能被前面的 3 个线程访问，这样就达到我们最开始的目的了：限制同时最多有 3 个线程调用我们的慢服务。 有线程释放信号量后 假设此时线程 1 因为最早去的，它执行完了这个任务，于是返回了。返回的时候它会调用 release 方法，表示“我处理完了我的任务，我想把许可证还回去”，所以，此时线程 1 就释放了之前持有的许可证，把它还给了我们的信号量，于是信号量所持有的许可证数量从 0 又变回了 1，如图所示： 此时由于许可证已经归还给了信号量，那么刚才找我们要许可证的线程 4 就可以顺利地拿到刚刚释放的这个许可证了。于是线程 4 也就拥有了访问慢服务的访问权，接下来它也会去访问这个慢服务。 不过要注意，此时线程 1 先归还了许可证给信号量，再由信号量把这个许可证转给线程 4，所以，此时同时访问慢服务的依然只有 3 个线程，分别是线程 2、3 和 4，因为之前的线程 1 已经完成任务并且离开了。 如果有两个线程释放许可证 假设程序继续运行，随着时间推移，线程 2 和 3 同时执行完毕，然后释放手中的许可证。于是信号量又重新拥有了 2 个许可证，它会把许可证进一步发放给还有这个需求的线程 5 和线程 6，那么这两个线程也就能访问这个慢服务了： 不过此时访问慢服务的就变成了线程 4、5、6，可以看出，总的数量从来没有超过 3 个。 在这个例子中，线程 4 一开始获取许可证的时候被阻塞了，那个时候即使有线程 5 和线程 6 甚至线程 100 都来执行 acquire 方法的话，信号量也会把这些通通给阻塞住，这样就起到了信号量最主要的控制并发量的作用。 使用流程 使用流程主要分为以下三步： (1).初始化一个信号量，并且传入许可证的数量，这是它的带公平参数的构造函数：public Semaphore(int permits, boolean fair)，传入两个参数，第一个参数是许可证的数量，另一个参数是是否公平。如果第二个参数传入 true，则代表它是公平的策略，会把之前已经等待的线程放入到队列中，而当有新的许可证到来时，它会把这个许可证按照顺序发放给之前正在等待的线程；如果这个构造函数第二个参数传入 false，则代表非公平策略，也就有可能插队，就是说后进行请求的线程有可能先得到许可证。 (2).在建立完这个构造函数，初始化信号量之后，我们就可以利用 acquire() 方法。在调用慢服务之前，让线程来调用 acquire 方法或者 acquireUninterruptibly方法，这两个方法的作用是要获取许可证，这同时意味着只有这个方法能顺利执行下去的话，它才能进一步访问这个代码后面的调用慢服务的方法。如果此时信号量已经没有剩余的许可证了，那么线程就会等在 acquire 方法的这一行代码中，所以它也不会进一步执行下面调用慢服务的方法。我们正是用这种方法，保护了我们的慢服务。 acquire() 和 acquireUninterruptibly() 的区别是：是否能响应中断。acquire() 是可以支持中断的，也就是说，它在获取信号量的期间，假设这个线程被中断了，那么它就会跳出 acquire() 方法，不再继续尝试获取了。而 acquireUninterruptibly() 方法是不会被中断的。 (3).在任务执行完毕之后，调用 release() 来释放许可证，比如说我们在执行完慢服务这行代码之后，再去执行 release() 方法，这样一来，许可证就会还给我们的信号量了。 其他主要方法介绍 （1）public boolean tryAcquire() tryAcquire 和之前介绍锁的 trylock 思维是一致的，是尝试获取许可证，相当于看看现在有没有空闲的许可证，如果有就获取，如果现在获取不到也没关系，不必陷入阻塞，可以去做别的事。 （2）public boolean tryAcquire(long timeout, TimeUnit unit) 同样有一个重载的方法，它里面传入了超时时间。比如传入了 3 秒钟，则意味着最多等待 3 秒钟，如果等待期间获取到了许可证，则往下继续执行；如果超时时间到，依然获取不到许可证，它就认为获取失败，且返回 false。 （3）availablePermits() 这个方法用来查询可用许可证的数量，返回一个整型的结果。 示例代码： 12345678910111213141516171819202122232425262728public class SemaphoreDemo2 &#123; static Semaphore semaphore = new Semaphore(3); public static void main(String[] args) &#123; ExecutorService service = Executors.newFixedThreadPool(50); for (int i = 0; i &lt; 1000; i++) &#123; service.submit(new Task()); &#125; service.shutdown(); &#125; static class Task implements Runnable &#123; @Override public void run() &#123; try &#123; semaphore.acquire(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName() + \"拿到了许可证，花费2秒执行慢服务\"); try &#123; Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(\"慢服务执行完毕，\" + Thread.currentThread().getName() + \"释放了许可证\"); semaphore.release(); &#125; &#125;&#125; 代码执行结果如下： 12345678910111213pool-1-thread-1拿到了许可证，花费2秒执行慢服务pool-1-thread-2拿到了许可证，花费2秒执行慢服务pool-1-thread-3拿到了许可证，花费2秒执行慢服务慢服务执行完毕，pool-1-thread-1释放了许可证慢服务执行完毕，pool-1-thread-2释放了许可证慢服务执行完毕，pool-1-thread-3释放了许可证pool-1-thread-4拿到了许可证，花费2秒执行慢服务pool-1-thread-5拿到了许可证，花费2秒执行慢服务pool-1-thread-6拿到了许可证，花费2秒执行慢服务慢服务执行完毕，pool-1-thread-4释放了许可证慢服务执行完毕，pool-1-thread-5释放了许可证慢服务执行完毕，pool-1-thread-6释放了许可证... 特殊用法：一次性获取或释放多个许可证 比如 semaphore.acquire(2)，里面传入参数 2，这就叫一次性获取两个许可证。同时释放也是一样的，semaphore.release(3) 相当于一次性释放三个许可证。 为什么要这样做呢？我们列举一个使用场景。比如说第一个任务 A（Task A ）会调用很耗资源的方法一 method1()，而任务 B 调用的是方法二 method 2，但这个方法不是特别消耗资源。在这种情况下，假设我们一共有 5 个许可证，只能允许同时有 1 个线程调用方法一，或者同时最多有 5 个线程调用方法二，但是方法一和方法二不能同时被调用。 所以，我们就要求 Task A 在执行之前要一次性获取到 5 个许可证才能执行，而 Task B 只需要获取一个许可证就可以执行了。这样就避免了任务 A 和 B 同时运行，同时又很好的兼顾了效率，不至于同时只允许一个线程访问方法二，那样的话也存在浪费资源的情况，所以这就相当于我们可以根据自己的需求合理地利用信号量的许可证来分配资源。 注意点 获取和释放的许可证数量尽量保持一致，否则比如每次都获取 2 个但只释放 1 个甚至不释放，那么信号量中的许可证就慢慢被消耗完了，最后导致里面没有许可证了，那其他的线程就再也没办法访问了； 在初始化的时候可以设置公平性，如果设置为 true 则会让它更公平，但如果设置为 false 则会让总的吞吐量更高。 信号量是支持跨线程、跨线程池的，而且并不是哪个线程获得的许可证，就必须由这个线程去释放。事实上，对于获取和释放许可证的线程是没有要求的，比如线程 A 获取了然后由线程 B 释放，这完全是可以的，只要逻辑合理即可。 信号量能被 FixedThreadPool 替代吗？ 这个问题相当于，信号量是可以限制同时访问的线程数，那为什么不直接用固定数量线程池去限制呢？这样不是更方便吗？比如说线程池里面有 3 个线程，那自然最多只有 3 个线程去访问了。 这是一个很好的问题，我们在实际业务中会遇到这样的情况：假如，在调用慢服务之前需要有个判断条件，比如只想在每天的零点附近去访问这个慢服务时受到最大线程数的限制（比如 3 个线程），而在除了每天零点附近的其他大部分时间，我们是希望让更多的线程去访问的。所以在这种情况下就应该把线程池的线程数量设置为 50 ，甚至更多，然后在执行之前加一个 if 判断，如果符合时间限制了（比如零点附近），再用信号量去额外限制，这样做是比较合理的。 再说一个例子，比如说在大型应用程序中会有不同类型的任务，它们也是通过不同的线程池来调用慢服务的。因为调用方不只是一处，可能是 Tomcat 服务器或者网关，我们就不应该限制，或者说也无法做到限制它们的线程池的大小。但可以做的是，在执行任务之前用信号量去限制一下同时访问的数量，因为我们的信号量具有跨线程、跨线程池的特性，所以即便这些请求来自于不同的线程池，我们也可以限制它们的访问。如果用 FixedThreadPool 去限制，那就做不到跨线程池限制了，这样的话会让功能大大削弱。 基于以上的理由，如果想要限制并发访问的线程数，用信号量是更合适的。 2.CountDownLatch 是如何安排线程执行顺序的？CountDownLatch是 JDK 提供的并发流程控制的工具类，它在 java.util.concurrent 包下， JDK1.5 以后加入的。 比如我们去游乐园坐激流勇进，有的时候游乐园里人不是那么多，这时，管理员会让你稍等一下，等人坐满了再开船，这样的话可以在一定程度上节约游乐园的成本。座位有多少，就需要等多少人，这就是 CountDownLatch 的核心思想，等到一个设定的数值达到之后，才能出发。 流程图 可以看到，最开始 CountDownLatch 设置的初始值为 3，然后 T0 线程上来就调用 await 方法，它的作用是让这个线程开始等待，等待后面的 T1、T2、T3，它们每一次调用 countDown 方法，3 这个数值就会减 1，也就是从 3 减到 2，从 2 减到 1，从 1 减到 0，一旦减到 0 之后，这个 T0 就相当于达到了自己触发继续运行的条件，于是它就恢复运行了。 主要方法介绍 （1）构造函数：public CountDownLatch(int count) { }; 它的构造函数是传入一个参数，该参数 count 是需要倒数的数值。 （2）await()：调用 await() 方法的线程开始等待，直到倒数结束，也就是 count 值为 0 的时候才会继续执行。 （3）await(long timeout, TimeUnit unit)：await() 有一个重载的方法，里面会传入超时参数，这个方法的作用和 await() 类似，但是这里可以设置超时时间，如果超时就不再等待了。 （4）countDown()：把数值倒数 1，也就是将 count 值减 1，直到减为 0 时，之前等待的线程会被唤起。 用法一：一个线程等待其他多个线程都执行完毕，再继续自己的工作 在实际场景中，很多情况下需要我们初始化一系列的前置条件（比如建立连接、准备数据），在这些准备条件都完成之前，是不能进行下一步工作的，所以这就是利用 CountDownLatch 的一个很好场景，我们可以让应用程序的主线程在其他线程都准备完毕之后再继续执行。 举个生活中的例子，那就是运动员跑步的场景，比如在比赛跑步时有 5 个运动员参赛，终点有一个裁判员，什么时候比赛结束呢？那就是当所有人都跑到终点之后，这相当于裁判员等待 5 个运动员都跑到终点，宣布比赛结束。我们用代码的形式来写出运动员跑步的场景，代码如下： 1234567891011121314151617181920212223242526public class RunDemo1 &#123; public static void main(String[] args) throws InterruptedException &#123; CountDownLatch latch = new CountDownLatch(5); ExecutorService service = Executors.newFixedThreadPool(5); for (int i = 0; i &lt; 5; i++) &#123; final int no = i + 1; Runnable runnable = new Runnable() &#123; @Override public void run() &#123; try &#123; Thread.sleep((long) (Math.random() * 10000)); System.out.println(no + \"号运动员完成了比赛。\"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; latch.countDown(); &#125; &#125; &#125;; service.submit(runnable); &#125; System.out.println(\"等待5个运动员都跑完.....\"); latch.await(); System.out.println(\"所有人都跑完了，比赛结束。\"); &#125;&#125; 程序的运行结果如下所示： 1234567等待5个运动员都跑完.....4号运动员完成了比赛。3号运动员完成了比赛。1号运动员完成了比赛。5号运动员完成了比赛。2号运动员完成了比赛。所有人都跑完了，比赛结束。 可以看出，直到 5 个运动员都完成了比赛之后，主线程才会继续，而且由于子线程等待的时间是随机的，所以各个运动员完成比赛的次序也是随机的。 用法二：多个线程等待某一个线程的信号，同时开始执行 这和第一个用法有点相反，我们再列举一个实际的场景，比如在运动会上，刚才说的是裁判员等运动员，现在是运动员等裁判员。在运动员起跑之前都会等待裁判员发号施令，一声令下运动员统一起跑，我们用代码把这件事情描述出来，如下所示： 1234567891011121314151617181920212223242526public class RunDemo2 &#123; public static void main(String[] args) throws InterruptedException &#123; System.out.println(\"运动员有5秒的准备时间\"); CountDownLatch countDownLatch = new CountDownLatch(1); ExecutorService service = Executors.newFixedThreadPool(5); for (int i = 0; i &lt; 5; i++) &#123; final int no = i + 1; Runnable runnable = new Runnable() &#123; @Override public void run() &#123; System.out.println(no + \"号运动员准备完毕，等待裁判员的发令枪\"); try &#123; countDownLatch.await(); System.out.println(no + \"号运动员开始跑步了\"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;; service.submit(runnable); &#125; Thread.sleep(5000); System.out.println(\"5秒准备时间已过，发令枪响，比赛开始！\"); countDownLatch.countDown(); &#125;&#125; 程序的运行结果如下： 123456789101112运动员有5秒的准备时间2号运动员准备完毕，等待裁判员的发令枪1号运动员准备完毕，等待裁判员的发令枪3号运动员准备完毕，等待裁判员的发令枪4号运动员准备完毕，等待裁判员的发令枪5号运动员准备完毕，等待裁判员的发令枪5秒准备时间已过，发令枪响，比赛开始！2号运动员开始跑步了1号运动员开始跑步了5号运动员开始跑步了4号运动员开始跑步了3号运动员开始跑步了 可以看到，运动员首先会有 5 秒钟的准备时间，然后 5 个运动员分别都准备完毕了，等待发令枪响，紧接着 5 秒之后，发令枪响，比赛开始，于是 5 个子线程几乎同时开始跑步了。 注意点 以上讲了两种用法，其实这两种用法并不是孤立的，甚至可以把这两种用法结合起来，比如利用两个 CountDownLatch，第一个初始值为多个，第二个初始值为 1，这样就可以应对更复杂的业务场景了； CountDownLatch 是不能够重用的，比如已经完成了倒数，那可不可以在下一次继续去重新倒数呢？这是做不到的，如果有这个需求的话，可以考虑使用 CyclicBarrier 或者创建一个新的 CountDownLatch 实例。 3.CyclicBarrier 和 CountdownLatch 有什么异同？CyclicBarrier作用 CyclicBarrier 和 CountDownLatch 确实有一定的相似性，它们都能阻塞一个或者一组线程，直到某种预定的条件达到之后，这些之前在等待的线程才会统一出发，继续向下执行。正因为它们有这个相似点，你可能会认为它们的作用是完全一样的，其实并不是。 CyclicBarrier 可以构造出一个集结点，当某一个线程执行 await() 的时候，它就会到这个集结点开始等待，等待这个栅栏被撤销。直到预定数量的线程都到了这个集结点之后，这个栅栏就会被撤销，之前等待的线程就在此刻统一出发，继续去执行剩下的任务。 举一个生活中的例子。假设我们班级春游去公园里玩，并且会租借三人自行车，每个人都可以骑，但由于这辆自行车是三人的，所以要凑齐三个人才能骑一辆，而且从公园大门走到自行车驿站需要一段时间。那么我们模拟这个场景，写出如下代码： 123456789101112131415161718192021222324252627282930public class CyclicBarrierDemo &#123; public static void main(String[] args) &#123; CyclicBarrier cyclicBarrier = new CyclicBarrier(3); for (int i = 0; i &lt; 6; i++) &#123; new Thread(new Task(i + 1, cyclicBarrier)).start(); &#125; &#125; static class Task implements Runnable &#123; private int id; private CyclicBarrier cyclicBarrier; public Task(int id, CyclicBarrier cyclicBarrier) &#123; this.id = id; this.cyclicBarrier = cyclicBarrier; &#125; @Override public void run() &#123; System.out.println(\"同学\" + id + \"现在从大门出发，前往自行车驿站\"); try &#123; Thread.sleep((long) (Math.random() * 10000)); System.out.println(\"同学\" + id + \"到了自行车驿站，开始等待其他人到达\"); cyclicBarrier.await(); System.out.println(\"同学\" + id + \"开始骑车\"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (BrokenBarrierException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; 在这段代码中可以看到，首先建了一个参数为 3 的 CyclicBarrier，参数为 3 的意思是需要等待 3 个线程到达这个集结点才统一放行；然后我们又在 for 循环中去开启了 6 个线程，每个线程中执行的 Runnable 对象就在下方的 Task 类中，直接看到它的 run 方法，它首先会打印出”同学某某现在从大门出发，前往自行车驿站”，然后是一个随机时间的睡眠，这就代表着从大门开始步行走到自行车驿站的时间，由于每个同学的步行速度不一样，所以时间用随机值来模拟。 当同学们都到了驿站之后，比如某一个同学到了驿站，首先会打印出“同学某某到了自行车驿站，开始等待其他人到达”的消息，然后去调用 CyclicBarrier 的 await() 方法。一旦它调用了这个方法，它就会陷入等待，直到三个人凑齐，才会继续往下执行，一旦开始继续往下执行，就意味着 3 个同学开始一起骑车了，所以打印出“某某开始骑车”这个语句。 程序运行结果如下所示： 123456789101112131415161718同学1现在从大门出发，前往自行车驿站同学3现在从大门出发，前往自行车驿站同学2现在从大门出发，前往自行车驿站同学4现在从大门出发，前往自行车驿站同学5现在从大门出发，前往自行车驿站同学6现在从大门出发，前往自行车驿站同学5到了自行车驿站，开始等待其他人到达同学2到了自行车驿站，开始等待其他人到达同学3到了自行车驿站，开始等待其他人到达同学3开始骑车同学5开始骑车同学2开始骑车同学6到了自行车驿站，开始等待其他人到达同学4到了自行车驿站，开始等待其他人到达同学1到了自行车驿站，开始等待其他人到达同学1开始骑车同学6开始骑车同学4开始骑车 可以看到 6 个同学纷纷从大门出发走到自行车驿站，因为每个人的速度不一样，所以会有 3 个同学先到自行车驿站，不过在这 3 个先到的同学里面，前面 2 个到的都必须等待第 3 个人到齐之后，才可以开始骑车。后面的同学也一样，由于第一辆车已经被骑走了，第二辆车依然也要等待 3 个人凑齐才能统一发车。 要想实现这件事情，如果你不利用 CyclicBarrier 去做的话，逻辑可能会非常复杂，因为你也不清楚哪个同学先到、哪个后到。而用了 CyclicBarrier 之后，可以非常简洁优雅的实现这个逻辑，这就是它的一个非常典型的应用场景。 执行动作 barrierAction public CyclicBarrier(int parties, Runnable barrierAction)：当 parties 线程到达集结点时，继续往下执行前，会执行这一次这个动作。 接下来我们再介绍一下它的一个额外功能，就是执行动作 barrierAction 功能。CyclicBarrier 还有一个构造函数是传入两个参数的，第一个参数依然是 parties，代表需要几个线程到齐；第二个参数是一个 Runnable 对象，它就是我们下面所要介绍的 barrierAction。 当预设数量的线程到达了集结点之后，在出发的时候，便会执行这里所传入的 Runnable 对象，那么假设我们把刚才那个代码的构造函数改成如下这个样子： 123456CyclicBarrier cyclicBarrier = new CyclicBarrier(3, new Runnable() &#123; @Override public void run() &#123; System.out.println(\"凑齐3人了，出发！\"); &#125;&#125;); 可以看出，我们传入了第二个参数，它是一个 Runnable 对象，在这里传入了这个 Runnable 之后，这个任务就会在到齐的时候去打印”凑齐3人了，出发！”。上面的代码如果改成这个样子，则执行结果如下所示： 1234567891011121314151617181920同学1现在从大门出发，前往自行车驿站同学3现在从大门出发，前往自行车驿站同学2现在从大门出发，前往自行车驿站同学4现在从大门出发，前往自行车驿站同学5现在从大门出发，前往自行车驿站同学6现在从大门出发，前往自行车驿站同学2到了自行车驿站，开始等待其他人到达同学4到了自行车驿站，开始等待其他人到达同学6到了自行车驿站，开始等待其他人到达凑齐3人了，出发！同学6开始骑车同学2开始骑车同学4开始骑车同学1到了自行车驿站，开始等待其他人到达同学3到了自行车驿站，开始等待其他人到达同学5到了自行车驿站，开始等待其他人到达凑齐3人了，出发！同学5开始骑车同学1开始骑车同学3开始骑车 可以看出，三个人凑齐了一组之后，就会打印出“凑齐 3 人了，出发！”这样的语句，该语句恰恰是我们在这边传入 Runnable 所执行的结果。 值得注意的是，这个语句每个周期只打印一次，不是说你有几个线程在等待就打印几次，而是说这个任务只在“开闸”的时候执行一次。 CyclicBarrier 和 CountDownLatch 的异同 相同点：都能阻塞一个或一组线程，直到某个预设的条件达成发生，再统一出发。 但是它们也有很多不同点，具体如下： 作用对象不同：CyclicBarrier 要等固定数量的线程都到达了栅栏位置才能继续执行，而 CountDownLatch 只需等待数字倒数到 0，也就是说 CountDownLatch 作用于事件，但 CyclicBarrier 作用于线程；CountDownLatch 是在调用了 countDown 方法之后把数字倒数减 1，而 CyclicBarrier 是在某线程开始等待后把计数减 1。 可重用性不同：CountDownLatch 在倒数到 0 并且触发门闩打开后，就不能再次使用了，除非新建一个新的实例；而 CyclicBarrier 可以重复使用，在刚才的代码中也可以看出，每 3 个同学到了之后都能出发，并不需要重新新建实例。CyclicBarrier 还可以随时调用 reset 方法进行重置，如果重置时有线程已经调用了 await 方法并开始等待，那么这些线程则会抛出 BrokenBarrierException 异常。 执行动作不同：CyclicBarrier 有执行动作 barrierAction，而 CountDownLatch 没这个功能。 4.Condition、object.wait() 和 notify() 的关系？Condition接口作用 我们假设线程 1 需要等待某些条件满足后，才能继续运行，这个条件会根据业务场景不同，有不同的可能性，比如等待某个时间点到达或者等待某些任务处理完毕。在这种情况下，我们就可以执行 Condition 的 await 方法，一旦执行了该方法，这个线程就会进入 WAITING 状态。 通常会有另外一个线程，我们把它称作线程 2，它去达成对应的条件，直到这个条件达成之后，那么，线程 2 调用 Condition 的 signal 方法 [或 signalAll 方法]，代表“这个条件已经达成了，之前等待这个条件的线程现在可以苏醒了”。这个时候，JVM 就会找到等待该 Condition 的线程，并予以唤醒，根据调用的是 signal 方法或 signalAll 方法，会唤醒 1 个或所有的线程。于是，线程 1 在此时就会被唤醒，然后它的线程状态又会回到 Runnable 可执行状态。 代码案例： 123456789101112131415161718192021222324252627282930313233343536373839public class ConditionDemo &#123; private ReentrantLock lock = new ReentrantLock(); private Condition condition = lock.newCondition(); void method1() throws InterruptedException &#123; lock.lock(); try&#123; System.out.println(Thread.currentThread().getName()+\":条件不满足，开始await\"); condition.await(); System.out.println(Thread.currentThread().getName()+\":条件满足了，开始执行后续的任务\"); &#125;finally &#123; lock.unlock(); &#125; &#125; void method2() throws InterruptedException &#123; lock.lock(); try&#123; System.out.println(Thread.currentThread().getName()+\":需要5秒钟的准备时间\"); Thread.sleep(5000); System.out.println(Thread.currentThread().getName()+\":准备工作完成，唤醒其他的线程\"); condition.signal(); &#125;finally &#123; lock.unlock(); &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; ConditionDemo conditionDemo = new ConditionDemo(); new Thread(new Runnable() &#123; @Override public void run() &#123; try &#123; conditionDemo.method2(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;).start(); conditionDemo.method1(); &#125;&#125; 程序运行结果如下所示： 1234main:条件不满足，开始 awaitThread-0:需要 5 秒钟的准备时间Thread-0:准备工作完成，唤醒其他的线程main:条件满足了，开始执行后续的任务 Condition 注意点 线程 2 解锁后，线程 1 才能获得锁并继续执行：线程 2 对应刚才代码中的子线程，而线程 1 对应主线程。这里需要额外注意，并不是说子线程调用了 signal 之后，主线程就可以立刻被唤醒去执行下面的代码了，而是说在调用了 signal 之后，还需要等待子线程完全退出这个锁，即执行 unlock 之后，这个主线程才有可能去获取到这把锁，并且当获取锁成功之后才能继续执行后面的任务。刚被唤醒的时候主线程还没有拿到锁，是没有办法继续往下执行的。 signalAll() 和 signal() 区别：signalAll() 会唤醒所有正在等待的线程，而 signal() 只会唤醒一个线程。 Condition 和 wait/notify的关系 如果说 Lock 是用来代替 synchronized 的，那么 Condition 就是用来代替相对应的 Object 的 wait/notify/notifyAll，所以在用法和性质上几乎都一样。 Condition 把 Object 的 wait/notify/notifyAll 转化为了一种相应的对象，其实现的效果基本一样，但是把更复杂的用法，变成了更直观可控的对象方法，是一种升级。 await 方法会自动释放持有的 Lock 锁，和 Object 的 wait 一样，不需要自己手动释放锁。 另外，调用 await 的时候必须持有锁，否则会抛出异常，这一点和 Object 的 wait 一样。","tags":[{"name":"java","slug":"java","permalink":"https://sunshine-zwq.gitee.io/tags/java/"},{"name":"并发编程","slug":"并发编程","permalink":"https://sunshine-zwq.gitee.io/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"},{"name":"面试","slug":"面试","permalink":"https://sunshine-zwq.gitee.io/tags/%E9%9D%A2%E8%AF%95/"}]},{"title":"Java并发编程常见问题-Future与Callable","date":"2020-12-18T08:02:27.000Z","path":"2020/12/18/Java并发编程常见问题-Future与Callable/","text":"1.Callable 和 Runnable 的不同？Runnable 的缺陷 (1).不能返回值 对于 Runnable 而言，它不能返回一个返回值，虽然可以利用其他的一些办法，比如在 Runnable 方法中写入日志文件或者修改某个共享的对象的办法，来达到保存线程执行结果的目的，但这种解决问题的行为千曲百折，属于曲线救国，效率着实不高。 实际上，在很多情况下执行一个子线程时，我们都希望能得到执行的任务的结果，也就是说，我们是需要得到返回值的，比如请求网络、查询数据库等，可是 Runnable 不能返回一个返回值。 (2).不能抛出 checked Exception 如下面这段代码所示： 1234567891011121314151617181920212223public class RunThrowException &#123; /** * 普通方法内可以 throw 异常，并在方法签名上声明 throws */ public void normalMethod() throws Exception &#123; throw new IOException(); &#125; Runnable runnable = new Runnable() &#123; /** * run方法上无法声明 throws 异常，且run方法内无法 throw 出 checked Exception，除非使用try catch进行处理 */ @Override public void run() &#123; try &#123; throw new IOException(); &#125; catch (IOException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; 在这段代码中，有两个方法，第一个方法是一个普通的方法，叫作 normalMethod，可以看到，在它的方法签名中有 throws Exception，并且在它的方法内也 throw 了一个 new IOException()。 然后在下面的的代码中，我们新建了一个 Runnable 对象，同时重写了它的 run 方法，我们没有办法在这个 run 方法的方法签名上声明 throws 一个异常出来。同时，在这个 run 方法里面也没办法 throw 一个 checked Exception，除非如代码所示，用 try catch 包裹起来，但是如果不用 try catch 是做不到的。 为什么有这样的缺陷 来看一下 Runnable 接口的定义： 123public interface Runnable &#123; public abstract void run();&#125; 代码比较短小，Runnable 是一个 interface，并且里面只有一个方法，叫作 public abstract void run()。这个方法已经规定了 run() 方法的返回类型是 void，而且这个方法没有声明抛出任何异常。所以，当实现并重写这个方法时，我们既不能改返回值类型，也不能更改对于异常抛出的描述，因为在实现方法的时候，语法规定是不允许对这些内容进行修改的。 Callable 接口 Callable 是一个类似于 Runnable 的接口，实现 Callable 接口的类和实现 Runnable 接口的类都是可以被其他线程执行的任务。 我们看一下 Callable 的源码： 123public interface Callable&lt;V&gt; &#123; V call() throws Exception;&#125; 可以看出它也是一个 interface，并且它的 call 方法中已经声明了 throws Exception，前面还有一个 V 泛型的返回值，这就和之前的 Runnable 有很大的区别。实现 Callable 接口，就要实现 call 方法，这个方法的返回值是泛型 V，如果把 call 中计算得到的结果放到这个对象中，就可以利用 call 方法的返回值来获得子线程的执行结果了。 Callable 和 Runnable 的不同之处 方法名，Callable 规定的执行方法是 call()，而 Runnable 规定的执行方法是 run()； 返回值，Callable 的任务执行后有返回值，而 Runnable 的任务执行后是没有返回值的； 抛出异常，call() 方法可抛出异常，而 run() 方法是不能抛出受检查异常的； 和 Callable 配合的有一个 Future 类，通过 Future 可以了解任务执行情况，或者取消任务的执行，还可获取任务执行的结果，这些功能都是 Runnable 做不到的，Callable 的功能要比 Runnable 强大。 2.Future 的主要功能是什么？Future 的作用 Future 最主要的作用是，比如当做一定运算的时候，运算过程可能比较耗时，有时会去查数据库，或是繁重的计算，比如压缩、加密等，在这种情况下，如果我们一直在原地等待方法返回，显然是不明智的，整体程序的运行效率会大大降低。我们可以把运算的过程放到子线程去执行，再通过 Future 去控制子线程执行的计算过程，最后获取到计算结果。这样一来就可以把整个程序的运行效率提高，是一种异步的思想。 Callable 和 Future 的关系 Callable 接口相比于 Runnable 的一大优势是可以有返回结果，那这个返回结果怎么获取呢？就可以用 Future 类的 get 方法来获取 。因此，Future 相当于一个存储器，它存储了 Callable 的 call 方法的任务结果。除此之外，我们还可以通过 Future 的 isDone 方法来判断任务是否已经执行完毕了，还可以通过 cancel 方法取消这个任务，或限时获取任务的结果等，总之 Future 的功能比较丰富。 Future 的方法和用法 Future 接口的代码，一共有 5 个方法，代码如下所示： 12345678public interface Future&lt;V&gt; &#123; boolean cancel(boolean mayInterruptIfRunning); boolean isCancelled(); boolean isDone(); V get() throws InterruptedException, ExecutionException; V get(long timeout, TimeUnit unit) throws InterruptedException, ExecutionException, TimeoutException&#125; get() 方法：获取结果 get 方法最主要的作用就是获取任务执行的结果，该方法在执行时的行为取决于 Callable 任务的状态，可能会发生以下 5 种情况。 （1）最常见的就是当执行 get 的时候，任务已经执行完毕了，可以立刻返回，获取到任务执行的结果。 （2）任务还没有结果，这是有可能的，比如我们往线程池中放一个任务，线程池中可能积压了很多任务，还没轮到我去执行的时候，就去 get 了，在这种情况下，相当于任务还没开始；还有一种情况是任务正在执行中，但是执行过程比较长，所以我去 get 的时候，它依然在执行的过程中。无论是任务还没开始或在进行中，我们去调用 get 的时候，都会把当前的线程阻塞，直到任务完成再把结果返回回来。 （3）任务执行过程中抛出异常，一旦这样，我们再去调用 get 的时候，就会抛出 ExecutionException 异常，不管我们执行 call 方法时里面抛出的异常类型是什么，在执行 get 方法时所获得的异常都是 ExecutionException。 （4）任务被取消了，如果任务被取消，我们用 get 方法去获取结果时则会抛出 CancellationException。 （5）任务超时，我们知道 get 方法有一个重载方法，那就是带延迟参数的，调用了这个带延迟参数的 get 方法之后，如果 call 方法在规定时间内正常顺利完成了任务，那么 get 会正常返回；但是如果到达了指定时间依然没有完成任务，get 方法则会抛出 TimeoutException，代表超时了。 下面用图的形式让过程更清晰： 在图中，右侧是一个线程池，线程池中有一些线程来执行任务。重点在图的左侧，可以看到有一个 submit 方法，该方法往线程池中提交了一个 Task，这个 Task 实现了 Callable 接口，当我们去给线程池提交这个任务的时候，调用 submit 方法会立刻返回一个 Future 类型的对象，这个对象目前内容是空的，其中还不包含计算结果，因为此时计算还没有完成。 当计算一旦完成时，也就是当我们可以获取结果的时候，线程池便会把这个结果填入到之前返回的 Future 中去（也就是 f 对象），而不是在此时新建一个新的 Future。这时就可以利用 Future 的 get 方法来获取到任务的执行结果了。 一个代码示例： 123456789101112131415161718192021222324/** * 描述： 演示一个 Future 的使用方法 */public class OneFuture &#123; public static void main(String[] args) &#123; ExecutorService service = Executors.newFixedThreadPool(10); Future&lt;Integer&gt; future = service.submit(new CallableTask()); try &#123; System.out.println(future.get()); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (ExecutionException e) &#123; e.printStackTrace(); &#125; service.shutdown(); &#125; static class CallableTask implements Callable&lt;Integer&gt; &#123; @Override public Integer call() throws Exception &#123; Thread.sleep(3000); return new Random().nextInt(); &#125; &#125;&#125; 在这段代码中，main 方法新建了一个 10 个线程的线程池，并且用 submit 方法把一个任务提交进去。这个任务如代码的最下方所示，它实现了 Callable 接口，它所做的内容就是先休眠三秒钟，然后返回一个随机数。接下来我们就直接把 future.get 结果打印出来，其结果是正常打印出一个随机数，比如 100192 等。这段代码对应了我们刚才那个图示的讲解，这也是 Future 最常用的一种用法。 isDone() 方法：判断是否执行完毕 下面我们再接着看看 Future 的一些其他方法，比如说 isDone() 方法，该方法是用来判断当前这个任务是否执行完毕了。 需要注意的是，这个方法如果返回 true 则代表执行完成了；如果返回 false 则代表还没完成。但这里如果返回 true，并不代表这个任务是成功执行的，比如说任务执行到一半抛出了异常。那么在这种情况下，对于这个 isDone 方法而言，它其实也是会返回 true 的，因为对它来说，虽然有异常发生了，但是这个任务在未来也不会再被执行，它确实已经执行完毕了。所以 isDone 方法在返回 true 的时候，不代表这个任务是成功执行的，只代表它执行完毕了。 我们用一个代码示例来看一看，代码如下所示： 123456789101112131415161718192021222324public class GetException &#123; public static void main(String[] args) &#123; ExecutorService service = Executors.newFixedThreadPool(20); Future&lt;Integer&gt; future = service.submit(new CallableTask()); try &#123; for (int i = 0; i &lt; 5; i++) &#123; System.out.println(i); Thread.sleep(500); &#125; System.out.println(future.isDone()); future.get(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (ExecutionException e) &#123; e.printStackTrace(); &#125; &#125; static class CallableTask implements Callable&lt;Integer&gt; &#123; @Override public Integer call() throws Exception &#123; throw new IllegalArgumentException(\"Callable抛出异常\"); &#125; &#125;&#125; 在这段代码中，可以看到有一个线程池，并且往线程池中去提交任务，这个任务会直接抛出一个异常。那么接下来我们就用一个 for 循环去休眠，同时让它慢慢打印出 0 ~ 4 这 5 个数字，这样做的目的是起到了一定的延迟作用。在这个执行完毕之后，再去调用 isDone() 方法，并且把这个结果打印出来，然后再去调用 future.get()。 这段代码的执行结果是这样的： 1234567801234truejava.util.concurrent.ExecutionException: java.lang.IllegalArgumentException: Callable抛出异常... 这里要注意，这个异常实际上是在任务刚被执行的时候就抛出了，因为计算任务中是没有其他逻辑的，只有抛出异常。我们再来看，控制台是什么时候打印出异常的呢？它是在 true 打印完毕后才打印出异常信息的，也就是说，在调用 get 方法时打印出的异常。 这段代码证明了三件事情：第一件事情，即便任务抛出异常，isDone 方法依然会返回 true；第二件事情，虽然抛出的异常是 IllegalArgumentException，但是对于 get 而言，它抛出的异常依然是 ExecutionException；第三个事情，虽然在任务执行一开始时就抛出了异常，但是真正要等到我们执行 get 的时候，才看到了异常。 cancel 方法：取消任务的执行 下面我们再来看一下 cancel 方法，如果不想执行某个任务了，则可以使用 cancel 方法，会有以下三种情况： 第一种情况最简单，那就是当任务还没有开始执行时，一旦调用 cancel，这个任务就会被正常取消，未来也不会被执行，那么 cancel 方法返回 true。 第二种情况也比较简单。如果任务已经完成，或者之前已经被取消过了，那么执行 cancel 方法则代表取消失败，返回 false。因为任务无论是已完成还是已经被取消过了，都不能再被取消了。 第三种情况比较特殊，就是这个任务正在执行，这个时候执行 cancel 方法是不会直接取消这个任务的，而是会根据我们传入的参数做判断。cancel 方法是必须传入一个参数，该参数叫作 mayInterruptIfRunning，它是什么含义呢？如果传入的参数是 true，执行任务的线程就会收到一个中断的信号，正在执行的任务可能会有一些处理中断的逻辑，进而停止，这个比较好理解。如果传入的是 false 则就代表不中断正在运行的任务，也就是说，本次 cancel 不会有任何效果，同时 cancel 方法会返回 false。 那么如何选择传入 true 还是 false 呢？ 传入 true 适用的情况是，明确知道这个任务能够处理中断。 传入 false 适用于什么情况呢？ 如果我们明确知道这个线程不能处理中断，那应该传入 false。 我们不知道这个任务是否支持取消（是否能响应中断），因为在大多数情况下代码是多人协作的，对于这个任务是否支持中断，我 不一定有十足的把握，那么在这种情况下也应该传入 false。 如果这个任务一旦开始运行，我们就希望它完全的执行完毕。在这种情况下，也应该传入 false。 isCancelled() 方法：判断是否被取消 最后一个方法是 isCancelled 方法，判断是否被取消，它和 cancel 方法配合使用，比较简单。 用 FutureTask 来创建 Future 除了用线程池的 submit 方法会返回一个 future 对象之外，同样还可以用 FutureTask 来获取 Future 类和任务的结果。 FutureTask 首先是一个任务（Task），然后具有 Future 接口的语义，因为它可以在将来（Future）得到执行的结果。 我们来看一下 FutureTask 的代码实现： 123public class FutureTask&lt;V&gt; implements RunnableFuture&lt;V&gt;&#123; ...&#125; 可以看到，它实现了一个接口，这个接口叫作 RunnableFuture。我们再来看一下 RunnableFuture 接口的代码实现： 123public interface RunnableFuture&lt;V&gt; extends Runnable, Future&lt;V&gt; &#123; void run();&#125; 可以看出，它是 extends Runnable 和 Future 这两个接口的，它们的关系如下图所示： 既然 RunnableFuture 继承了 Runnable 接口和 Future 接口，而 FutureTask 又实现了 RunnableFuture 接口，所以 FutureTask 既可以作为 Runnable 被线程执行，又可以作为 Future 得到 Callable 的返回值。 典型用法是，把 Callable 实例当作 FutureTask 构造函数的参数，生成 FutureTask 的对象，然后把这个对象当作一个 Runnable 对象，放到线程池中或另起线程去执行，最后还可以通过 FutureTask 获取任务执行的结果。 下面用代码来演示一下： 12345678910111213141516171819202122232425262728/** * 描述： 演示 FutureTask 的用法 */public class FutureTaskDemo &#123; public static void main(String[] args) &#123; Task task = new Task(); FutureTask&lt;Integer&gt; integerFutureTask = new FutureTask&lt;&gt;(task); new Thread(integerFutureTask).start(); try &#123; System.out.println(\"task运行结果：\"+integerFutureTask.get()); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (ExecutionException e) &#123; e.printStackTrace(); &#125; &#125;&#125;class Task implements Callable&lt;Integer&gt; &#123; @Override public Integer call() throws Exception &#123; System.out.println(\"子线程正在计算\"); int sum = 0; for (int i = 0; i &lt; 100; i++) &#123; sum += i; &#125; return sum; &#125;&#125; 在这段代码中可以看出，首先创建了一个实现了 Callable 接口的 Task，然后把这个 Task 实例传入到 FutureTask 的构造函数中去，创建了一个 FutureTask 实例，并且把这个实例当作一个 Runnable 放到 new Thread() 中去执行，最后再用 FutureTask 的 get 得到结果，并打印出来。 执行结果是 4950，正是任务里 0+1+2+…+99 的结果。 3.使用 Future 有哪些注意点？Future 产生新的线程了吗？Future 的注意点 (1).当 for 循环批量获取 Future 的结果时容易 block，get 方法调用时应使用 timeout 限制 假设一共有四个任务需要执行，我们都把它放到线程池中，然后它获取的时候是按照从 1 到 4 的顺序，也就是执行 get() 方法来获取的，代码如下所示： 123456789101112131415161718192021222324252627282930313233343536373839404142public class FutureDemo &#123; public static void main(String[] args) &#123; //创建线程池 ExecutorService service = Executors.newFixedThreadPool(10); //提交任务，并用 Future 接收返回结果 ArrayList&lt;Future&gt; allFutures = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; 4; i++) &#123; Future&lt;String&gt; future; if (i == 0 || i == 1) &#123; future = service.submit(new SlowTask()); &#125; else &#123; future = service.submit(new FastTask()); &#125; allFutures.add(future); &#125; for (int i = 0; i &lt; 4; i++) &#123; Future&lt;String&gt; future = allFutures.get(i); try &#123; String result = future.get(); System.out.println(result); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (ExecutionException e) &#123; e.printStackTrace(); &#125; &#125; service.shutdown(); &#125; static class SlowTask implements Callable&lt;String&gt; &#123; @Override public String call() throws Exception &#123; Thread.sleep(5000); return \"速度慢的任务\"; &#125; &#125; static class FastTask implements Callable&lt;String&gt; &#123; @Override public String call() throws Exception &#123; return \"速度快的任务\"; &#125; &#125;&#125; 在代码中我们新建了线程池，并且用一个 list 来保存 4 个 Future。其中，前两个 Future 所对应的任务是慢任务，也就是代码下方的 SlowTask，而后两个 Future 对应的任务是快任务。慢任务在执行的时候需要 5 秒钟的时间才能执行完毕，而快任务很快就可以执行完毕，几乎不花费时间。 在提交完这 4 个任务之后，我们用 for 循环对它们依次执行 get 方法，来获取它们的执行结果，然后再把这个结果打印出来。 执行结果如下： 1234速度慢的任务速度慢的任务速度快的任务速度快的任务 这个执行结果是打印 4 行语句，前面两个是速度慢的任务，后面两个是速度快的任务。虽然结果是正确的，但实际上在执行的时候会先等待 5 秒，然后再很快打印出这 4 行语句。 这里有一个问题，即第三个的任务量是比较小的，它可以很快返回结果，紧接着第四个任务也会返回结果。但是由于前两个任务速度很慢，所以我们在利用 get 方法执行时，会卡在第一个任务上。也就是说，虽然此时第三个和第四个任务很早就得到结果了，但我们在此时使用这种 for 循环的方式去获取结果，依然无法及时获取到第三个和第四个任务的结果。直到 5 秒后，第一个任务出结果了，我们才能获取到，紧接着也可以获取到第二个任务的结果，然后才轮到第三、第四个任务。 假设由于网络原因，第一个任务可能长达 1 分钟都没办法返回结果，那么这个时候，我们的主线程会一直卡着，影响了程序的运行效率。 此时我们就可以用 Future 的带超时参数的 get(long timeout, TimeUnit unit) 方法来解决这个问题。这个方法的作用是，如果在限定的时间内没能返回结果的话，那么便会抛出一个 TimeoutException 异常，随后就可以把这个异常捕获住，或者是再往上抛出去，这样就不会一直卡着了。 (2).Future 的生命周期不能后退 Future 的生命周期不能后退，一旦完成了任务，它就永久停在了“已完成”的状态，不能从头再来，也不能让一个已经完成计算的 Future 再次重新执行任务。 Future 产生新的线程了吗 有一种说法是，除了继承 Thread 类和实现 Runnable 接口之外，还有第三种产生新线程的方式，那就是采用 Callable 和 Future，这叫作有返回值的创建线程的方式。这种说法是不正确的。 其实 Callable 和 Future 本身并不能产生新的线程，它们需要借助其他的比如 Thread 类或者线程池才能执行任务。例如，在把 Callable 提交到线程池后，真正执行 Callable 的其实还是线程池中的线程，而线程池中的线程是由 ThreadFactory 产生的，这里产生的新线程与 Callable、Future 都没有关系，所以 Future 并没有产生新的线程。","tags":[{"name":"java","slug":"java","permalink":"https://sunshine-zwq.gitee.io/tags/java/"},{"name":"并发编程","slug":"并发编程","permalink":"https://sunshine-zwq.gitee.io/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"},{"name":"面试","slug":"面试","permalink":"https://sunshine-zwq.gitee.io/tags/%E9%9D%A2%E8%AF%95/"}]},{"title":"Java并发编程常见问题-ThreadLocal","date":"2020-12-18T05:14:03.000Z","path":"2020/12/18/Java并发编程常见问题-ThreadLocal/","text":"1.ThreadLocal 适合用在哪些实际生产的场景中？在通常的业务开发中，ThreadLocal 有两种典型的使用场景。 场景1，ThreadLocal 用作保存每个线程独享的对象，为每个线程都创建一个副本，这样每个线程都可以修改自己所拥有的副本, 而不会影响其他线程的副本，确保了线程安全。 场景2，ThreadLocal 用作每个线程内需要独立保存信息，以便供其他方法更方便地获取该信息的场景。每个线程获取到的信息可能都是不一样的，前面执行的方法保存了信息后，后续方法可以通过 ThreadLocal 直接获取到，避免了传参，类似于全局变量的概念。 典型场景1 通常用于保存线程不安全的工具类，典型的需要使用的类就是 SimpleDateFormat。 场景介绍 在这种情况下，每个 Thread 内都有自己的实例副本，且该副本只能由当前 Thread 访问到并使用，相当于每个线程内部的本地变量，这也是 ThreadLocal 命名的含义。因为每个线程独享副本，而不是公用的，所以不存在多线程间共享的问题。 (1).所有的线程都共用一个 simpleDateFormat 对象 123456789101112131415161718192021public class ThreadLocalDemo04 &#123; public static ExecutorService threadPool = Executors.newFixedThreadPool(16); static SimpleDateFormat dateFormat = new SimpleDateFormat(\"mm:ss\"); public static void main(String[] args) throws InterruptedException &#123; for (int i = 0; i &lt; 1000; i++) &#123; int finalI = i; threadPool.submit(new Runnable() &#123; @Override public void run() &#123; String date = new ThreadLocalDemo04().date(finalI); System.out.println(date); &#125; &#125;); &#125; threadPool.shutdown(); &#125; public String date(int seconds) &#123; Date date = new Date(1000 * seconds); return dateFormat.format(date); &#125;&#125; 运行结果： 1234567800:0400:0400:0500:04...16:1516:1416:13 从打印结果可以看出，线程不安全，出现了并发安全问题。 从图中可以看出，我们有不同的线程，并且线程会执行它们的任务。但是不同的任务所调用的 simpleDateFormat 对象都是同一个，所以它们所指向的那个对象都是同一个，但是这样一来就会有线程不安全的问题。 (2).使用 ThreadLocal 1234567891011121314151617181920212223242526272829public class ThreadLocalDemo06 &#123; public static ExecutorService threadPool = Executors.newFixedThreadPool(16); public static void main(String[] args) throws InterruptedException &#123; for (int i = 0; i &lt; 1000; i++) &#123; int finalI = i; threadPool.submit(new Runnable() &#123; @Override public void run() &#123; String date = new ThreadLocalDemo06().date(finalI); System.out.println(date); &#125; &#125;); &#125; threadPool.shutdown(); &#125; public String date(int seconds) &#123; Date date = new Date(1000 * seconds); SimpleDateFormat dateFormat = ThreadSafeFormatter.dateFormatThreadLocal.get(); return dateFormat.format(date); &#125;&#125;class ThreadSafeFormatter &#123; public static ThreadLocal&lt;SimpleDateFormat&gt; dateFormatThreadLocal = new ThreadLocal&lt;SimpleDateFormat&gt;() &#123; @Override protected SimpleDateFormat initialValue() &#123; return new SimpleDateFormat(\"mm:ss\"); &#125; &#125;;&#125; 在这段代码中，我们使用了 ThreadLocal 帮每个线程去生成它自己的 simpleDateFormat 对象，对于每个线程而言，这个对象是独享的。代码运行结果如下： 123456700:0500:0400:01...16:3716:3616:32 这个结果是正确的，不会出现重复的时间。 我们用图来看一下当前的这种状态： 在图中的左侧可以看到，这个线程池一共有 16 个线程，对应 16 个 simpleDateFormat 对象。而在这个图画的右侧是 1000 个任务，任务是非常多的，和原来一样有 1000 个任务。在不使用 ThreadLocal 或 synchronized 确保线程安全情况下，就只能选择每个线程新建一个 simpleDateFormat 示例，而这里最大的变化就是，虽然任务有 1000 个，但是我们不需要去创建 1000 个 simpleDateFormat 对象了。即便任务再多，最终也只会有和线程数相同的 simpleDateFormat 对象。这样既高效地使用了内存，又同时保证了线程安全。 典型场景2 每个线程内需要保存类似于全局变量的信息（例如在拦截器中获取的用户信息），可以让不同方法直接使用，避免参数传递的麻烦却不想被多线程共享（因为不同线程获取到的用户信息不一样）。 例如，用 ThreadLocal 保存一些业务内容（用户权限信息、从用户系统获取到的用户名、用户ID 等），这些信息在同一个线程内相同，但是不同的线程使用的业务内容是不相同的。 在线程生命周期内，都通过这个静态 ThreadLocal 实例的 get() 方法取得自己 set 过的那个对象，避免了将这个对象（如 user 对象）作为参数传递的麻烦。 我们用图画的形式举一个实例： 比如说我们是一个用户系统。假设不使用 ThreadLocal，那么当一个请求进来的时候，一个线程会负责执行这个请求，然后这个请求就会依次调用 service-1()、service-2()、service-3()、service-4()，这 4 个方法可能是分布在不同的类中的。 在 service-1() 的时候它会创建一个 user 的对象，用于保存比如说这个用户的用户名等信息，后面 service-2/3/4() 都需要用到这个对象的信息，比如说 service-2() 代表下订单、service-3() 代表发货、service-4() 代表完结订单，在这种情况下，每一个方法都需要用户信息，所以就需要把这个 user 对象层层传递下去，从 service-1() 传到 service-2()，再从 service-2() 传到 service-3()，以此类推。 这样做会导致代码非常冗余，那有没有什么办法可以解决这个问题呢？我们首先想到的方法就是使用一个 HashMap，如下图所示： 比如说我们使用了这样的 Map 之后，就不需要把 user 对象层层传递了，而是在执行 service-1() 的时候，把这个用户信息给 put 进去，然后后面需要拿用户信息的时候，直接从静态的 User map 里面 get 就可以了。这样一来，无论你执行哪个方法，都可以直接获取到这个用户信息。当然，我们也要考虑到 web 服务器通常都是多线程的，当多个线程同时工作的时候，我们也需要保证线程安全。 所以在这里，如果我们使用 HashMap 是不够的，因为它是线程不安全的，那我们就可以使用 synchronized，或者直接把 HashMap 替换成 ConcurrentHashMap，用类似的方法来保证线程安全，这样的改进如下图所示： 在这个图中，可以看出有两个线程，并且每个线程所做的事情都是访问 service-1/2/3/4()。那么当它们同时运行的时候，都会同时访问这个 User map，于是就需要 User map 是线程安全的。 无论我们使用 synchronized 还是使用 ConcurrentHashMap，它对性能都是有所影响的，因为即便是使用性能比较好的 ConcurrentHashMap，它也是包含少量的同步，或者是 cas 等过程。相比于完全没有同步，它依然是有性能损耗的。所以在此一个更好的办法就是使用 ThreadLocal。 这样一来，我们就可以在不影响性能的情况下，也无需层层传递参数，就可以达到保存当前线程所对应的用户信息的目的。如下图所示： 在这个图中可以看出，同样是多个线程同时去执行，但是这些线程同时去访问这个 ThreadLocal 并且能利用 ThreadLocal 拿到只属于自己的独享对象。这样的话，就无需任何额外的措施，保证了线程安全，因为每个线程是独享 user 对象的。代码如下所示： 1234567891011121314151617181920212223242526272829303132333435public class ThreadLocalDemo07 &#123; public static void main(String[] args) &#123; new Service1().service1(); &#125;&#125;class Service1 &#123; public void service1() &#123; User user = new User(\"张三\"); UserContextHolder.holder.set(user); new Service2().service2(); &#125;&#125;class Service2 &#123; public void service2() &#123; User user = UserContextHolder.holder.get(); System.out.println(\"Service2拿到用户名：\" + user.name); new Service3().service3(); &#125;&#125;class Service3 &#123; public void service3() &#123; User user = UserContextHolder.holder.get(); System.out.println(\"Service3拿到用户名：\" + user.name); UserContextHolder.holder.remove(); &#125;&#125;class UserContextHolder &#123; public static ThreadLocal&lt;User&gt; holder = new ThreadLocal&lt;&gt;();&#125;class User &#123; String name; public User(String name) &#123; this.name = n &#125;&#125; 在这个代码中我们可以看出，我们有一个 UserContextHolder，里面保存了一个 ThreadLocal，在调用 Service1 的方法的时候，就往里面存入了 user 对象，而在后面去调用的时候，直接从里面用 get 方法取出来就可以了。没有参数层层传递的过程，非常的优雅、方便。 代码运行结果： 12Service2拿到用户名：张三Service3拿到用户名：张三 2.ThreadLocal 是用来解决共享资源的多线程访问的问题吗？这道题的答案很明确——不是，ThreadLocal 并不是用来解决共享资源问题的。虽然 ThreadLocal 确实可以用于解决多线程情况下的线程安全问题，但其资源并不是共享的，而是每个线程独享的。所以这道题其实是有一定陷阱成分在内的。 ThreadLocal 解决线程安全问题的时候，相比于使用“锁”而言，换了一个思路，把资源变成了各线程独享的资源，非常巧妙地避免了同步操作。具体而言，它可以在 initialValue 中 new 出自己线程独享的资源，而多个线程之间，它们所访问的对象本身是不共享的，自然就不存在任何并发问题。这是 ThreadLocal 解决并发问题的最主要思路。 如果我们把放到 ThreadLocal 中的资源用 static 修饰，让它变成一个共享资源的话，那么即便使用了 ThreadLocal，同样也会有线程安全问题。比如我们对上面的例子进行改造，如果我们在 SimpleDateFormat 之前加上一个 static 关键字来修饰，并且把这个静态对象放到 ThreadLocal 中去存储的话，代码如下所示： 123456789101112131415161718192021222324252627282930public class ThreadLocalStatic &#123; public static ExecutorService threadPool = Executors.newFixedThreadPool(16); static SimpleDateFormat dateFormat = new SimpleDateFormat(\"mm:ss\"); public static void main(String[] args) throws InterruptedException &#123; for (int i = 0; i &lt; 1000; i++) &#123; int finalI = i; threadPool.submit(new Runnable() &#123; @Override public void run() &#123; String date = new ThreadLocalStatic().date(finalI); System.out.println(date); &#125; &#125;); &#125; threadPool.shutdown(); &#125; public String date(int seconds) &#123; Date date = new Date(1000 * seconds); SimpleDateFormat dateFormat = ThreadSafeFormatter.dateFormatThreadLocal.get(); return dateFormat.format(date); &#125;&#125;class ThreadSafeFormatter &#123; public static ThreadLocal&lt;SimpleDateFormat&gt; dateFormatThreadLocal = new ThreadLocal&lt;SimpleDateFormat&gt;() &#123; @Override protected SimpleDateFormat initialValue() &#123; return ThreadLocalStatic.dateFormat; &#125; &#125;&#125; 那么在多线程中去获取这个资源并且同时使用的话，同样会出现时间重复的问题，运行结果如下： 1234500:1500:1500:0500:16... 可以看出，00:15 被多次打印了，发生了线程安全问题。也就是说，如果我们需要放到 ThreadLocal 中的这个对象是共享的，是被 static 修饰的，那么此时其实根本就不需要用到 ThreadLocal，即使用了 ThreadLocal 并不能解决线程安全问题。 相反，我们对于这种共享的变量，如果想要保证它的线程安全，应该用其他的方法，比如说可以使用 synchronized 或者是加锁等其他的方法来解决线程安全问题，而不是使用 ThreadLocal，因为这不是 ThreadLocal 应该使用的场景。 ThreadLocal 和 synchronized 是什么关系 当 ThreadLocal 用于解决线程安全问题的时候，也就是把一个对象给每个线程都生成一份独享的副本的，在这种场景下，ThreadLocal 和 synchronized 都可以理解为是用来保证线程安全的手段。但是效果和实现原理不同： ThreadLocal 是通过让每个线程独享自己的副本，避免了资源的竞争。 synchronized 主要用于临界资源的分配，在同一时刻限制最多只有一个线程能访问该资源。 相比于 ThreadLocal 而言，synchronized 的效率会更低一些，但是花费的内存也更少。在这种场景下，ThreadLocal 和 synchronized 虽然有不同的效果，不过都可以达到线程安全的目的。 但是对于 ThreadLocal 而言，它还有不同的使用场景。比如当 ThreadLocal 用于让多个类能更方便地拿到我们希望给每个线程独立保存这个信息的场景下时（比如每个线程都会对应一个用户信息，也就是 user 对象），在这种场景下，ThreadLocal 侧重的是避免传参，所以此时 ThreadLocal 和 synchronized 是两个不同维度的工具。 3.多个 ThreadLocal 在 Thread 中的 threadlocals 里是怎么存储的？Thread、 ThreadLocal 及 ThreadLocalMap 三者之间的关系 我们看到最左下角的 Thread 1，这是一个线程，它的箭头指向了 ThreadLocalMap 1，其要表达的意思是，每个 Thread 对象中都持有一个 ThreadLocalMap 类型的成员变量，在这里 Thread 1 所拥有的成员变量就是 ThreadLocalMap 1。 而这个 ThreadLocalMap 自身类似于是一个 Map，里面会有一个个 key value 形式的键值对。那么我们就来看一下它的 key 和 value 分别是什么。可以看到这个表格的左侧是 ThreadLocal 1、ThreadLocal 2…… ThreadLocal n，能看出这里的 key 就是 ThreadLocal 的引用。 而在表格的右侧是一个一个的 value，这就是我们希望 ThreadLocal 存储的内容，例如 user 对象等。 这里需要重点看到它们的数量对应关系：一个 Thread 里面只有一个ThreadLocalMap ，而在一个 ThreadLocalMap 里面却可以有很多的 ThreadLocal，每一个 ThreadLocal 都对应一个 value。因为一个 Thread 是可以调用多个 ThreadLocal 的，所以 Thread 内部就采用了 ThreadLocalMap 这样 Map 的数据结构来存放 ThreadLocal 和 value。 源码分析 (1).get 方法 1234567891011121314151617public T get() &#123; //获取到当前线程 Thread t = Thread.currentThread(); //获取到当前线程内的 ThreadLocalMap 对象，每个线程内都有一个 ThreadLocalMap 对象 ThreadLocalMap map = getMap(t); if (map != null) &#123; //获取 ThreadLocalMap 中的 Entry 对象并拿到 Value ThreadLocalMap.Entry e = map.getEntry(this); if (e != null) &#123; @SuppressWarnings(\"unchecked\") T result = (T)e.value; return result; &#125; &#125; //如果线程内之前没创建过 ThreadLocalMap，就创建 return setInitialValue();&#125; 这是 ThreadLocal 的 get 方法，可以看出它利用了 Thread.currentThread 来获取当前线程的引用，并且把这个引用传入到了 getMap 方法里面，来拿到当前线程的 ThreadLocalMap。 然后就是一个 if ( map != null ) 条件语句，那我们先来看看 if (map == null) 的情况，如果 map == null，则说明之前这个线程中没有创建过 ThreadLocalMap，于是就去调用 setInitialValue 来创建；如果 map != null，我们就应该通过 this 这个引用（也就是当前的 ThreadLocal 对象的引用）来获取它所对应的 Entry，同时再通过这个 Entry 拿到里面的 value，最终作为结果返回。 值得注意的是，这里的 ThreadLocalMap 是保存在线程 Thread 类中的，而不是保存在 ThreadLocal 中的。 (2).getMap 方法 123ThreadLocalMap getMap(Thread t) &#123; return t.threadLocals;&#125; 可以看到，这个方法很清楚地表明了 Thread 和 ThreadLocalMap 的关系，可以看出 ThreadLocalMap 是线程的一个成员变量。这个方法的作用就是获取到当前线程内的 ThreadLocalMap 对象，每个线程都有 ThreadLocalMap 对象，而这个对象的名字就叫作 threadLocals，初始值为 null，代码如下： 1ThreadLocal.ThreadLocalMap threadLocals = null; (3).set 方法 12345678public void set(T value) &#123; Thread t = Thread.currentThread(); ThreadLocalMap map = getMap(t); if (map != null) map.set(this, value); else createMap(t, value);&#125; set 方法的作用是把我们想要存储的 value 给保存进去。可以看出，首先，它还是需要获取到当前线程的引用，并且利用这个引用来获取到 ThreadLocalMap ；然后，如果 map == null 则去创建这个 map，而当 map != null 的时候就利用 map.set 方法，把 value 给 set 进去。 可以看出，map.set(this, value) 传入的这两个参数中，第一个参数是 this，就是当前 ThreadLocal 的引用，这也再次体现了，在 ThreadLocalMap 中，它的 key 的类型是 ThreadLocal；而第二个参数就是我们所传入的 value，这样一来就可以把这个键值对保存到 ThreadLocalMap 中去了。 ThreadLocalMap 类，也就是 Thread.threadLocals 下面这段代码截取自定义在 ThreadLocal 类中的 ThreadLocalMap 类： 123456789101112static class ThreadLocalMap &#123; static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; super(k); value = v; &#125; &#125; private Entry[] table;//...&#125; ThreadLocalMap 类是每个线程 Thread 类里面的一个成员变量，其中最重要的就是截取出的这段代码中的 Entry 内部类。在 ThreadLocalMap 中会有一个 Entry 类型的数组，名字叫 table。我们可以把 Entry 理解为一个 map，其键值对为： 键，当前的 ThreadLocal； 值，实际需要存储的变量，比如 user 用户对象或者 simpleDateFormat 对象等。 ThreadLocalMap 既然类似于 Map，所以就和 HashMap 一样，也会有包括 set、get、rehash、resize 等一系列标准操作。但是，虽然思路和 HashMap 是类似的，但是具体实现会有一些不同。 比如其中一个不同点就是，我们知道 HashMap 在面对 hash 冲突的时候，采用的是拉链法。它会先把对象 hash 到一个对应的格子中，如果有冲突就用链表的形式往下链，如下图所示： 但是 ThreadLocalMap 解决 hash 冲突的方式是不一样的，它采用的是线性探测法。如果发生冲突，并不会用链表的形式往下链，而是会继续寻找下一个空的格子。这是 ThreadLocalMap 和 HashMap 在处理冲突时不一样的点。 4.内存泄漏——为何每次用完 ThreadLocal 都要调用 remove()？什么是内存泄漏 内存泄漏指的是，当某一个对象不再有用的时候，占用的内存却不能被回收，这就叫作内存泄漏。 因为通常情况下，如果一个对象不再有用，那么我们的垃圾回收器 GC，就应该把这部分内存给清理掉。这样的话，就可以让这部分内存后续重新分配到其他的地方去使用；否则，如果对象没有用，但一直不能被回收，这样的垃圾对象如果积累的越来越多，则会导致我们可用的内存越来越少，最后发生内存不够用的 OOM 错误。 Key 的泄漏 每一个 Thread 都有一个 ThreadLocal.ThreadLocalMap 这样的类型变量，该变量的名字叫作 threadLocals。线程在访问了 ThreadLocal 之后，都会在它的 ThreadLocalMap 里面的 Entry 中去维护该 ThreadLocal 变量与具体实例的映射。 我们可能会在业务代码中执行了 ThreadLocal instance = null 操作，想清理掉这个 ThreadLocal 实例，但是假设我们在 ThreadLocalMap 的 Entry 中强引用了 ThreadLocal 实例，那么，虽然在业务代码中把 ThreadLocal 实例置为了 null，但是在 Thread 类中依然有这个引用链的存在。 GC 在垃圾回收的时候会进行可达性分析，它会发现这个 ThreadLocal 对象依然是可达的，所以对于这个 ThreadLocal 对象不会进行垃圾回收，这样的话就造成了内存泄漏的情况。 JDK 开发者考虑到了这一点，所以 ThreadLocalMap 中的 Entry 继承了 WeakReference 弱引用，代码如下所示： 12345678static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; super(k); value = v; &#125;&#125; 可以看到，这个 Entry 是 extends WeakReference。弱引用的特点是，如果这个对象只被弱引用关联，而没有任何强引用关联，那么这个对象就可以被回收，所以弱引用不会阻止 GC。因此，这个弱引用的机制就避免了 ThreadLocal 的内存泄露问题。 这就是为什么 Entry 的 key 要使用弱引用的原因。 Value 的泄漏 可是，如果我们继续研究的话会发现，虽然 ThreadLocalMap 的每个 Entry 都是一个对 key 的弱引用，但是这个 Entry 包含了一个对 value 的强引用，还是刚才那段代码： 12345678static class Entry extends WeakReference&lt;ThreadLocal&lt;?&gt;&gt; &#123; /** The value associated with this ThreadLocal. */ Object value; Entry(ThreadLocal&lt;?&gt; k, Object v) &#123; super(k); value = v; &#125;&#125; 可以看到，value = v 这行代码就代表了强引用的发生。 正常情况下，当线程终止，key 所对应的 value 是可以被正常垃圾回收的，因为没有任何强引用存在了。但是有时线程的生命周期是很长的，如果线程迟迟不会终止，那么可能 ThreadLocal 以及它所对应的 value 早就不再有用了。在这种情况下，我们应该保证它们都能够被正常的回收。 为了更好地分析这个问题，我们用下面这张图来看一下具体的引用链路（实线代表强引用，虚线代表弱引用）： 可以看到，左侧是引用栈，栈里面有一个 ThreadLocal 的引用和一个线程的引用，右侧是我们的堆，在堆中是对象的实例。 我们重点看一下下面这条链路：Thread Ref → Current Thread → ThreadLocalMap → Entry → Value → 可能泄漏的value实例。 这条链路是随着线程的存在而一直存在的，如果线程执行耗时任务而不停止，那么当垃圾回收进行可达性分析的时候，这个 Value 就是可达的，所以不会被回收。但是与此同时可能我们已经完成了业务逻辑处理，不再需要这个 Value 了，此时也就发生了内存泄漏问题。 JDK 同样也考虑到了这个问题，在执行 ThreadLocal 的 set、remove、rehash 等方法时，它都会扫描 key 为 null 的 Entry，如果发现某个 Entry 的 key 为 null，则代表它所对应的 value 也没有作用了，所以它就会把对应的 value 置为 null，这样，value 对象就可以被正常回收了。 但是假设 ThreadLocal 已经不被使用了，那么实际上 set、remove、rehash 方法也不会被调用，与此同时，如果这个线程又一直存活、不终止的话，那么刚才的那个调用链就一直存在，也就导致了 value 的内存泄漏。 如何避免内存泄露 解决方法：调用 ThreadLocal 的 remove 方法。调用这个方法就可以删除对应的 value 对象，可以避免内存泄漏。 来看一下 remove 方法的源码： 12345public void remove() &#123; ThreadLocalMap m = getMap(Thread.currentThread()); if (m != null) m.remove(this);&#125; 可以看出，它是先获取到 ThreadLocalMap 这个引用的，并且调用了它的 remove 方法。这里的 remove 方法可以把 key 所对应的 value 给清理掉，这样一来，value 就可以被 GC 回收了。 所以，在使用完了 ThreadLocal 之后，我们应该手动去调用它的 remove 方法，目的是防止内存泄漏的发生。","tags":[{"name":"java","slug":"java","permalink":"https://sunshine-zwq.gitee.io/tags/java/"},{"name":"并发编程","slug":"并发编程","permalink":"https://sunshine-zwq.gitee.io/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"},{"name":"面试","slug":"面试","permalink":"https://sunshine-zwq.gitee.io/tags/%E9%9D%A2%E8%AF%95/"}]},{"title":"Java并发编程常见问题-阻塞队列","date":"2020-12-17T09:21:50.000Z","path":"2020/12/17/Java并发编程常见问题-阻塞队列/","text":"1.什么是阻塞队列？阻塞队列的作用 阻塞队列，也就是 BlockingQueue，它是一个接口，如代码所示： 1public interface BlockingQueue&lt;E&gt; extends Queue&lt;E&gt;&#123;...&#125; BlockingQueue 继承了 Queue 接口，是队列的一种。Queue 和 BlockingQueue 都是在 Java 5 中加入的。 BlockingQueue 是线程安全的，我们在很多场景下都可以利用线程安全的队列来优雅地解决我们业务自身的线程安全问题。比如说，使用生产者/消费者模式的时候，我们生产者只需要往队列里添加元素，而消费者只需要从队列里取出它们就可以了，如图所示： 在图中，左侧有三个生产者线程，它会把生产出来的结果放到中间的阻塞队列中，而右侧的三个消费者也会从阻塞队列中取出它所需要的内容并进行处理。因为阻塞队列是线程安全的，所以生产者和消费者都可以是多线程的，不会发生线程安全问题。 既然队列本身是线程安全的，队列可以安全地从一个线程向另外一个线程传递数据，所以我们的生产者/消费者直接使用线程安全的队列就可以，而不需要自己去考虑更多的线程安全问题。这也就意味着，考虑锁等线程安全问题的重任从“你”转移到了“队列”上，降低了我们开发的难度和工作量。 同时，队列它还能起到一个隔离的作用。比如说我们开发一个银行转账的程序，那么生产者线程不需要关心具体的转账逻辑，只需要把转账任务，如账户和金额等信息放到队列中就可以，而不需要去关心银行这个类如何实现具体的转账业务。而作为银行这个类来讲，它会去从队列里取出来将要执行的具体的任务，再去通过自己的各种方法来完成本次转账。 这样就实现了具体任务与执行任务类之间的解耦，任务被放在了阻塞队列中，而负责放任务的线程是无法直接访问到我们银行具体实现转账操作的对象的，实现了隔离，提高了安全性。 上图展示了 Queue 最主要的实现类，可以看出 Java 提供的线程安全的队列（也称为并发队列）分为阻塞队列和非阻塞队列两大类。 阻塞队列的典型例子就是 BlockingQueue 接口的实现类，BlockingQueue 下面有 6 种最主要的实现，分别是 ArrayBlockingQueue、LinkedBlockingQueue、SynchronousQueue、DelayQueue、PriorityBlockingQueue 和 LinkedTransferQueue，它们各自有不同的特点。 非阻塞并发队列的典型例子是 ConcurrentLinkedQueue，这个类不会让线程阻塞，利用 CAS 保证了线程安全。 我们可以根据需要自由选取阻塞队列或者非阻塞队列来满足业务需求。 还有一个和 Queue 关系紧密的 Deque 接口，它继承了 Queue，如代码所示： 1public interface Deque&lt;E&gt; extends Queue&lt;E&gt; &#123;//...&#125; Deque 的意思是双端队列，音标是 [dek]，是 double-ended-queue 的缩写，它从头和尾都能添加和删除元素；而普通的 Queue 只能从一端进入，另一端出去。这是 Deque 和 Queue 的不同之处，Deque 其他方面的性质都和 Queue 类似。 阻塞队列的特点 阻塞队列区别于其他类型的队列的最主要的特点就是“阻塞”这两个字，所以下面重点介绍阻塞功能：阻塞功能使得生产者和消费者两端的能力得以平衡，当有任何一端速度过快时，阻塞队列便会把过快的速度给降下来。实现阻塞最重要的两个方法是 take 方法和 put 方法。 take 方法 take 方法的功能是获取并移除队列的头结点，通常在队列里有数据的时候是可以正常移除的。可是一旦执行 take 方法的时候，队列里无数据，则阻塞，直到队列里有数据。一旦队列里有数据了，就会立刻解除阻塞状态，并且取到数据。过程如图所示： put 方法 put 方法插入元素时，如果队列没有满，那就和普通的插入一样是正常的插入，但是如果队列已满，那么就无法继续插入，则阻塞，直到队列里有了空闲空间。如果后续队列有了空闲空间，比如消费者消费了一个元素，那么此时队列就会解除阻塞状态，并把需要添加的数据添加到队列中。过程如图所示： 以上过程中的阻塞和解除阻塞，都是 BlockingQueue 完成的，不需要我们自己处理。 是否有界（容量有多大） 此外，阻塞队列还有一个非常重要的属性，那就是容量的大小，分为有界和无界两种。 无界队列意味着里面可以容纳非常多的元素，例如 LinkedBlockingQueue 的上限是 Integer.MAX_VALUE，约为 2 的 31 次方，是非常大的一个数，可以近似认为是无限容量，因为我们几乎无法把这个容量装满。 但是有的阻塞队列是有界的，例如 ArrayBlockingQueue 如果容量满了，也不会扩容，所以一旦满了就无法再往里放数据了。 2.阻塞队列包含哪些常用的方法？add、offer、put 等方法的区别？我们把 BlockingQueue 中最常用的和添加、删除相关的 8 个方法列出来，并且把它们分为三组，每组方法都和添加、移除元素相关。 这三组方法由于功能很类似，所以比较容易混淆。它们的区别仅在于特殊情况：当队列满了无法添加元素，或者是队列空了无法移除元素时，不同组的方法对于这种特殊情况会有不同的处理方式： 抛出异常：add、remove、element 返回结果但不抛出异常：offer、poll、peek 阻塞：put、take 第一组：add、remove、element (1).add 方法 add 方法是往队列里添加一个元素，如果队列满了，就会抛出异常来提示队列已满。示例代码如下： 123456private static void addTest() &#123; BlockingQueue&lt;Integer&gt; blockingQueue = new ArrayBlockingQueue&lt;Integer&gt;(2); blockingQueue.add(1); blockingQueue.add(1); blockingQueue.add(1);&#125; 在这段代码中，我们创建了一个容量为 2 的 BlockingQueue，并且尝试往里面放 3 个值，超过了容量上限，那么在添加第三个值的时候就会得到异常： 1Exception in thread &quot;main&quot; java.lang.IllegalStateException:Queue full (2).remove 方法 remove 方法的作用是删除元素，如果我们删除的队列是空的，由于里面什么都没有，所以也无法删除任何元素，那么 remove 方法就会抛出异常。示例代码如下： 12345678private static void removeTest() &#123; ArrayBlockingQueue&lt;Integer&gt; blockingQueue = new ArrayBlockingQueue&lt;Integer&gt;(2); blockingQueue.add(1); blockingQueue.add(1); blockingQueue.remove(); blockingQueue.remove(); blockingQueue.remove();&#125; 在这段代码中，我们往一个容量为 2 的 BlockingQueue 里放入 2 个元素，并且删除 3 个元素。在删除前面两个元素的时候会正常执行，因为里面依然有元素存在，但是在删除第三个元素时，由于队列里面已经空了，所以便会抛出异常： 1Exception in thread &quot;main&quot; java.util.NoSuchElementException (3).element 方法 element 方法是返回队列的头部节点，但是并不删除。和 remove 方法一样，如果我们用这个方法去操作一个空队列，想获取队列的头结点，可是由于队列是空的，我们什么都获取不到，会抛出和前面 remove 方法一样的异常：NoSuchElementException。示例代码如下： 1234private static void elementTest() &#123; ArrayBlockingQueue&lt;Integer&gt; blockingQueue = new ArrayBlockingQueue&lt;Integer&gt;(2); blockingQueue.element();&#125; 我们新建了一个容量为 2 的 ArrayBlockingQueue，直接调用 element 方法，由于之前没有往里面添加元素，默认为空，那么会得到异常： 1Exception in thread &quot;main&quot; java.util.NoSuchElementException 第二组：offer、poll、peek 实际上我们通常并不想看到第一组方法抛出的异常，这时我们可以优先采用第二组方法。第二组方法相比于第一组而言要友好一些，当发现队列满了无法添加，或者队列为空无法删除的时候，第二组方法会给一个提示，而不是抛出一个异常。 (1).offer 方法 offer 方法用来插入一个元素，并用返回值来提示插入是否成功。如果添加成功会返回 true，而如果队列已经满了，此时继续调用 offer 方法的话，它不会抛出异常，只会返回一个错误提示：false。示例代码如下： 123456private static void offerTest() &#123; ArrayBlockingQueue&lt;Integer&gt; blockingQueue = new ArrayBlockingQueue&lt;Integer&gt;(2); System.out.println(blockingQueue.offer(1)); System.out.println(blockingQueue.offer(1)); System.out.println(blockingQueue.offer(1));&#125; 我们创建了一个容量为 2 的 ArrayBlockingQueue，并且调用了三次 offer方法尝试添加，每次都把返回值打印出来，运行结果如下： 123truetruefalse 可以看出，前面两次添加成功了，但是第三次添加的时候，已经超过了队列的最大容量，所以会返回 false，表明添加失败。 (2).poll 方法 poll 方法和第一组的 remove 方法是对应的，作用也是移除并返回队列的头节点。但是如果当队列里面是空的，没有任何东西可以移除的时候，便会返回 null 作为提示。正因如此，我们是不允许往队列中插入 null 的，否则我们没有办法区分返回的 null 是一个提示还是一个真正的元素。示例代码如下： 12345678910private static void pollTest() &#123; ArrayBlockingQueue&lt;Integer&gt; blockingQueue = new ArrayBlockingQueue&lt;Integer&gt;(3); blockingQueue.offer(1); blockingQueue.offer(2); blockingQueue.offer(3); System.out.println(blockingQueue.poll()); System.out.println(blockingQueue.poll()); System.out.println(blockingQueue.poll()); System.out.println(blockingQueue.poll());&#125; 在这个代码中我们创建了一个容量为 3 的 ArrayBlockingQueue，并且先往里面放入 3 个元素，然后四次调用 poll 方法，运行结果如下： 1234123null 前面三次 poll 都运行成功了，并且返回了元素内容 1、2、3，是先进先出的顺序。第四次的 poll 方法返回 null，代表此时已经没有元素可以移除了。 (3).peek 方法 peek 方法和第一组的 element 方法是对应的，意思是返回队列的头元素但并不删除。如果队列里面是空的，它便会返回 null 作为提示。示例代码如下： 1234private static void peekTest() &#123; ArrayBlockingQueue&lt;Integer&gt; blockingQueue = new ArrayBlockingQueue&lt;Integer&gt;(2); System.out.println(blockingQueue.peek());&#125; 运行结果： 1null 我们新建了一个空的 ArrayBlockingQueue，然后直接调用 peek，返回结果 null，代表此时并没有东西可以取出。 带超时时间的 offer 和 poll offer 和 poll 都有带超时时间的重载方法： 1offer(E e, long timeout, TimeUnit unit) 它有三个参数，分别是元素、超时时长和时间单位。通常情况下，这个方法会插入成功并返回 true；如果队列满了导致插入不成功，在调用带超时时间重载方法的 offer 的时候，则会等待指定的超时时间，如果时间到了依然没有插入成功，就会返回 false。 1poll(long timeout, TimeUnit unit) 带时间参数的 poll 方法和 offer 类似：如果能够移除，便会立刻返回这个节点的内容；如果队列是空的就会进行等待，等待时间正是我们指定的时间，直到超时时间到了，如果队列里依然没有元素可供移除，便会返回 null 作为提示。 第三组：put、take (1).put 方法 put 方法的作用是插入元素。通常在队列没满的时候是正常的插入，但是如果队列已满就无法继续插入，这时它既不会立刻返回 false 也不会抛出异常，而是让插入的线程陷入阻塞状态，直到队列里有了空闲空间，此时队列就会让之前的线程解除阻塞状态，并把刚才那个元素添加进去。 (2).take 方法 take 方法的作用是获取并移除队列的头结点。通常在队列里有数据的时候会正常取出数据并删除；但是如果执行 take 的时候队列里无数据，则阻塞，直到队列里有数据；一旦队列里有数据了，就会立刻解除阻塞状态，并且取到数据。 总结 用表格把上面 8 种方法总结如下： 3.有哪几种常见的阻塞队列？ArrayBlockingQueue ArrayBlockingQueue 是最典型的有界队列，其内部是用数组存储元素的，利用 ReentrantLock 实现线程安全。 我们在创建它的时候就需要指定它的容量，之后也不可以再扩容了，在构造函数中我们同样可以指定是否是公平的，代码如下： 1ArrayBlockingQueue(int capacity, boolean fair) 第一个参数是容量，第二个参数是是否公平。正如 ReentrantLock 一样，如果 ArrayBlockingQueue 被设置为非公平的，那么就存在插队的可能；如果设置为公平的，那么等待了最长时间的线程会被优先处理，其他线程不允许插队，不过这样的公平策略同时会带来一定的性能损耗，因为非公平的吞吐量通常会高于公平的情况。 LinkedBlockingQueue 这是一个内部用链表实现的 BlockingQueue。如果我们不指定它的初始容量，那么它容量默认就为整型的最大值 Integer.MAX_VALUE，由于这个数非常大，我们通常不可能放入这么多的数据，所以 LinkedBlockingQueue 也被称作无界队列，代表它几乎没有界限。 SynchronousQueue 如图所示，SynchronousQueue 最大的不同之处在于，它的容量为 0，所以没有一个地方来暂存元素，导致每次取数据都要先阻塞，直到有数据被放入；同理，每次放数据的时候也会阻塞，直到有消费者来取。 需要注意的是，SynchronousQueue 的容量不是 1 而是 0，因为 SynchronousQueue 不需要去持有元素，它所做的就是直接传递（direct handoff）。由于每当需要传递的时候，SynchronousQueue 会把元素直接从生产者传给消费者，在此期间并不需要做存储，所以如果运用得当，它的效率是很高的。 另外，由于它的容量为 0，所以相比于一般的阻塞队列，SynchronousQueue 的很多方法的实现是很有意思的，我们来举几个例子： SynchronousQueue 的 peek 方法永远返回 null，代码如下： 123public E peek() &#123; return null;&#125; 因为 peek 方法的含义是取出头结点，但是 SynchronousQueue 的容量是 0，所以连头结点都没有，peek 方法也就没有意义，所以始终返回 null。同理，element 始终会抛出 NoSuchElementException 异常。 而 SynchronousQueue 的 size 方法始终返回 0，因为它内部并没有容量，代码如下： 123public int size() &#123; return 0;&#125; 直接 return 0，同理，isEmpty 方法始终返回 true： 123public boolean isEmpty() &#123; return true;&#125; 因为它始终都是空的。 PriorityBlockingQueue 前面我们所说的 ArrayBlockingQueue 和 LinkedBlockingQueue 都是采用先进先出的顺序进行排序，可是如果有的时候我们需要自定义排序怎么办呢？这时就需要使用 PriorityBlockingQueue。 PriorityBlockingQueue 是一个支持优先级的无界阻塞队列，可以通过自定义类实现 compareTo() 方法来指定元素排序规则，或者初始化时通过构造器参数 Comparator 来指定排序规则。同时，插入队列的对象必须是可比较大小的，也就是 Comparable 的，否则会抛出 ClassCastException 异常。 它的 take 方法在队列为空的时候会阻塞，但是正因为它是无界队列，而且会自动扩容，所以它的队列永远不会满，所以它的 put 方法永远不会阻塞，添加操作始终都会成功，也正因为如此，它的成员变量里只有一个 Condition： 1private final Condition notEmpty; 这和之前的 ArrayBlockingQueue 拥有两个 Condition（分别是 notEmpty 和 notFull）形成了鲜明的对比，我们的 PriorityBlockingQueue 不需要 notFull，因为它永远都不会满，真是“有空间就可以任性”。 DelayQueue DelayQueue 这个队列比较特殊，具有“延迟”的功能。我们可以设定让队列中的任务延迟多久之后执行，比如 10 秒钟之后执行，这在例如“30 分钟后未付款自动取消订单”等需要延迟执行的场景中被大量使用。 它是无界队列，放入的元素必须实现 Delayed 接口，而 Delayed 接口又继承了 Comparable 接口，所以自然就拥有了比较和排序的能力，代码如下： 123public interface Delayed extends Comparable&lt;Delayed&gt; &#123; long getDelay(TimeUnit unit);&#125; 可以看出这个 Delayed 接口继承自 Comparable，里面有一个需要实现的方法，就是 getDelay。这里的 getDelay 方法返回的是“还剩下多长的延迟时间才会被执行”，如果返回 0 或者负数则代表任务已过期。 元素会根据延迟时间的长短被放到队列的不同位置，越靠近队列头代表越早过期。 DelayQueue 内部使用了 PriorityQueue 的能力来进行排序，而不是自己从头编写，我们在工作中可以学习这种思想，对已有的功能进行复用，不但可以减少开发量，同时避免了“重复造轮子”，更重要的是，对学到的知识进行合理的运用，让知识变得更灵活，做到触类旁通。 4.阻塞和非阻塞队列的并发安全原理是什么？ArrayBlockingQueue 源码分析 我们首先看一下 ArrayBlockingQueue 的源码，ArrayBlockingQueue 有以下几个重要的属性： 12345678// 用于存放元素的数组final Object[] items;// 下一次读取操作的位置int takeIndex;// 下一次写入操作的位置int putIndex;// 队列中的元素数量int count; 第一个就是最核心的、用于存储元素的 Object 类型的数组；然后它还会有两个位置变量，分别是 takeIndex 和 putIndex，这两个变量就是用来标明下一次读取和写入位置的；另外还有一个 count 用来计数，它所记录的就是队列中的元素个数。 另外，我们再来看下面这三个变量： 1234// 以下3个是控制并发用的工具final ReentrantLock lock;private final Condition notEmpty;private final Condition notFull; 这三个变量也非常关键，第一个就是一个 ReentrantLock，而下面两个 Condition 分别是由 ReentrantLock 产生出来的，这三个变量就是我们实现线程安全最核心的工具。 ArrayBlockingQueue 实现并发同步的原理就是利用 ReentrantLock 和它的两个 Condition，读操作和写操作都需要先获取到 ReentrantLock 独占锁才能进行下一步操作。进行读操作时如果队列为空，线程就会进入到读线程专属的 notEmpty 的 Condition 的队列中去排队，等待写线程写入新的元素；同理，如果队列已满，这个时候写操作的线程会进入到写线程专属的 notFull 队列中去排队，等待读线程将队列元素移除并腾出空间。 下面，我们来分析一下最重要的 put 方法： 123456789101112public void put(E e) throws InterruptedException &#123; checkNotNull(e); final ReentrantLock lock = this.lock; lock.lockInterruptibly(); try &#123; while (count == items.length) notFull.await(); enqueue(e); &#125; finally &#123; lock.unlock(); &#125;&#125; 在 put 方法中，首先用 checkNotNull 方法去检查插入的元素是不是 null。如果不是 null，我们会用 ReentrantLock 上锁，并且上锁方法是 lock.lockInterruptibly()，在获取锁的同时是可以响应中断的，这也正是我们的阻塞队列在调用 put 方法时，在尝试获取锁但还没拿到锁的期间可以响应中断的底层原因。 紧接着 ，是一个非常经典的 try finally 代码块，finally 中会去解锁，try 中会有一个 while 循环，它会检查当前队列是不是已经满了，也就是 count 是否等于数组的长度。如果等于就代表已经满了，于是我们便会进行等待，直到有空余的时候，我们才会执行下一步操作，调用 enqueue 方法让元素进入队列，最后用 unlock 方法解锁。 和 ArrayBlockingQueue 类似，其他各种阻塞队列如 LinkedBlockingQueue、PriorityBlockingQueue、DelayQueue、DelayedWorkQueue 等一系列 BlockingQueue 的内部也是利用了 ReentrantLock 来保证线程安全，只不过细节有差异，比如 LinkedBlockingQueue 的内部有两把锁，分别锁住队列的头和尾，比共用同一把锁的效率更高，不过总体思想都是类似的。 非阻塞队列ConcurrentLinkedQueue ConcurrentLinkedQueue 是使用链表作为其数据结构的，看一下关键方法 offer 的源码： 12345678910111213141516171819202122232425262728public boolean offer(E e) &#123; checkNotNull(e); final Node&lt;E&gt; newNode = new Node&lt;E&gt;(e); for (Node&lt;E&gt; t = tail, p = t;;) &#123; Node&lt;E&gt; q = p.next; if (q == null) &#123; // p is last node if (p.casNext(null, newNode)) &#123; // Successful CAS is the linearization point // for e to become an element of this queue, // and for newNode to become \"live\". if (p != t) // hop two nodes at a time casTail(t, newNode); // Failure is OK. return true; &#125; // Lost CAS race to another thread; re-read next &#125; else if (p == q) // We have fallen off list. If tail is unchanged, it // will also be off-list, in which case we need to // jump to head, from which all live nodes are always // reachable. Else the new tail is a better bet. p = (t != (t = tail)) ? t : head; else // Check for tail updates after two hops. p = (p != t &amp;&amp; t != (t = tail)) ? t : q; &#125;&#125; 在这里我们不去一行一行分析具体的内容，而是把目光放到整体的代码结构上，在检查完空判断之后，可以看到它整个是一个大的 for 循环，而且是一个非常明显的死循环。在这个循环中有一个非常亮眼的 p.casNext 方法，这个方法正是利用了 CAS 来操作的，而且这个死循环去配合 CAS 也就是典型的乐观锁的思想。我们就来看一下 p.casNext 方法的具体实现，其方法代码如下： 123boolean casNext(Node&lt;E&gt; cmp, Node&lt;E&gt; val) &#123; return UNSAFE.compareAndSwapObject(this, nextOffset, cmp, val);&#125; 可以看出这里运用了 UNSAFE.compareAndSwapObject 方法来完成 CAS 操作，而 compareAndSwapObject 是一个 native 方法，最终会利用 CPU 的 CAS 指令保证其不可中断。 可以看出，非阻塞队列 ConcurrentLinkedQueue 使用 CAS 非阻塞算法 + 不停重试，来实现线程安全，适合用在不需要阻塞功能，且并发不是特别剧烈的场景。 5.如何选择适合自己的阻塞队列？线程池对于阻塞队列的选择 (1).FixedThreadPool（SingleThreadExecutor 同理）选取的是 LinkedBlockingQueue 因为 LinkedBlockingQueue 不同于 ArrayBlockingQueue，ArrayBlockingQueue 的容量是有限的，而 LinkedBlockingQueue 是链表长度默认是可以无限延长的。 由于 FixedThreadPool 的线程数是固定的，在任务激增的时候，它无法增加更多的线程来帮忙处理 Task，所以需要像 LinkedBlockingQueue 这样没有容量上限的 Queue 来存储那些还没处理的 Task。 如果所有的 corePoolSize 线程都正在忙，那么新任务将会进入阻塞队列等待，由于队列是没有容量上限的，队列永远不会被填满，这样就保证了对于线程池 FixedThreadPool 和 SingleThreadExecutor 而言，不会拒绝新任务的提交，也不会丢失数据。 (2).CachedThreadPool 选取的是 SynchronousQueue 对于 CachedThreadPool 而言，为了避免新提交的任务被拒绝，它选择了无限制的 maximumPoolSize（在专栏中，maxPoolSize 等同于 maximumPoolSize），所以既然它的线程的最大数量是无限的，也就意味着它的线程数不会受到限制，那么它就不需要一个额外的空间来存储那些 Task，因为每个任务都可以通过新建线程来处理。 SynchronousQueue 会直接把任务交给线程，而不需要另外保存它们，效率更高，所以 CachedThreadPool 使用的 Queue 是 SynchronousQueue。 (3).ScheduledThreadPool（SingleThreadScheduledExecutor同理）选取的是延迟队列 对于 ScheduledThreadPool 而言，它使用的是 DelayedWorkQueue。延迟队列的特点是：不是先进先出，而是会按照延迟时间的长短来排序，下一个即将执行的任务会排到队列的最前面。 我们来举个例子：例如我们往这个队列中，放一个延迟 10 分钟执行的任务，然后再放一个延迟 10 秒钟执行的任务。通常而言，如果不是延迟队列，那么按照先进先出的排列规则，也就是延迟 10 分钟执行的那个任务是第一个放置的，会放在最前面。但是由于我们此时使用的是阻塞队列，阻塞队列在排放各个任务的位置的时候，会根据延迟时间的长短来排放。所以，我们第二个放置的延迟 10 秒钟执行的那个任务，反而会排在延迟 10 分钟的任务的前面，因为它的执行时间更早。 我们选择使用延迟队列的原因是，ScheduledThreadPool 处理的是基于时间而执行的 Task，而延迟队列有能力把 Task 按照执行时间的先后进行排序，这正是我们所需要的功能。 ArrayBlockingQueue 除了线程池选择的 3 种阻塞队列外，还有一种常用的阻塞队列叫作 ArrayBlockingQueue，它也经常被用于我们手动创建的线程池中。 这种阻塞队列内部是用数组实现的，在新建对象的时候要求传入容量值，且后期不能扩容，所以 ArrayBlockingQueue的最大特点就是容量是有限且固定的。这样一来，使用 ArrayBlockingQueue 且设置了合理大小的最大线程数的线程池，在任务队列放满了以后，如果线程数也已经达到了最大值，那么线程池根据规则就会拒绝新提交的任务，而不会无限增加任务或者线程数导致内存不足，可以非常有效地防止资源耗尽的情况发生。 归纳 通常我们可以从以下 5 个角度考虑，来选择合适的阻塞队列： (1).功能 第 1 个需要考虑的就是功能层面，比如是否需要阻塞队列帮我们排序，如优先级排序、延迟执行等。如果有这个需要，我们就必须选择类似于 PriorityBlockingQueue 之类的有排序能力的阻塞队列。 (2).容量 第 2 个需要考虑的是容量，或者说是否有存储的要求，还是只需要“直接传递”。在考虑这一点的时候，我们知道前面介绍的那几种阻塞队列，有的是容量固定的，如 ArrayBlockingQueue；有的默认是容量无限的，如 LinkedBlockingQueue；而有的里面没有任何容量，如 SynchronousQueue；而对于 DelayQueue 而言，它的容量固定就是 Integer.MAX_VALUE。 所以不同阻塞队列的容量是千差万别的，我们需要根据任务数量来推算出合适的容量，从而去选取合适的 BlockingQueue。 (3).能否扩容 第 3 个需要考虑的是能否扩容。因为有时我们并不能在初始的时候很好的准确估计队列的大小，因为业务可能有高峰期、低谷期。 如果一开始就固定一个容量，可能无法应对所有的情况，也是不合适的，有可能需要动态扩容。如果我们需要动态扩容的话，那么就不能选择 ArrayBlockingQueue ，因为它的容量在创建时就确定了，无法扩容。相反，PriorityBlockingQueue 即使在指定了初始容量之后，后续如果有需要，也可以自动扩容。 (4).内存结构 第 4 个需要考虑的点就是内存结构。 ArrayBlockingQueue的内部结构是“数组”的形式，和它不同的是，LinkedBlockingQueue 的内部是用链表实现的，所以这里就需要我们考虑到，ArrayBlockingQueue 没有链表所需要的“节点”，空间利用率更高。所以如果我们对性能有要求可以从内存的结构角度去考虑这个问题。 和它不同的是，LinkedBlockingQueue 的内部是用链表实现的，所以这里就需要我们考虑到，ArrayBlockingQueue 没有链表所需要的“节点”，空间利用率更高。所以如果我们对性能有要求可以从内存的结构角度去考虑这个问题。 (5).性能 第 5 点就是从性能的角度去考虑。比如 LinkedBlockingQueue 由于拥有两把锁，它的操作粒度更细，在并发程度高的时候，相对于只有一把锁的 ArrayBlockingQueue 性能会更好。 另外，SynchronousQueue 性能往往优于其他实现，因为它只需要“直接传递”，而不需要存储的过程。如果我们的场景需要直接传递的话，可以优先考虑 SynchronousQueue。","tags":[{"name":"java","slug":"java","permalink":"https://sunshine-zwq.gitee.io/tags/java/"},{"name":"并发编程","slug":"并发编程","permalink":"https://sunshine-zwq.gitee.io/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"},{"name":"面试","slug":"面试","permalink":"https://sunshine-zwq.gitee.io/tags/%E9%9D%A2%E8%AF%95/"}]},{"title":"Java并发编程常见问题-并发容器","date":"2020-12-17T06:45:43.000Z","path":"2020/12/17/Java并发编程常见问题-并发容器/","text":"1.HashMap 为什么是线程不安全的？HashMap 是平时工作和学习中用得非常非常多的一个容器，也是 Map 最主要的实现类之一，但是它自身并不具备线程安全的特点，可以从多种情况中体现出来。 源码分析 来看一下 HashMap 中 put 方法的源码： 123456789101112131415161718192021public V put(K key, V value) &#123; if (key == null) return putForNullKey(value); int hash = hash(key.hashCode()); int i = indexFor(hash, table.length); for (Entry&lt;K,V&gt; e = table[i]; e != null; e = e.next) &#123; Object k; if (e.hash == hash &amp;&amp; ((k = e.key) == key || key.equals(k))) &#123; V oldValue = e.value; e.value = value; e.recordAccess(this); return oldValue; &#125; &#125; //modCount++ 是一个复合操作 modCount++; addEntry(hash, key, value, i); return null;&#125; 在 HashMap 的 put() 方法中，可以看出里面进行了很多操作，那么在这里，我们把目光聚焦到标记出来的 modCount++ 这一行代码中，从表面上看 i++ 只是一行代码，但实际上它并不是一个原子操作，它的执行步骤主要分为三步，而且在每步操作之间都有可能被打断。 所以，从源码的角度，或者说从理论上来讲，这完全足以证明 HashMap 是线程非安全的了。因为如果有多个线程同时调用 put() 方法的话，它很有可能会把 modCount 的值计算错（上述的源码分析针对的是 Java 7 版本的源码，而在 Java 8 版本的 HashMap 的 put 方法中会调用 putVal 方法，里面同样有 ++modCount 语句，所以原理是一样的）。 实验：扩容期间取出的值不准确 为什么说 HashMap 不是线程安全的呢？先来讲解下原理。HashMap 本身默认的容量不是很大，如果不停地往 map 中添加新的数据，它便会在合适的时机进行扩容。而在扩容期间，它会新建一个新的空数组，并且用旧的项填充到这个新的数组中去。那么，在这个填充的过程中，如果有线程获取值，很可能会取到 null 值，而不是我们所希望的、原来添加的值。所以我们程序就想演示这种情景，我们来看一下这段代码： 1234567891011121314151617181920public class HashMapNotSafe &#123; public static void main(String[] args) &#123; final Map&lt;Integer, String&gt; map = new HashMap&lt;&gt;(); final Integer targetKey = 0b1111_1111_1111_1111; // 65 535 final String targetValue = \"v\"; map.put(targetKey, targetValue); new Thread(() -&gt; &#123; IntStream.range(0, targetKey).forEach(key -&gt; map.put(key, \"someValue\")); &#125;).start(); while (true) &#123; if (null == map.get(targetKey)) &#123; throw new RuntimeException(\"HashMap is not thread safe.\"); &#125; &#125; &#125;&#125; 代码中首先建立了一个 HashMap，并且定义了 key 和 value， key 的值是一个二进制的 1111_1111_1111_1111，对应的十进制是 65535。之所以选取这样的值，就是为了让它在扩容往回填充数据的时候，尽量不要填充得太快，比便于能捕捉到错误的发生。而对应的 value 是无所谓的，随意选取了一个非 null 的 “v” 来表示它，并且把这个值放到了 map 中。 接下来，就用一个新的线程不停地往 map 中去填入新的数据，先来看是怎么填入的。首先它用了一个 IntStream，这个 range 是从 0 到之前所讲过的 65535，这个 range 是一个左闭右开的区间，所以会从 0、1、2、3……一直往上加，并且每一次加的时候，这个 0、1、2、3、4 都会作为 key 被放到 map 中去。而它的 value 是统一的，都是 “someValue”，因为 value 不是我们所关心的。 然后，我们就会把这个线程启动起来，随后就进入一个 while 循环，这个 while 循环是关键，在 while 循环中会不停地检测之前放入的 key 所对应的 value 还是不是我们所期望的字符串 “v”。在 while 循环中会不停地从 map 中取 key 对应的值。如果 HashMap 是线程安全的，那么无论怎样它所取到的值都应该是最开始放入的字符串 “v”，可是如果取出来是一个 null，就会满足这个 if 条件并且随即抛出一个异常，因为如果取出 null 就证明它所取出来的值和一开始放入的值是不一致的，也就证明了它是线程不安全的，所以在此要抛出一个 RuntimeException 提示我们。 代码的运行结果： 12Exception in thread \"main\" java.lang.RuntimeException: HashMap is not thread safe.at lesson29.HashMapNotSafe.main(HashMapNotSafe.java:25) 很明显，很快这个程序就抛出了我们所希望看到的 RuntimeException，并且我们把它描述为：HashMap is not thread safe，一旦它能进入到这个 if 语句，就已经证明它所取出来的值是 null，而不是我们期望的字符串 “v”。 通过以上这个例子，也证明了HashMap 是线程非安全的。 同时 put 碰撞导致数据丢失 比如，有多个线程同时使用 put 来添加元素，而且恰好两个 put 的 key 是一样的，它们发生了碰撞，也就是根据 hash 值计算出来的 bucket 位置一样，并且两个线程又同时判断该位置是空的，可以写入，所以这两个线程的两个不同的 value 便会添加到数组的同一个位置，这样最终就只会保留一个数据，丢失一个数据。 可见性问题无法保证 我们再从可见性的角度去考虑一下。可见性也是线程安全的一部分，如果某一个数据结构声称自己是线程安全的，那么它同样需要保证可见性，也就是说，当一个线程操作这个容器的时候，该操作需要对另外的线程都可见，也就是其他线程都能感知到本次操作。可是 HashMap 对此是做不到的，如果线程 1 给某个 key 放入了一个新值，那么线程 2 在获取对应的 key 的值的时候，它的可见性是无法保证的，也就是说线程 2 可能可以看到这一次的更改，但也有可能看不到。所以从可见性的角度出发，HashMap 同样是线程非安全的。 死循环造成 CPU 100% 下面再举一个死循环造成 CPU 100% 的例子。HashMap 有可能会发生死循环并且造成 CPU 100% ，这种情况发生最主要的原因就是在扩容的时候，也就是内部新建新的 HashMap 的时候，扩容的逻辑会反转散列桶中的节点顺序，当有多个线程同时进行扩容的时候，由于 HashMap 并非线程安全的，所以如果两个线程同时反转的话，便可能形成一个循环，并且这种循环是链表的循环，相当于 A 节点指向 B 节点，B 节点又指回到 A 节点，这样一来，在下一次想要获取该 key 所对应的 value 的时候，便会在遍历链表的时候发生永远无法遍历结束的情况，也就发生 CPU 100% 的情况。 所以综上所述，HashMap 是线程不安全的，在多线程使用场景中如果需要使用 Map，应该尽量避免使用线程不安全的 HashMap。同时，虽然 Collections.synchronizedMap(new HashMap()) 是线程安全的，但是效率低下，因为内部用了很多的 synchronized，多个线程不能同时操作。推荐使用线程安全同时性能比较好的 ConcurrentHashMap。 2.ConcurrentHashMap 在 Java7 和 8 有何不同？在 Java 8 中，对于 ConcurrentHashMap 这个常用的工具类进行了很大的升级，对比之前 Java 7 版本在诸多方面都进行了调整和变化。不过，在 Java 7 中的 Segment 的设计思想依然具有参考和学习的价值。 Java 7 版本的 ConcurrentHashMap Java 7 版本中的 ConcurrentHashMap 的结构示意图： 从图中可以看出，在 ConcurrentHashMap 内部进行了 Segment 分段，Segment 继承了 ReentrantLock，可以理解为一把锁，各个 Segment 之间都是相互独立上锁的，互不影响。相比于之前的 Hashtable 每次操作都需要把整个对象锁住而言，大大提高了并发效率。因为它的锁与锁之间是独立的，而不是整个对象只有一把锁。 每个 Segment 的底层数据结构与 HashMap 类似，仍然是数组和链表组成的拉链法结构。默认有 0~15 共 16 个 Segment，所以最多可以同时支持 16 个线程并发操作（操作分别分布在不同的 Segment 上）。16 这个默认值可以在初始化的时候设置为其他值，但是一旦确认初始化以后，是不可以扩容的。 Java 8 版本的 ConcurrentHashMap 在 Java 8 中，几乎完全重写了 ConcurrentHashMap，代码量从原来 Java 7 中的 1000 多行，变成了现在的6000 多行，所以也大大提高了源码的阅读难度。 图中的节点有三种类型。 第一种是最简单的，空着的位置代表当前还没有元素来填充。 第二种就是和 HashMap 非常类似的拉链法结构，在每一个槽中会首先填入第一个节点，但是后续如果计算出相同的 Hash 值，就用链表的形式往后进行延伸。 第三种结构就是红黑树结构，这是 Java 7 的 ConcurrentHashMap 中所没有的结构。 当第二种情况的链表长度大于某一个阈值（默认为 8），且同时满足一定的容量要求的时候，ConcurrentHashMap 便会把这个链表从链表的形式转化为红黑树的形式，目的是进一步提高它的查找性能。所以，Java 8 的一个重要变化就是引入了红黑树的设计。 红黑树是每个节点都带有颜色属性的二叉查找树，颜色为红色或黑色，红黑树的本质是对二叉查找树 BST 的一种平衡策略，我们可以理解为是一种平衡二叉查找树，查找效率高，会自动平衡，防止极端不平衡从而影响查找效率的情况发生。 由于自平衡的特点，即左右子树高度几乎一致，所以其查找性能近似于二分查找，时间复杂度是 O(log(n)) 级别；反观链表，它的时间复杂度就不一样了，如果发生了最坏的情况，可能需要遍历整个链表才能找到目标元素，时间复杂度为 O(n)，远远大于红黑树的 O(log(n))，尤其是在节点越来越多的情况下，O(log(n)) 体现出的优势会更加明显。 红黑树的一些其他特点： 每个节点要么是红色，要么是黑色，但根节点永远是黑色的。 红色节点不能连续，也就是说，红色节点的子和父都不能是红色的。 从任一节点到其每个叶子节点的路径都包含相同数量的黑色节点。 正是由于这些规则和要求的限制，红黑树保证了较高的查找效率，所以现在就可以理解为什么 Java 8 的 ConcurrentHashMap 要引入红黑树了。好处就是避免在极端的情况下冲突链表变得很长，在查询的时候，效率会非常慢。而红黑树具有自平衡的特点，所以，即便是极端情况下，也可以保证查询效率在 O(log(n))。 分析 Java 8 版本的 ConcurrentHashMap 的重要源码 前面讲解了 Java 7 和 Java 8 中 ConcurrentHashMap 的主体结构，下面深入源码分析。由于 Java 7 版本已经过时了，所以把重点放在 Java 8 版本的源码分析上。 Node 节点 我们先来看看最基础的内部存储结构 Node，这就是一个一个的节点，如这段代码所示： 1234567static class Node&lt;K,V&gt; implements Map.Entry&lt;K,V&gt; &#123; final int hash; final K key; volatile V val; volatile Node&lt;K,V&gt; next; // ...&#125; 可以看出，每个 Node 里面是 key-value 的形式，并且把 value 用 volatile 修饰，以便保证可见性，同时内部还有一个指向下一个节点的 next 指针，方便产生链表结构。 put 方法源码分析 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788final V putVal(K key, V value, boolean onlyIfAbsent) &#123; if (key == null || value == null) &#123; throw new NullPointerException(); &#125; //计算 hash 值 int hash = spread(key.hashCode()); int binCount = 0; for (Node&lt;K, V&gt;[] tab = table; ; ) &#123; Node&lt;K, V&gt; f; int n, i, fh; //如果数组是空的，就进行初始化 if (tab == null || (n = tab.length) == 0) &#123; tab = initTable(); &#125; // 找该 hash 值对应的数组下标 else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) &#123; //如果该位置是空的，就用 CAS 的方式放入新值 if (casTabAt(tab, i, null, new Node&lt;K, V&gt;(hash, key, value, null))) &#123; break; &#125; &#125; //hash值等于 MOVED 代表在扩容 else if ((fh = f.hash) == MOVED) &#123; tab = helpTransfer(tab, f); &#125; //槽点上是有值的情况 else &#123; V oldVal = null; //用 synchronized 锁住当前槽点，保证并发安全 synchronized (f) &#123; if (tabAt(tab, i) == f) &#123; //如果是链表的形式 if (fh &gt;= 0) &#123; binCount = 1; //遍历链表 for (Node&lt;K, V&gt; e = f; ; ++binCount) &#123; K ek; //如果发现该 key 已存在，就判断是否需要进行覆盖，然后返回 if (e.hash == hash &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) &#123; oldVal = e.val; if (!onlyIfAbsent) &#123; e.val = value; &#125; break; &#125; Node&lt;K, V&gt; pred = e; //到了链表的尾部也没有发现该 key，说明之前不存在，就把新值添加到链表的最后 if ((e = e.next) == null) &#123; pred.next = new Node&lt;K, V&gt;(hash, key, value, null); break; &#125; &#125; &#125; //如果是红黑树的形式 else if (f instanceof TreeBin) &#123; Node&lt;K, V&gt; p; binCount = 2; //调用 putTreeVal 方法往红黑树里增加数据 if ((p = ((TreeBin&lt;K, V&gt;) f).putTreeVal(hash, key, value)) != null) &#123; oldVal = p.val; if (!onlyIfAbsent) &#123; p.val = value; &#125; &#125; &#125; &#125; &#125; if (binCount != 0) &#123; //检查是否满足条件并把链表转换为红黑树的形式，默认的 TREEIFY_THRESHOLD 阈值是 8 if (binCount &gt;= TREEIFY_THRESHOLD) &#123; treeifyBin(tab, i); &#125; //putVal 的返回是添加前的旧值，所以返回 oldVal if (oldVal != null) &#123; return oldVal; &#125; break; &#125; &#125; &#125; addCount(1L, binCount); return null;&#125; 可以看出，方法中会逐步根据当前槽点是未初始化、空、扩容、链表、红黑树等不同情况做出不同的处理。 get 方法源码分析 123456789101112131415161718192021222324public V get(Object key) &#123; Node&lt;K,V&gt;[] tab; Node&lt;K,V&gt; e, p; int n, eh; K ek; //计算 hash 值 int h = spread(key.hashCode()); //如果整个数组是空的，或者当前槽点的数据是空的，说明 key 对应的 value 不存在，直接返回 null if ((tab = table) != null &amp;&amp; (n = tab.length) &gt; 0 &amp;&amp; (e = tabAt(tab, (n - 1) &amp; h)) != null) &#123; //判断头结点是否就是我们需要的节点，如果是则直接返回 if ((eh = e.hash) == h) &#123; if ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek))) return e.val; &#125; //如果头结点 hash 值小于 0，说明是红黑树或者正在扩容，就用对应的 find 方法来查找 else if (eh &lt; 0) return (p = e.find(h, key)) != null ? p.val : null; //遍历链表来查找 while ((e = e.next) != null) &#123; if (e.hash == h &amp;&amp; ((ek = e.key) == key || (ek != null &amp;&amp; key.equals(ek)))) return e.val; &#125; &#125; return null;&#125; 总结一下 get 的过程： 计算 Hash 值，并由此值找到对应的槽点； 如果数组是空的或者该位置为 null，那么直接返回 null 就可以了； 如果该位置处的节点刚好就是我们需要的，直接返回该节点的值； 如果该位置节点是红黑树或者正在扩容，就用 find 方法继续查找； 否则那就是链表，就进行遍历链表查找。 对比Java7 和Java8 的异同和优缺点 数据结构 Java 7 采用 Segment 分段锁来实现，而 Java 8 中的 ConcurrentHashMap 使用数组 + 链表 + 红黑树，在这一点上它们的差别非常大。 并发度 Java 7 中，每个 Segment 独立加锁，最大并发个数就是 Segment 的个数，默认是 16。 但是到了 Java 8 中，锁粒度更细，理想情况下 table 数组元素的个数（也就是数组长度）就是其支持并发的最大个数，并发度比之前有提高。 保证并发安全的原理 Java 7 采用 Segment 分段锁来保证安全，而 Segment 是继承自 ReentrantLock。 Java 8 中放弃了 Segment 的设计，采用 Node + CAS + synchronized 保证线程安全。 遇到 Hash 碰撞 Java 7 在 Hash 冲突时，会使用拉链法，也就是链表的形式。 Java 8 先使用拉链法，在链表长度超过一定阈值时，将链表转换为红黑树，来提高查找效率。 查询时间复杂度 Java 7 遍历链表的时间复杂度是 O(n)，n 为链表长度。 Java 8 如果变成遍历红黑树，那么时间复杂度降低为 O(log(n))，n 为树的节点个数。 3.为什么 Map 桶中超过 8 个才转为红黑树？JDK 1.8 的 HashMap 和 ConcurrentHashMap 都有这样一个特点：最开始的 Map 是空的，因为里面没有任何元素，往里放元素时会计算 hash 值，计算之后，第 1 个 value 会首先占用一个桶（也称为槽点）位置，后续如果经过计算发现需要落到同一个桶中，那么便会使用链表的形式往后延长，俗称“拉链法”，如图所示： 图中，有的桶是空的， 比如第 4 个；有的只有一个元素，比如 1、3、6；有的就是刚才说的拉链法，比如第 2 和第 5 个桶。 当链表长度大于或等于阈值（默认为 8）的时候，如果同时还满足容量大于或等于 MIN_TREEIFY_CAPACITY（默认为 64）的要求，就会把链表转换为红黑树。同样，后续如果由于删除或者其他原因调整了大小，当红黑树的节点小于或等于 6 个以后，又会恢复为链表形态。 java8 HashMap 的结构示意图： 更多的时候我们会关注，为何转为红黑树以及红黑树的一些特点，可是，为什么转化的这个阈值要默认设置为 8 呢？要想知道为什么设置为 8，那首先我们就要知道为什么要转换，因为转换是第一步。 每次遍历一个链表，平均查找的时间复杂度是 O(n)，n 是链表的长度。红黑树有和链表不一样的查找性能，由于红黑树有自平衡的特点，可以防止不平衡情况的发生，所以可以始终将查找的时间复杂度控制在 O(log(n))。最初链表还不是很长，所以可能 O(n) 和 O(log(n)) 的区别不大，但是如果链表越来越长，那么这种区别便会有所体现。所以为了提升查找性能，需要把链表转化为红黑树的形式。 那为什么不一开始就用红黑树，反而要经历一个转换的过程呢？其实在 JDK 的源码注释中已经对这个问题作了解释： 1234Because TreeNodes are about twice the size of regular nodes,use them only when bins contain enough nodes to warrant use(see TREEIFY_THRESHOLD). And when they become too small (due removal or resizing) they are converted back to plain bins. 这段话的意思是：单个 TreeNode 需要占用的空间大约是普通 Node 的两倍，所以只有当包含足够多的 Nodes 时才会转成 TreeNodes，而是否足够多就是由 TREEIFY_THRESHOLD 的值决定的。而当桶中节点数由于移除或者 resize 变少后，又会变回普通的链表的形式，以便节省空间。 通过查看源码可以发现，默认是链表长度达到 8 就转成红黑树，而当长度降到 6 就转换回去，这体现了时间和空间平衡的思想，最开始使用链表的时候，空间占用是比较少的，而且由于链表短，所以查询时间也没有太大的问题。可是当链表越来越长，需要用红黑树的形式来保证查询的效率。对于何时应该从链表转化为红黑树，需要确定一个阈值，这个阈值默认为 8，并且在源码中也对选择 8 这个数字做了说明，原文如下： 1234567891011121314151617181920In usages with well-distributed user hashCodes, tree bins are rarely used. Ideally, under random hashCodes, the frequency of nodes in bins follows a Poisson distribution (http:&#x2F;&#x2F;en.wikipedia.org&#x2F;wiki&#x2F;Poisson_distribution) with a parameter of about 0.5 on average for the default resizing threshold of 0.75, although with a large variance because of resizing granularity. Ignoring variance, the expected occurrences of list size k are (exp(-0.5) * pow(0.5, k) &#x2F; factorial(k)). The first values are: 0: 0.60653066 1: 0.30326533 2: 0.07581633 3: 0.01263606 4: 0.00157952 5: 0.00015795 6: 0.00001316 7: 0.00000094 8: 0.00000006 more: less than 1 in ten million 这段话的意思是，如果 hashCode 分布良好，也就是 hash 计算的结果离散好的话，那么红黑树这种形式是很少会被用到的，因为各个值都均匀分布，很少出现链表很长的情况。在理想情况下，链表长度符合泊松分布，各个长度的命中概率依次递减，当长度为 8 的时候，概率仅为 0.00000006。这是一个小于千万分之一的概率，通常我们的 Map 里面是不会存储这么多的数据的，所以通常情况下，并不会发生从链表向红黑树的转换。 但是，HashMap 决定某一个元素落到哪一个桶里，是和这个对象的 hashCode 有关的，JDK 并不能阻止我们用户实现自己的哈希算法，如果我们故意把哈希算法变得不均匀，例如： 1234@Overridepublic int hashCode() &#123; return 1;&#125; 这里 hashCode 计算出来的值始终为 1，那么就很容易导致 HashMap 里的链表变得很长。来看下面这段代码： 12345678910111213141516public class HashMapDemo &#123; public static void main(String[] args) &#123; HashMap map = new HashMap&lt;HashMapDemo,Integer&gt;(1); for (int i = 0; i &lt; 1000; i++) &#123; HashMapDemo hashMapDemo1 = new HashMapDemo(); map.put(hashMapDemo1, null); &#125; System.out.println(\"运行结束\"); &#125; @Override public int hashCode() &#123; return 1; &#125;&#125; 在这个例子中，我们建了一个 HashMap，并且不停地往里放入值，所放入的 key 的对象，它的 hashCode 是被重写过得，并且始终返回 1。这段代码运行时，如果通过 debug 让程序暂停在 System.out.println(“运行结束”) 这行语句，我们观察 map 内的节点，可以发现已经变成了 TreeNode，而不是通常的 Node，这说明内部已经转为了红黑树。 事实上，链表长度超过 8 就转为红黑树的设计，更多的是为了防止用户自己实现了不好的哈希算法时导致链表过长，从而导致查询效率低，而此时转为红黑树更多的是一种保底策略，用来保证极端情况下查询的效率。 通常如果 hash 算法正常的话，那么链表的长度也不会很长，那么红黑树也不会带来明显的查询时间上的优势，反而会增加空间负担。所以通常情况下，并没有必要转为红黑树，所以就选择了概率非常小，小于千万分之一概率，也就是长度为 8 的概率，把长度 8 作为转化的默认阈值。 所以如果平时开发中发现 HashMap 或是 ConcurrentHashMap 内部出现了红黑树的结构，这个时候往往就说明我们的哈希算法出了问题，需要留意是不是我们实现了效果不好的 hashCode 方法，并对此进行改进，以便减少冲突。 4.同样是线程安全，ConcurrentHashMap 和 Hashtable 的区别？出现的版本不同 Hashtable 在 JDK1.0 的时候就存在了，并在 JDK1.2 版本中实现了 Map 接口，成为了集合框架的一员。而 ConcurrentHashMap 则是在 JDK1.5 中才出现的，也正是因为它们出现的年代不同，而后出现的往往是对前面出现的类的优化，所以它们在实现方式以及性能上，也存在着较大的不同。 实现线程安全的方式不同 虽然 ConcurrentHashMap 和 Hashtable 它们两个都是线程安全的，但是从原理上分析，Hashtable 实现并发安全的原理是通过 synchronized 关键字，让我们直接看下源码，以 clear() 方法为例，代码如下： 1234567public synchronized void clear() &#123; Entry&lt;?,?&gt; tab[] = table; modCount++; for (int index = tab.length; --index &gt;= 0; ) tab[index] = null; count = 0;&#125; 可以看出这个 clear() 方法是被 synchronized 关键字所修饰的，同理其他的方法例如 put、get、size 等，也同样是被 synchronized 关键字修饰的。之所以 Hashtable 是线程安全的，是因为几乎每个方法都被 synchronized 关键字所修饰了，这也就保证了线程安全。 Collections.SynchronizedMap(new HashMap()) 的原理和 Hashtable 类似，也是利用 synchronized 实现的。 ConcurrentHashMap 本质上实现线程安全的原理是利用了 CAS + synchronized + Node 节点的方式。 性能不同 正因为它们在线程安全的实现方式上的不同，导致它们在性能方面也有很大的不同。当线程数量增加的时候，Hashtable 的性能会急剧下降，因为每一次修改都需要锁住整个对象，而其他线程在此期间是不能操作的。不仅如此，还会带来额外的上下文切换等开销，所以此时它的吞吐量甚至还不如单线程的情况。 而在 ConcurrentHashMap 中，就算上锁也仅仅会对一部分上锁而不是全部都上锁，所以多线程中的吞吐量通常都会大于单线程的情况，也就是说，在并发效率上，ConcurrentHashMap 比 Hashtable 提高了很多。 迭代时修改的不同 Hashtable（包括 HashMap）不允许在迭代期间修改内容，否则会抛出ConcurrentModificationException 异常，其原理是检测 modCount 变量，迭代器的 next() 方法的代码如下： 12345public T next() &#123; if (modCount != expectedModCount) throw new ConcurrentModificationException(); return nextElement();&#125; 可以看出在这个 next() 方法中，会首先判断 modCount 是否等于 expectedModCount。其中 expectedModCount 是在迭代器生成的时候随之生成的，并且不会改变。它所代表的含义是当前 Hashtable 被修改的次数，而每一次去调用 Hashtable 的包括 addEntry()、remove()、rehash() 等方法中，都会修改 modCount 的值。这样一来，如果我们在迭代的过程中，去对整个 Hashtable 的内容做了修改的话，也就同样会反映到 modCount 中。这样一来，迭代器在进行 next 的时候，也可以感知到，于是它就会发现 modCount 不等于 expectedModCount，就会抛出 ConcurrentModificationException 异常。 所以对于 Hashtable 而言，它是不允许在迭代期间对内容进行修改的。相反，ConcurrentHashMap 即便在迭代期间修改内容，也不会抛出ConcurrentModificationException。 5.CopyOnWriteArrayList 有什么特点？其实在 CopyOnWriteArrayList 出现之前，我们已经有了 ArrayList 和 LinkedList 作为 List 的数组和链表的实现，而且也有了线程安全的 Vector 和 Collections.synchronizedList() 可以使用。所以首先就让我们来看下线程安全的 Vector 的 size 和 get 方法的代码： 12345678public synchronized int size() &#123; return elementCount;&#125;public synchronized E get(int index) &#123; if (index &gt;= elementCount) throw new ArrayIndexOutOfBoundsException(index); return elementData(index);&#125; 可以看出，Vector 内部是使用 synchronized 来保证线程安全的，并且锁的粒度比较大，都是方法级别的锁，在并发量高的时候，很容易发生竞争，并发效率相对比较低。在这一点上，Vector 和 Hashtable 很类似。 并且，前面这几种 List 在迭代期间不允许编辑，如果在迭代期间进行添加或删除元素等操作，则会抛出 ConcurrentModificationException 异常，这样的特点也在很多情况下给使用者带来了麻烦。 所以从 JDK1.5 开始，Java 并发包里提供了使用 CopyOnWrite 机制实现的并发容器 CopyOnWriteArrayList 作为主要的并发 List，CopyOnWrite 的并发集合还包括 CopyOnWriteArraySet，其底层正是利用CopyOnWriteArrayList 实现的。 适用场景 读操作可以尽可能的快，而写即使慢一些也没关系 在很多应用场景中，读操作可能会远远多于写操作。比如，有些系统级别的信息，往往只需要加载或者修改很少的次数，但是会被系统内所有模块频繁的访问。对于这种场景，我们最希望看到的就是读操作可以尽可能的快，而写即使慢一些也没关系。 读多写少 黑名单是最典型的场景，假如我们有一个搜索网站，用户在这个网站的搜索框中，输入关键字搜索内容，但是某些关键字不允许被搜索。这些不能被搜索的关键字会被放在一个黑名单中，黑名单并不需要实时更新，可能每天晚上更新一次就可以了。当用户搜索时，会检查当前关键字在不在黑名单中，如果在，则提示不能搜索。这种读多写少的场景也很适合使用 CopyOnWrite 集合。 读写规则 读写锁的规则 读写锁的思想是：读读共享、其他都互斥（写写互斥、读写互斥、写读互斥），原因是由于读操作不会修改原有的数据，因此并发读并不会有安全问题；而写操作是危险的，所以当写操作发生时，不允许有读操作加入，也不允许第二个写线程加入。 对读写锁规则的升级 CopyOnWriteArrayList 的思想比读写锁的思想又更进一步。为了将读取的性能发挥到极致，CopyOnWriteArrayList 读取是完全不用加锁的，更厉害的是，写入也不会阻塞读取操作，也就是说你可以在写入的同时进行读取，只有写入和写入之间需要进行同步，也就是不允许多个写入同时发生，但是在写入发生时允许读取同时发生。这样一来，读操作的性能就会大幅度提升。 特点 CopyOnWrite的含义 从 CopyOnWriteArrayList 的名字就能看出它是满足 CopyOnWrite 的 ArrayList，CopyOnWrite 的意思是说，当容器需要被修改的时候，不直接修改当前容器，而是先将当前容器进行 Copy，复制出一个新的容器，然后修改新的容器，完成修改之后，再将原容器的引用指向新的容器。这样就完成了整个修改过程。 这样做的好处是，CopyOnWriteArrayList 利用了“不变性”原理，因为容器每次修改都是创建新副本，所以对于旧容器来说，其实是不可变的，也是线程安全的，无需进一步的同步操作。我们可以对 CopyOnWrite 容器进行并发的读，而不需要加锁，因为当前容器不会添加任何元素，也不会有修改。 CopyOnWriteArrayList 的所有修改操作（add，set等）都是通过创建底层数组的新副本来实现的，所以 CopyOnWrite 容器也是一种读写分离的思想体现，读和写使用不同的容器。 迭代期间允许修改集合内容 我们知道 ArrayList 在迭代期间如果修改集合的内容，会抛出 ConcurrentModificationException 异常。让我们来分析一下 ArrayList 会抛出异常的原因。 在 ArrayList 源码里的 ListItr 的 next 方法中有一个 checkForComodification 方法，代码如下： 1234final void checkForComodification() &#123; if (modCount != expectedModCount) throw new ConcurrentModificationException();&#125; 这里会首先检查 modCount 是否等于 expectedModCount。modCount 是保存修改次数，每次我们调用 add、remove 或 trimToSize 等方法时它会增加，expectedModCount 是迭代器的变量，当我们创建迭代器时会初始化并记录当时的 modCount。后面迭代期间如果发现 modCount 和 expectedModCount 不一致，就说明有人修改了集合的内容，就会抛出异常。 和 ArrayList 不同的是，CopyOnWriteArrayList 的迭代器在迭代的时候，如果数组内容被修改了，CopyOnWriteArrayList 不会报 ConcurrentModificationException 的异常，因为迭代器使用的依然是旧数组，只不过迭代的内容可能已经过时了。演示代码如下： 123456789101112131415161718192021/*** 描述： 演示CopyOnWriteArrayList迭代期间可以修改集合的内容*/public class CopyOnWriteArrayListDemo &#123; public static void main(String[] args) &#123; CopyOnWriteArrayList&lt;Integer&gt; list = new CopyOnWriteArrayList&lt;&gt;(new Integer[]&#123;1, 2, 3&#125;); System.out.println(list); //[1, 2, 3] //Get iterator 1 Iterator&lt;Integer&gt; itr1 = list.iterator(); //Add one element and verify list is updated list.add(4); System.out.println(list); //[1, 2, 3, 4] //Get iterator 2 Iterator&lt;Integer&gt; itr2 = list.iterator(); System.out.println(\"====Verify Iterator 1 content====\"); itr1.forEachRemaining(System.out::println); //1,2,3 System.out.println(\"====Verify Iterator 2 content====\"); itr2.forEachRemaining(System.out::println); //1,2,3,4 &#125;&#125; 这段代码会首先创建一个 CopyOnWriteArrayList，并且初始值被赋为 [1, 2, 3]，此时打印出来的结果很明显就是 [1, 2, 3]。然后我们创建一个叫作 itr1 的迭代器，创建之后再添加一个新的元素，利用 list.add() 方法把元素 4 添加进去，此时我们打印出 List 自然是 [1, 2, 3, 4]。我们再创建一个叫作 itr2 的迭代器，在下方把两个迭代器迭代产生的内容打印出来，这段代码的运行结果是： 1234567891011[1, 2, 3][1, 2, 3, 4]&#x3D;&#x3D;&#x3D;&#x3D;Verify Iterator 1 content&#x3D;&#x3D;&#x3D;&#x3D;123&#x3D;&#x3D;&#x3D;&#x3D;Verify Iterator 2 content&#x3D;&#x3D;&#x3D;&#x3D;1234 可以看出，这两个迭代器打印出来的内容是不一样的。第一个迭代器打印出来的是 [1, 2, 3]，而第二个打印出来的是 [1, 2, 3, 4]。虽然它们的打印时机都发生在第四个元素被添加之后，但它们的创建时机是不同的。由于迭代器 1 被创建时的 List 里面只有三个元素，后续无论 List 有什么修改，对它来说都是无感知的。 以上这个结果说明了，CopyOnWriteArrayList 的迭代器一旦被建立之后，如果往之前的 CopyOnWriteArrayList 对象中去新增元素，在迭代器中既不会显示出元素的变更情况，同时也不会报错，这一点和 ArrayList 是有很大区别的。 缺点 这些缺点不仅是针对 CopyOnWriteArrayList，其实同样也适用于其他的 CopyOnWrite 容器： 内存占用问题 因为 CopyOnWrite 的写时复制机制，所以在进行写操作的时候，内存里会同时驻扎两个对象的内存，这一点会占用额外的内存空间。 在元素较多或者复杂的情况下，复制的开销很大 复制过程不仅会占用双倍内存，还需要消耗 CPU 等资源，会降低整体性能。 数据一致性问题 由于 CopyOnWrite 容器的修改是先修改副本，所以这次修改对于其他线程来说，并不是实时能看到的，只有在修改完之后才能体现出来。如果你希望写入的的数据马上能被其他线程看到，CopyOnWrite 容器是不适用的。","tags":[{"name":"java","slug":"java","permalink":"https://sunshine-zwq.gitee.io/tags/java/"},{"name":"并发编程","slug":"并发编程","permalink":"https://sunshine-zwq.gitee.io/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"},{"name":"面试","slug":"面试","permalink":"https://sunshine-zwq.gitee.io/tags/%E9%9D%A2%E8%AF%95/"}]},{"title":"Java并发编程常见问题-各种各样的“锁”","date":"2020-12-17T06:43:40.000Z","path":"2020/12/17/Java并发编程常见问题-各种各样的“锁”/","text":"1.你知道哪几种锁？分别有什么特点？锁的 7 大分类 对于 Java 中的锁而言，一把锁也有可能同时占有多个标准，符合多种分类，比如 ReentrantLock 既是可中断锁，又是可重入锁。 根据分类标准我们把锁分为以下 7 大类别，分别是： 偏向锁/轻量级锁/重量级锁； 可重入锁/非可重入锁； 共享锁/独占锁； 公平锁/非公平锁； 悲观锁/乐观锁； 自旋锁/非自旋锁； 可中断锁/不可中断锁。 偏向锁/轻量级锁/重量级锁 这三种锁特指 synchronized 锁的状态，通过在对象头中的 mark word 来表明锁的状态。 偏向锁 如果自始至终，对于这把锁都不存在竞争，那么其实就没必要上锁，只需要打个标记就行了，这就是偏向锁的思想。一个对象被初始化后，还没有任何线程来获取它的锁时，那么它就是可偏向的，当有第一个线程来访问它并尝试获取锁的时候，它就将这个线程记录下来，以后如果尝试获取锁的线程正是偏向锁的拥有者，就可以直接获得锁，开销很小，性能最好。 轻量级锁 JVM 开发者发现在很多情况下，synchronized 中的代码是被多个线程交替执行的，而不是同时执行的，也就是说并不存在实际的竞争，或者是只有短时间的锁竞争，用 CAS 就可以解决，这种情况下，用完全互斥的重量级锁是没必要的。轻量级锁是指当锁原来是偏向锁的时候，被另一个线程访问，说明存在竞争，那么偏向锁就会升级为轻量级锁，线程会通过自旋的形式尝试获取锁，而不会陷入阻塞。 重量级锁 重量级锁是互斥锁，它是利用操作系统的同步机制实现的，所以开销相对比较大。当多个线程直接有实际竞争，且锁竞争时间长的时候，轻量级锁不能满足需求，锁就会膨胀为重量级锁。重量级锁会让其他申请却拿不到锁的线程进入阻塞状态。 可以发现锁升级的路径：无锁→偏向锁→轻量级锁→重量级锁。 综上所述，偏向锁性能最好，可以避免执行 CAS 操作。而轻量级锁利用自旋和 CAS 避免了重量级锁带来的线程阻塞和唤醒，性能中等。重量级锁则会把获取不到锁的线程阻塞，性能最差。 可重入锁/非可重入锁 第 2 个分类是可重入锁和非可重入锁。可重入锁指的是线程当前已经持有这把锁了，能在不释放这把锁的情况下，再次获取这把锁。同理，不可重入锁指的是虽然线程当前持有了这把锁，但是如果想再次获取这把锁，也必须要先释放锁后才能再次尝试获取。 对于可重入锁而言，最典型的就是 ReentrantLock 了，正如它的名字一样，reentrant 的意思就是可重入，它也是 Lock 接口最主要的一个实现类。 共享锁/独占锁 第 3 种分类标准是共享锁和独占锁。共享锁指的是我们同一把锁可以被多个线程同时获得，而独占锁指的就是，这把锁只能同时被一个线程获得。我们的读写锁，就最好地诠释了共享锁和独占锁的理念。读写锁中的读锁，是共享锁，而写锁是独占锁。读锁可以被同时读，可以同时被多个线程持有，而写锁最多只能同时被一个线程持有。 公平锁/非公平锁 第 4 种分类是公平锁和非公平锁。公平锁的公平的含义在于如果线程现在拿不到这把锁，那么线程就都会进入等待，开始排队，在等待队列里等待时间长的线程会优先拿到这把锁，有先来先得的意思。而非公平锁就不那么“完美”了，它会在一定情况下，忽略掉已经在排队的线程，发生插队现象。 悲观锁/乐观锁 第 5 种分类是悲观锁，以及与它对应的乐观锁。悲观锁的概念是在获取资源之前，必须先拿到锁，以便达到“独占”的状态，当前线程在操作资源的时候，其他线程由于不能拿到锁，所以其他线程不能来影响我。而乐观锁恰恰相反，它并不要求在获取资源前拿到锁，也不会锁住资源；相反，乐观锁利用 CAS 理念，在不独占资源的情况下，完成了对资源的修改。 自旋锁/非自旋锁 第 6 种分类是自旋锁与非自旋锁。自旋锁的理念是如果线程现在拿不到锁，并不直接陷入阻塞或者释放 CPU资源，而是开始利用循环，不停地尝试获取锁，这个循环过程被形象地比喻为“自旋”，就像是线程在“自我旋转”。相反，非自旋锁的理念就是没有自旋的过程，如果拿不到锁就直接放弃，或者进行其他的处理逻辑，例如去排队、陷入阻塞等。 可中断锁/不可中断锁 第 7 种分类是可中断锁和不可中断锁。在 Java 中，synchronized 关键字修饰的锁代表的是不可中断锁，一旦线程申请了锁，就没有回头路了，只能等到拿到锁以后才能进行其他的逻辑处理。而我们的 ReentrantLock 是一种典型的可中断锁，例如使用 lockInterruptibly 方法在获取锁的过程中，突然不想获取了，那么也可以在中断之后去做其他的事情，不需要一直傻等到获取到锁才离开。 2.悲观锁和乐观锁的本质是什么？悲观锁 悲观锁比较悲观，它认为如果不锁住这个资源，别的线程就会来争抢，就会造成数据结果错误，所以悲观锁为了确保结果的正确性，会在每次获取并修改数据时，都把数据锁住，让其他线程无法访问该数据，这样就可以确保数据内容万无一失。 这也和我们人类中悲观主义者的性格是一样的，悲观主义者做事情之前总是担惊受怕，所以会严防死守，保证别人不能来碰我的东西，这就是悲观锁名字的含义。 乐观锁 乐观锁比较乐观，认为自己在操作资源的时候不会有其他线程来干扰，所以并不会锁住被操作对象，不会不让别的线程来接触它，同时，为了确保数据正确性，在更新之前，会去对比在我修改数据期间，数据有没有被其他线程修改过：如果没被修改过，就说明真的只有我自己在操作，那我就可以正常的修改数据；如果发现数据和我一开始拿到的不一样了，说明其他线程在这段时间内修改过数据，那说明我迟了一步，所以我会放弃这次修改，并选择报错、重试等策略。 这和我们生活中乐天派的人的性格是一样的，乐观的人并不会担忧还没有发生的事情，相反，他会认为未来是美好的，所以他在修改数据之前，并不会把数据给锁住。当然，乐天派也不会盲目行动，如果他发现事情和他预想的不一样，也会有相应的处理办法，他不会坐以待毙，这就是乐观锁的思想。 乐观锁的实现一般都是利用 CAS 算法实现的。 悲观锁和乐观锁概念并不是 Java 中独有的，这是一种广义的思想，这种思想可以应用于其他领域，比如说在数据库中，同样也有对悲观锁和乐观锁的应用。 典型案例 悲观锁：synchronized 关键字和 Lock 接口 Java 中悲观锁的实现包括 synchronized 关键字和 Lock 相关类等，我们以 Lock 接口为例，例如 Lock 的实现类 ReentrantLock，类中的 lock() 等方法就是执行加锁，而 unlock() 方法是执行解锁。处理资源之前必须要先加锁并拿到锁，等到处理完了之后再解开锁，这就是非常典型的悲观锁思想。 乐观锁：原子类 乐观锁的典型案例就是原子类，例如 AtomicInteger 在更新数据时，就使用了乐观锁的思想，多个线程可以同时操作同一个原子变量。 大喜大悲：数据库 数据库中同时拥有悲观锁和乐观锁的思想。例如，我们如果在 MySQL 选择 select for update 语句，那就是悲观锁，在提交之前不允许第三方来修改该数据，这当然会造成一定的性能损耗，在高并发的情况下是不可取的。 相反，我们可以利用一个版本 version 字段在数据库中实现乐观锁。在获取及修改数据时都不需要加锁，但是我们在获取完数据并计算完毕，准备更新数据时，会检查版本号和获取数据时的版本号是否一致，如果一致就直接更新，如果不一致，说明计算期间已经有其他线程修改过这个数据了，那我就可以选择重新获取数据，重新计算，然后再次尝试更新数据。 悲观锁的性能不如乐观锁好，应该尽量避免用悲观锁，这种说法对吗？ 有一种说法认为，悲观锁由于它的操作比较重量级，不能多个线程并行执行，而且还会有上下文切换等动作，所以悲观锁的性能不如乐观锁好，应该尽量避免用悲观锁，这种说法是不正确的。 因为虽然悲观锁确实会让得不到锁的线程阻塞，但是这种开销是固定的。悲观锁的原始开销确实要高于乐观锁，但是特点是一劳永逸，就算一直拿不到锁，也不会对开销造成额外的影响。 反观乐观锁虽然一开始的开销比悲观锁小，但是如果一直拿不到锁，或者并发量大，竞争激烈，导致不停重试，那么消耗的资源也会越来越多，甚至开销会超过悲观锁。 所以，同样是悲观锁，在不同的场景下，效果可能完全不同，可能在今天的这种场景下是好的选择，在明天的另外的场景下就是坏的选择，这恰恰是“汝之蜜糖，彼之砒霜”。 因此，我们就来看一下两种锁各自的使用场景，把合适的锁用到合适的场景中去，把合理的资源分配到合理的地方去。 两种锁各自的使用场景 悲观锁适合用于并发写入多、临界区代码复杂、竞争激烈等场景，这种场景下悲观锁可以避免大量的无用的反复尝试等消耗。 乐观锁适用于大部分是读取，少部分是修改的场景，也适合虽然读写都很多，但是并发并不激烈的场景。在这些场景下，乐观锁不加锁的特点能让性能大幅提高。 3.如何看到 synchronized 背后的“monitor 锁”？获取和释放 monitor 锁的时机 最简单的同步方式是利用 synchronized 关键字来修饰代码块或者修饰一个方法，那么这部分被保护的代码，在同一时刻就最多只有一个线程可以运行，而 synchronized 的背后正是利用 monitor 锁实现的。每个 Java 对象都可以用作一个实现同步的锁，这个锁也被称为内置锁或 monitor 锁，获得 monitor 锁的唯一途径就是进入由这个锁保护的同步代码块或同步方法，线程在进入被 synchronized 保护的代码块之前，会自动获取锁，并且无论是正常路径退出，还是通过抛出异常退出，在退出的时候都会自动释放锁。 先看一个 synchronized 修饰方法的代码的例子： 123public synchronized void method() &#123; method body&#125; method() 方法是被 synchronized 修饰的，为了方便理解其背后的原理，把上面这段代码改写为下面这种等价形式的伪代码： 123456789public void method() &#123; this.intrinsicLock.lock(); try&#123; method body &#125; finally &#123; this.intrinsicLock.unlock(); &#125;&#125; 在这种写法中，进入 method 方法后，立刻添加内置锁，并且用 try 代码块把方法保护起来，最后用 finally 释放这把锁，这里的 intrinsicLock 就是 monitor 锁。 用 javap 命令查看反汇编的结果 (1).同步代码块 JVM 实现 synchronized 方法和 synchronized 代码块的细节是不一样的，分别来看一下两者的实现。 1234567public class SynTest &#123; public void synBlock() &#123; synchronized (this) &#123; System.out.println(\"hello\"); &#125; &#125;&#125; 在 SynTest 类中的 synBlock 方法，包含一个同步代码块，synchronized 代码块中有一行代码打印了 hello 字符串，下面我们来通过命令看下 synchronized 关键字到底做了什么事情：首先用 cd 命令切换到 SynTest.java 类所在的路径，然后执行 javac SynTest.java，于是就会产生一个名为 SynTest.class 的字节码文件，然后我们执行 javap -verbose SynTest.class，就可以看到对应的反汇编内容。 关键信息如下： 123456789101112131415161718192021public void synBlock(); descriptor: ()V flags: ACC_PUBLIC Code: stack&#x3D;2, locals&#x3D;3, args_size&#x3D;1 0: aload_0 1: dup 2: astore_1 3: monitorenter 4: getstatic #2 &#x2F;&#x2F; Field java&#x2F;lang&#x2F;System.out:Ljava&#x2F;io&#x2F;PrintStream; 7: ldc #3 &#x2F;&#x2F; String lagou 9: invokevirtual #4 &#x2F;&#x2F; Method java&#x2F;io&#x2F;PrintStream.println:(Ljava&#x2F;lang&#x2F;String;)V 12: aload_1 13: monitorexit 14: goto 22 17: astore_2 18: aload_1 19: monitorexit 20: aload_2 21: athrow 22: return 从里面可以看出，synchronized 代码块实际上多了 monitorenter 和 monitorexit 指令，第3、13、19行指令分别对应的是 monitorenter 和 monitorexit。这里有一个 monitorenter，却有两个 monitorexit 指令的原因是，JVM 要保证每个 monitorenter 必须有与之对应的 monitorexit，monitorenter 指令被插入到同步代码块的开始位置，而 monitorexit 需要插入到方法正常结束处和异常处两个地方，这样就可以保证抛异常的情况下也能释放锁。 可以把执行 monitorenter 理解为加锁，执行 monitorexit 理解为释放锁，每个对象维护着一个记录着被锁次数的计数器。未被锁定的对象的该计数器为 0，我们来具体看一下 monitorenter 和 monitorexit 的含义： monitorenter 执行 monitorenter 的线程尝试获得 monitor 的所有权，会发生以下这三种情况之一： a. 如果该 monitor 的计数为 0，则线程获得该 monitor 并将其计数设置为 1。然后，该线程就是这个 monitor 的所有者。 b. 如果线程已经拥有了这个 monitor ，则它将重新进入，并且累加计数。 c. 如果其他线程已经拥有了这个 monitor，那个这个线程就会被阻塞，直到这个 monitor 的计数变成为 0，代表这个 monitor 已经被释放了，于是当前这个线程就会再次尝试获取这个 monitor。 monitorexitmonitorexit 的作用是将 monitor 的计数器减 1，直到减为 0 为止。代表这个 monitor 已经被释放了，已经没有任何线程拥有它了，也就代表着解锁，所以，其他正在等待这个 monitor 的线程，此时便可以再次尝试获取这个 monitor 的所有权。 (2).同步方法 从上面可以看出，同步代码块是使用 monitorenter 和 monitorexit 指令实现的。而对于 synchronized 方法，并不是依靠 monitorenter 和 monitorexit 指令实现的，被 javap 反汇编后可以看到，synchronized 方法和普通方法大部分是一样的，不同在于，这个方法会有一个叫作 ACC_SYNCHRONIZED 的 flag 修饰符，来表明它是同步方法。 同步方法的代码如下所示： 123public synchronized void synMethod() &#123; &#125; 对应的反汇编指令如下所示： 12345678public synchronized void synMethod(); descriptor: ()V flags: ACC_PUBLIC, ACC_SYNCHRONIZED Code: stack&#x3D;0, locals&#x3D;1, args_size&#x3D;1 0: return LineNumberTable: line 16: 0 可以看出，被 synchronized 修饰的方法会有一个 ACC_SYNCHRONIZED 标志。当某个线程要访问某个方法的时候，会首先检查方法是否有 ACC_SYNCHRONIZED 标志，如果有则需要先获得 monitor 锁，然后才能开始执行方法，方法执行之后再释放 monitor 锁。其他方面， synchronized 方法和刚才的 synchronized 代码块是很类似的，例如这时如果其他线程来请求执行方法，也会因为无法获得 monitor 锁而被阻塞。 4.synchronized 和 Lock 孰优孰劣，如何选择？相同点 synchronized 和 Lock 都是用来保护资源线程安全的。 都可以保证可见性。 对于 synchronized 而言，线程 A 在进入 synchronized 块之前或在 synchronized 块内进行操作，对于后续的获得同一个 monitor 锁的线程 B 是可见的，也就是线程 B 是可以看到线程 A 之前的操作的，这也体现了 happens-before 针对 synchronized 的一个原则。 而对于 Lock 而言，它和 synchronized 是一样，都可以保证可见性，如图所示，在解锁之前的所有操作对加锁之后的所有操作都是可见的。 synchronized 和 ReentrantLock 都拥有可重入的特点。 这里的 ReentrantLock 是 Lock 接口的一个最主要的实现类，在对比 synchronized 和 Lock 的时候，也会选择 Lock 的主要实现类来进行对比。可重入指的是某个线程如果已经获得了一个锁，现在试图再次请求这个它已经获得的锁，如果它无需提前释放这个锁，而是直接可以继续使用持有的这个锁，那么就是可重入的。如果必须释放锁后才能再次申请这个锁，就是不可重入的。而 synchronized 和 ReentrantLock 都具有可重入的特性。 不同点 用法区别 synchronized 关键字可以加在方法上，不需要指定锁对象（此时的锁对象为 this），也可以新建一个同步代码块并且自定义 monitor 锁对象；而 Lock 接口必须显示用 Lock 锁对象开始加锁 lock() 和解锁 unlock()，并且一般会在 finally 块中确保用 unlock() 来解锁，以防发生死锁。与 Lock 显式的加锁和解锁不同的是 synchronized 的加解锁是隐式的，尤其是抛异常的时候也能保证释放锁，但是 Java 代码中并没有相关的体现。 加解锁顺序不同 对于 Lock 而言如果有多把 Lock 锁，Lock 可以不完全按照加锁的反序解锁，比如可以先获取 Lock1 锁，再获取 Lock2 锁，解锁时则先解锁 Lock1，再解锁 Lock2，加解锁有一定的灵活度，如代码所示： 12345lock1.lock();lock2.lock();...lock1.unlock();lock2.unlock(); 但是 synchronized 无法做到，synchronized 解锁的顺序和加锁的顺序必须完全相反，例如： 12345synchronized(obj1)&#123; synchronized(obj2)&#123; ... &#125;&#125; 那么在这里，顺序就是先对 obj1 加锁，然后对 obj2 加锁，然后对 obj2 解锁，最后解锁 obj1。这是因为 synchronized 加解锁是由 JVM 实现的，在执行完 synchronized 块后会自动解锁，所以会按照 synchronized的嵌套顺序加解锁，不能自行控制。 synchronized 锁不够灵活 一旦 synchronized 锁已经被某个线程获得了，此时其他线程如果还想获得，那它只能被阻塞，直到持有锁的线程运行完毕或者发生异常从而释放这个锁。如果持有锁的线程持有很长时间才释放，那么整个程序的运行效率就会降低，而且如果持有锁的线程永远不释放锁，那么尝试获取锁的线程只能永远等下去。 相比之下，Lock 类在等锁的过程中，如果使用的是 lockInterruptibly 方法，那么如果觉得等待的时间太长了不想再继续等待，可以中断退出，也可以用 tryLock() 等方法尝试获取锁，如果获取不到锁也可以做别的事，更加灵活。 synchronized 锁只能同时被一个线程拥有，但是 Lock 锁没有这个限制 例如在读写锁中的读锁，是可以同时被多个线程持有的，可是 synchronized 做不到。 原理区别synchronized 是内置锁，由 JVM 实现获取锁和释放锁的原理，还分为偏向锁、轻量级锁、重量级锁。 Lock 根据实现不同，有不同的原理，例如 ReentrantLock 内部是通过 AQS 来获取和释放锁的。 是否可以设置公平/非公平 公平锁是指多个线程在等待同一个锁时，根据先来后到的原则依次获得锁。ReentrantLock 等 Lock 实现类可以根据自己的需要来设置公平或非公平，synchronized 则不能设置（synchronized 是非公平锁）。 性能区别 在 Java 5 以及之前，synchronized 的性能比较低，但是到了 Java 6 以后，发生了变化，因为 JDK 对 synchronized 进行了很多优化，比如自适应自旋、锁消除、锁粗化、轻量级锁、偏向锁等，所以后期的 Java 版本里的 synchronized 的性能并不比 Lock 差。 如何选择 如果能不用最好既不使用 Lock 也不使用 synchronized。因为在许多情况下你可以使用 java.util.concurrent 包中的机制，它会为你处理所有的加锁和解锁操作，也就是推荐优先使用工具类来加解锁。 如果 synchronized 关键字适合你的程序， 那么请尽量使用它，这样可以减少编写代码的数量，减少出错的概率。因为一旦忘记在 finally 里 unlock，代码可能会出很大的问题，而使用 synchronized 更安全。 如果特别需要 Lock 的特殊功能，比如尝试获取锁、可中断、超时功能等，才使用 Lock。 5.Lock 有哪几个常用方法？分别有什么用？简介 Lock 接口是 Java 5 引入的，最常见的实现类是 ReentrantLock，可以起到“锁”的作用。 Lock 并不是用来代替 synchronized 的，而是当使用 synchronized 不合适或不足以满足要求的时候，Lock 可以用来提供更高级功能的。 通常情况下，Lock 只允许一个线程来访问这个共享资源。不过有的时候，一些特殊的实现也可允许并发访问，比如 ReadWriteLock 里面的 ReadLock。 方法纵览 12345678public interface Lock &#123; void lock(); void lockInterruptibly() throws InterruptedException; boolean tryLock(); boolean tryLock(long time, TimeUnit unit) throws InterruptedException; void unlock(); Condition newCondition();&#125; lock() 方法 lock() 是最基础的获取锁的方法。在线程获取锁时如果锁已被其他线程获取，则进行等待，是最初级的获取锁的方法。 对于 Lock 接口而言，获取锁和释放锁都是显式的，不像 synchronized 那样是隐式的，所以 Lock 不会像 synchronized 一样在异常时自动释放锁（synchronized 即使不写对应的代码也可以释放），lock 的加锁和释放锁都必须以代码的形式写出来，所以使用 lock() 时必须由我们自己主动去释放锁，因此最佳实践是执行 lock() 后，首先在 try{} 中操作同步资源，如果有必要就用 catch{} 块捕获异常，然后在 finally{} 中释放锁，以保证发生异常时锁一定被释放，示例代码如下所示： 12345678Lock lock = ...;lock.lock();try&#123; //获取到了被本锁保护的资源，处理任务 //捕获异常&#125;finally&#123; lock.unlock(); //释放锁&#125; 如果不遵守在 finally 里释放锁的规范，就会让 Lock 变得非常危险，因为你不知道未来什么时候由于异常的发生，导致跳过了 unlock() 语句，使得这个锁永远不能被释放了，其他线程也无法再获得这个锁，这就是 Lock 相比于 synchronized 的一个劣势，使用 synchronized 时不需要担心这个问题。 与此同时，lock() 方法不能被中断，这会带来很大的隐患：一旦陷入死锁，lock() 就会陷入永久等待，所以一般我们用 tryLock() 等其他更高级的方法来代替 lock()。 tryLock() tryLock() 用来尝试获取锁，如果当前锁没有被其他线程占用，则获取成功，返回 true，否则返回 false，代表获取锁失败。相比于 lock()，这样的方法显然功能更强大，我们可以根据是否能获取到锁来决定后续程序的行为。 因为该方法会立即返回，即便在拿不到锁时也不会一直等待，所以通常情况下，我们用 if 语句判断 tryLock() 的返回结果，根据是否获取到锁来执行不同的业务逻辑，典型使用方法如下： 12345678910Lock lock = ...;if(lock.tryLock()) &#123; try&#123; //处理任务 &#125;finally&#123; lock.unlock(); //释放锁 &#125; &#125;else &#123; //如果不能获取锁，则做其他事情&#125; 有了这个强大的 tryLock() 方法我们便可以解决死锁问题，代码如下所示： 1234567891011121314151617181920public void tryLock(Lock lock1, Lock lock2) throws InterruptedException &#123; while (true) &#123; if (lock1.tryLock()) &#123; try &#123; if (lock2.tryLock()) &#123; try &#123; System.out.println(\"获取到了两把锁，完成业务逻辑\"); return; &#125; finally &#123; lock2.unlock(); &#125; &#125; &#125; finally &#123; lock1.unlock(); &#125; &#125; else &#123; Thread.sleep(new Random().nextInt(1000)); &#125; &#125; &#125; 如果代码中不用 tryLock() 方法，那么便可能会产生死锁。但是有了 tryLock() 方法之后，首先会检测 lock1 是否能获取到，如果能获取到再尝试获取 lock2，但如果 lock1 获取不到也没有关系，会在下面进行随机时间的等待，这个等待的目标是争取让其他的线程在这段时间完成它的任务，以便释放其他线程所持有的锁；同理如果获取到了 lock1 但没有获取到 lock2，那么也会释放掉 lock1，随即进行随机的等待，只有当它同时获取到 lock1 和 lock2 的时候，才会进入到里面执行业务逻辑，比如在这里会打印出“获取到了两把锁，完成业务逻辑”，然后方法便会返回。 tryLock(long time, TimeUnit unit) tryLock() 的重载方法是 tryLock(long time, TimeUnit unit)，这个方法和 tryLock() 很类似，区别在于 tryLock(long time, TimeUnit unit) 方法会有一个超时时间，在拿不到锁时会等待一定的时间，如果在时间期限结束后，还获取不到锁，就会返回 false；如果一开始就获取锁或者等待期间内获取到锁，则返回 true。 这个方法解决了 lock() 方法容易发生死锁的问题，使用 tryLock(long time, TimeUnit unit) 时，在等待了一段指定的超时时间后，线程会主动放弃这把锁的获取，避免永久等待；在等待的期间，也可以随时中断线程，这就避免了死锁的发生。本方法和下面介绍的 lockInterruptibly() 是非常类似的。 lockInterruptibly() 这个方法的作用就是去获取锁，如果这个锁当前是可以获得的，那么这个方法会立刻返回，但是如果这个锁当前是不能获得的（被其他线程持有），那么当前线程便会开始等待，除非它等到了这把锁或者是在等待的过程中被中断了，否则这个线程便会一直在这里执行这行代码。一句话总结就是，除非当前线程在获取锁期间被中断，否则便会一直尝试获取直到获取到为止。 顾名思义，lockInterruptibly() 是可以响应中断的。相比于不能响应中断的 synchronized 锁，lockInterruptibly() 可以让程序更灵活，可以在获取锁的同时，保持对中断的响应。我们可以把这个方法理解为超时时间是无穷长的 tryLock(long time, TimeUnit unit)，因为 tryLock(long time, TimeUnit unit) 和 lockInterruptibly() 都能响应中断，只不过 lockInterruptibly() 永远不会超时。 这个方法本身是会抛出 InterruptedException 的，所以使用的时候，如果不在方法签名声明抛出该异常，那么就要写两个 try 块，如下所示： 123456789101112public void lockInterruptibly() &#123; try &#123; lock.lockInterruptibly(); try &#123; System.out.println(\"操作资源\"); &#125; finally &#123; lock.unlock(); &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; 在这个方法中首先执行了 lockInterruptibly 方法，并且对它进行了 try catch 包装，然后同样假设能够获取到这把锁，和之前一样，就必须要使用 try finally 来保障锁的绝对释放。 unlock() unlock() 方法是用于解锁的，方法比较简单，对于 ReentrantLock 而言，执行 unlock() 的时候，内部会把锁的“被持有计数器”减 1，直到减到 0 就代表当前这把锁已经完全释放了，如果减 1 后计数器不为 0，说明这把锁之前被“重入”了，那么锁并没有真正释放，仅仅是减少了持有的次数。 6.讲一讲公平锁和非公平锁，为什么要“非公平”？什么是公平和非公平 公平锁指的是按照线程请求的顺序，来分配锁；而非公平锁指的是不完全按照请求的顺序，在一定情况下，可以允许插队。但需要注意这里的非公平并不是指完全的随机，不是说线程可以任意插队，而是仅仅“在合适的时机”插队。 那什么时候是合适的时机呢？假设当前线程在请求获取锁的时候，恰巧前一个持有锁的线程释放了这把锁，那么当前申请锁的线程就可以不顾已经等待的线程而选择立刻插队。但是如果当前线程请求的时候，前一个线程并没有在那一时刻释放锁，那么当前线程还是一样会进入等待队列。 为什么要设置非公平策略呢，而且非公平还是 ReentrantLock的默认策略，如果不加以设置的话默认就是非公平的，难道我的这些排队的时间都白白浪费了吗，为什么别人比我有优先权呢？毕竟公平是一种很好的行为，而非公平是一种不好的行为。 考虑一种情况，假设线程 A 持有一把锁，线程 B 请求这把锁，由于线程 A 已经持有这把锁了，所以线程 B 会陷入等待，在等待的时候线程 B 会被挂起，也就是进入阻塞状态，那么当线程 A 释放锁的时候，本该轮到线程 B 苏醒获取锁，但如果此时突然有一个线程 C 插队请求这把锁，那么根据非公平的策略，会把这把锁给线程 C，这是因为唤醒线程 B 是需要很大开销的，很有可能在唤醒之前，线程 C 已经拿到了这把锁并且执行完任务释放了这把锁。相比于等待唤醒线程 B 的漫长过程，插队的行为会让线程 C 本身跳过陷入阻塞的过程，如果在锁代码中执行的内容不多的话，线程 C 就可以很快完成任务，并且在线程 B 被完全唤醒之前，就把这个锁交出去，这样是一个双赢的局面，对于线程 C 而言，不需要等待提高了它的效率，而对于线程 B 而言，它获得锁的时间并没有推迟，因为等它被唤醒的时候，线程 C 早就释放锁了，因为线程 C 的执行速度相比于线程 B 的唤醒速度，是很快的，所以 Java 设计者设计非公平锁，是为了提高整体的运行效率。 公平的场景 下面用图示来说明公平和非公平的场景，先来看公平的情况。假设创建了一个公平锁，此时有 4 个线程按顺序来请求公平锁，线程 1 在拿到这把锁之后，线程 2、3、4 会在等待队列中开始等待，然后等线程 1 释放锁之后，线程 2、3、4 会依次去获取这把锁，线程 2 先获取到的原因是它等待的时间最长。 不公平的场景 下面再来看看非公平的情况，假设线程 1 在解锁的时候，突然有线程 5 尝试获取这把锁，那么根据非公平策略，线程 5 是可以拿到这把锁的，尽管它没有进入等待队列，而且线程 2、3、4 等待的时间都比线程 5 要长，但是从整体效率考虑，这把锁此时还是会交给线程 5 持有。 代码案例：演示公平和非公平的效果 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859/** * 描述：演示公平锁，分别展示公平和不公平的情况，非公平锁会让现在持有锁的线程优先再次获取到锁。代码借鉴自Java并发编程实战手册2.7。 */public class FairAndUnfair &#123; public static void main(String args[]) &#123; PrintQueue printQueue = new PrintQueue(); Thread thread[] = new Thread[5]; for (int i = 0; i &lt; 5; i++) &#123; thread[i] = new Thread(new Job(printQueue), \"Thread \" + i); &#125; for (int i = 0; i &lt; 5; i++) &#123; thread[i].start(); try &#123; Thread.sleep(100); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125;class Job implements Runnable &#123; private PrintQueue printQueue; public Job(PrintQueue printQueue) &#123; this.printQueue = printQueue; &#125; @Override public void run() &#123; System.out.printf(\"%s: Going to print a job\\n\", Thread.currentThread().getName()); printQueue.printJob(new Object()); System.out.printf(\"%s: The document has been printed\\n\", Thread.currentThread().getName()); &#125;&#125;class PrintQueue &#123; private final Lock queueLock = new ReentrantLock(false); public void printJob(Object document) &#123; queueLock.lock(); try &#123; Long duration = (long) (Math.random() * 10000); System.out.printf(\"%s: PrintQueue: Printing a Job during %d seconds\\n\", Thread.currentThread().getName(), (duration / 1000)); Thread.sleep(duration); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; queueLock.unlock(); &#125; queueLock.lock(); try &#123; Long duration = (long) (Math.random() * 10000); System.out.printf(\"%s: PrintQueue: Printing a Job during %d seconds\\n\", Thread.currentThread().getName(), (duration / 1000)); Thread.sleep(duration); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; queueLock.unlock(); &#125; &#125;&#125; 可以通过改变 new ReentrantLock(false) 中的参数来设置公平/非公平锁。以上代码在公平的情况下的输出： 1234567891011121314151617181920Thread 0: Going to print a jobThread 0: PrintQueue: Printing a Job during 5 secondsThread 1: Going to print a jobThread 2: Going to print a jobThread 3: Going to print a jobThread 4: Going to print a jobThread 1: PrintQueue: Printing a Job during 3 secondsThread 2: PrintQueue: Printing a Job during 4 secondsThread 3: PrintQueue: Printing a Job during 3 secondsThread 4: PrintQueue: Printing a Job during 9 secondsThread 0: PrintQueue: Printing a Job during 8 secondsThread 0: The document has been printedThread 1: PrintQueue: Printing a Job during 1 secondsThread 1: The document has been printedThread 2: PrintQueue: Printing a Job during 8 secondsThread 2: The document has been printedThread 3: PrintQueue: Printing a Job during 2 secondsThread 3: The document has been printedThread 4: PrintQueue: Printing a Job during 0 secondsThread 4: The document has been printed 可以看出，线程直接获取锁的顺序是完全公平的，先到先得。 而以上代码在非公平的情况下的输出是这样的： 1234567891011121314151617181920Thread 0: Going to print a jobThread 0: PrintQueue: Printing a Job during 6 secondsThread 1: Going to print a jobThread 2: Going to print a jobThread 3: Going to print a jobThread 4: Going to print a jobThread 0: PrintQueue: Printing a Job during 8 secondsThread 0: The document has been printedThread 1: PrintQueue: Printing a Job during 9 secondsThread 1: PrintQueue: Printing a Job during 8 secondsThread 1: The document has been printedThread 2: PrintQueue: Printing a Job during 6 secondsThread 2: PrintQueue: Printing a Job during 4 secondsThread 2: The document has been printedThread 3: PrintQueue: Printing a Job during 9 secondsThread 3: PrintQueue: Printing a Job during 8 secondsThread 3: The document has been printedThread 4: PrintQueue: Printing a Job during 4 secondsThread 4: PrintQueue: Printing a Job during 2 secondsThread 4: The document has been printed 可以看出，非公平情况下，存在抢锁“插队”的现象，比如Thread 0 在释放锁后又能优先获取到锁，虽然此时在等待队列中已经有 Thread 1 ~ Thread 4 在排队了。 对比公平和非公平的优缺点 公平锁的优点在于各个线程公平平等，每个线程等待一段时间后，都有执行的机会，而它的缺点就在于整体执行速度更慢，吞吐量更小，相反非公平锁的优势就在于整体执行速度更快，吞吐量更大，但同时也可能产生线程饥饿问题，也就是说如果一直有线程插队，那么在等待队列中的线程可能长时间得不到运行。 tryLock()特例 这里有一个特例需要注意，针对 tryLock() 方法，它不遵守设定的公平原则。 例如，当有线程执行 tryLock() 方法的时候，一旦有线程释放了锁，那么这个正在 tryLock 的线程就能获取到锁，即使设置的是公平锁模式，即使在它之前已经有其他正在等待队列中等待的线程，简单地说就是 tryLock 可以插队。 看它的源码就会发现： 123public boolean tryLock() &#123; return sync.nonfairTryAcquire(1);&#125; 这里调用的就是 nonfairTryAcquire()，表明了是不公平的，和锁本身是否是公平锁无关。 7.读写锁 ReadWriteLock 获取锁有哪些规则？在没有读写锁之前，假设使用普通的 ReentrantLock，虽然保证了线程安全，但是也浪费了一定的资源，因为如果多个读操作同时进行，其实并没有线程安全问题，可以允许让多个读操作并行，以便提高程序效率。 但是写操作不是线程安全的，如果多个线程同时写，或者在写的同时进行读操作，便会造成线程安全问题。 读写锁就解决了这样的问题，它设定了一套规则，既可以保证多个线程同时读的效率，同时又可以保证有写入操作时的线程安全。 整体思路是它有两把锁，第 1 把锁是写锁，获得写锁之后，既可以读数据又可以修改数据，而第 2 把锁是读锁，获得读锁之后，只能查看数据，不能修改数据。读锁可以被多个线程同时持有，所以多个线程可以同时查看数据。 在读的地方合理使用读锁，在写的地方合理使用写锁，灵活控制，可以提高程序的执行效率。 读写锁的获取规则 我们在使用读写锁时遵守下面的获取规则： 如果有一个线程已经占用了读锁，则此时其他线程如果要申请读锁，可以申请成功。 如果有一个线程已经占用了读锁，则此时其他线程如果要申请写锁，则申请写锁的线程会一直等待释放读锁，因为读写不能同时操作。 如果有一个线程已经占用了写锁，则此时其他线程如果申请写锁或者读锁，都必须等待之前的线程释放写锁，同样也因为读写不能同时，并且两个线程不应该同时写。 所以我们用一句话总结：要么是一个或多个线程同时有读锁，要么是一个线程有写锁，但是两者不会同时出现。也可以总结为：读读共享、其他都互斥（写写互斥、读写互斥、写读互斥）。 使用案例 ReentrantReadWriteLock 是 ReadWriteLock 的实现类，最主要的有两个方法：readLock() 和 writeLock() 用来获取读锁和写锁。 1234567891011121314151617181920212223242526272829303132333435363738394041/** * 描述： 演示读写锁用法 */public class ReadWriteLockDemo &#123; private static final ReentrantReadWriteLock reentrantReadWriteLock = new ReentrantReadWriteLock( false); private static final ReentrantReadWriteLock.ReadLock readLock = reentrantReadWriteLock .readLock(); private static final ReentrantReadWriteLock.WriteLock writeLock = reentrantReadWriteLock .writeLock(); private static void read() &#123; readLock.lock(); try &#123; System.out.println(Thread.currentThread().getName() + \"得到读锁，正在读取\"); Thread.sleep(500); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; System.out.println(Thread.currentThread().getName() + \"释放读锁\"); readLock.unlock(); &#125; &#125; private static void write() &#123; writeLock.lock(); try &#123; System.out.println(Thread.currentThread().getName() + \"得到写锁，正在写入\"); Thread.sleep(500); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; System.out.println(Thread.currentThread().getName() + \"释放写锁\"); writeLock.unlock(); &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; new Thread(() -&gt; read()).start(); new Thread(() -&gt; read()).start(); new Thread(() -&gt; write()).start(); new Thread(() -&gt; write()).start(); &#125;&#125; 程序的运行结果是： 12345678Thread-0得到读锁，正在读取Thread-1得到读锁，正在读取Thread-0释放读锁Thread-1释放读锁Thread-2得到写锁，正在写入Thread-2释放写锁Thread-3得到写锁，正在写入Thread-3释放写锁 可以看出，读锁可以同时被多个线程获得，而写锁不能。 读写锁适用场合 相比于 ReentrantLock 适用于一般场合，ReadWriteLock 适用于读多写少的情况，合理使用可以进一步提高并发效率。 8.读锁应该插队吗？什么是读写锁的升降级？读锁插队策略 ReentrantReadWriteLock 可以设置为公平或者非公平，代码如下： 公平锁： 1ReentrantReadWriteLock reentrantReadWriteLock = new ReentrantReadWriteLock(true); 非公平锁： 1ReentrantReadWriteLock reentrantReadWriteLock = new ReentrantReadWriteLock(false); 如果是公平锁，就在构造函数的参数中传入 true，如果是非公平锁，就在构造函数的参数中传入 false，默认是非公平锁。在获取读锁之前，线程会检查 readerShouldBlock() 方法，同样，在获取写锁之前，线程会检查 writerShouldBlock() 方法，来决定是否需要插队或者是去排队。 首先看公平锁对于这两个方法的实现： 123456final boolean writerShouldBlock() &#123; return hasQueuedPredecessors();&#125;final boolean readerShouldBlock() &#123; return hasQueuedPredecessors();&#125; 很明显，在公平锁的情况下，只要等待队列中有线程在等待，也就是 hasQueuedPredecessors() 返回 true 的时候，那么 writer 和 reader 都会 block，也就是一律不允许插队，都乖乖去排队，这也符合公平锁的思想。 再看一下非公平锁的实现： 123456final boolean writerShouldBlock() &#123; return false; // writers can always barge&#125;final boolean readerShouldBlock() &#123; return apparentlyFirstQueuedIsExclusive();&#125; 在 writerShouldBlock() 这个方法中始终返回 false，可以看出，对于想获取写锁的线程而言，由于返回值是 false，所以它是随时可以插队的，这就和我们的 ReentrantLock 的设计思想是一样的，但是读锁却不一样。这里实现的策略很有意思，先来看下面这种场景： 假设线程 2 和线程 4 正在同时读取，线程 3 想要写入，但是由于线程 2 和线程 4 已经持有读锁了，所以线程 3 就进入等待队列进行等待。此时，线程 5 突然跑过来想要插队获取读锁： 面对这种情况有两种应对策略： (1).允许插队 由于现在有线程在读，而线程 5 又不会特别增加它们读的负担，因为线程们可以共用这把锁，所以第一种策略就是让线程 5 直接加入到线程 2 和线程 4 一起去读取。 这种策略看上去增加了效率，但是有一个严重的问题，那就是如果想要读取的线程不停地增加，比如线程 6，那么线程 6 也可以插队，这就会导致读锁长时间内不会被释放，导致线程 3 长时间内拿不到写锁，也就是那个需要拿到写锁的线程会陷入“饥饿”状态，它将在长时间内得不到执行。 (2).不允许插队 这种策略认为由于线程 3 已经提前等待了，所以虽然线程 5 如果直接插队成功，可以提高效率，但是我们依然让线程 5 去排队等待： 按照这种策略线程 5 会被放入等待队列中，并且排在线程 3 的后面，让线程 3 优先于线程 5 执行，这样可以避免“饥饿”状态，这对于程序的健壮性是很有好处的，直到线程 3 运行完毕，线程 5 才有机会运行，这样谁都不会等待太久的时间。 所以我们可以看出，即便是非公平锁，只要等待队列的头结点是尝试获取写锁的线程，那么读锁依然是不能插队的，目的是避免“饥饿”。 策略选择演示 策略的选择取决于具体锁的实现，ReentrantReadWriteLock 的实现选择了策略 2 ，是很明智的。 策略演示代码如下所示： 12345678910111213141516171819202122232425262728293031323334353637383940/** * 描述： 演示读锁不插队 */public class ReadLockJumpQueue &#123; private static final ReentrantReadWriteLock reentrantReadWriteLock = new ReentrantReadWriteLock(); private static final ReentrantReadWriteLock.ReadLock readLock = reentrantReadWriteLock .readLock(); private static final ReentrantReadWriteLock.WriteLock writeLock = reentrantReadWriteLock .writeLock(); private static void read() &#123; readLock.lock(); try &#123; System.out.println(Thread.currentThread().getName() + \"得到读锁，正在读取\"); Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; System.out.println(Thread.currentThread().getName() + \"释放读锁\"); readLock.unlock(); &#125; &#125; private static void write() &#123; writeLock.lock(); try &#123; System.out.println(Thread.currentThread().getName() + \"得到写锁，正在写入\"); Thread.sleep(2000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; System.out.println(Thread.currentThread().getName() + \"释放写锁\"); writeLock.unlock(); &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; new Thread(() -&gt; read(),\"Thread-2\").start(); new Thread(() -&gt; read(),\"Thread-4\").start(); new Thread(() -&gt; write(),\"Thread-3\").start(); new Thread(() -&gt; read(),\"Thread-5\").start(); &#125;&#125; 以上代码的运行结果是： 12345678Thread-2得到读锁，正在读取Thread-4得到读锁，正在读取Thread-2释放读锁Thread-4释放读锁Thread-3得到写锁，正在写入Thread-3释放写锁Thread-5得到读锁，正在读取Thread-5释放读锁 从这个结果可以看出，ReentrantReadWriteLock 的实现选择了“不允许插队”的策略，这就大大减小了发生“饥饿”的概率。（如果运行结果和课程不一致，可以在每个线程启动后增加 100ms 的睡眠时间，以便保证线程的运行顺序）。 锁的升降级 以下代码演示了在更新缓存的时候，如何利用锁的降级功能： 12345678910111213141516171819202122232425262728293031323334public class CachedData &#123; Object data; volatile boolean cacheValid; final ReentrantReadWriteLock rwl = new ReentrantReadWriteLock(); void processCachedData() &#123; rwl.readLock().lock(); if (!cacheValid) &#123; //在获取写锁之前，必须首先释放读锁。 rwl.readLock().unlock(); rwl.writeLock().lock(); try &#123; //这里需要再次判断数据的有效性,因为在我们释放读锁和获取写锁的空隙之内，可能有其他线程修改了数据。 if (!cacheValid) &#123; data = new Object(); cacheValid = true; &#125; //在不释放写锁的情况下，直接获取读锁，这就是读写锁的降级。 rwl.readLock().lock(); &#125; finally &#123; //释放了写锁，但是依然持有读锁 rwl.writeLock().unlock(); &#125; &#125; try &#123; System.out.println(data); &#125; finally &#123; //释放读锁 rwl.readLock().unlock(); &#125; &#125;&#125; 在这段代码中有一个读写锁，最重要的就是中间的 processCachedData 方法，在这个方法中，会首先获取到读锁，也就是rwl.readLock().lock()，它去判断当前的缓存是否有效，如果有效那么就直接跳过整个 if 语句，如果已经失效，代表需要更新这个缓存了。由于需要更新缓存，所以之前获取到的读锁是不够用的，需要获取写锁。 在获取写锁之前，首先释放读锁，然后利用 rwl.writeLock().lock() 来获取到写锁，然后是经典的 try finally 语句，在 try 语句中首先判断缓存是否有效，因为在刚才释放读锁和获取写锁的过程中，可能有其他线程抢先修改了数据，所以在此需要进行二次判断。 如果发现缓存是无效的，就用 new Object() 这样的方式来示意，获取到了新的数据内容，并把缓存的标记位设置为 ture，让缓存变得有效。由于后续希望打印出 data 的值，所以不能在此处释放掉所有的锁。在不释放写锁的情况下直接获取读锁，也就是rwl.readLock().lock() 这行语句所做的事情，然后，在持有读锁的情况下释放写锁，最后，在最下面的 try 中把 data 的值打印出来。 这就是一个非常典型的利用锁的降级功能的代码。 为什么需要锁的降级？ 如果我们在刚才的方法中，一直使用写锁，最后才释放写锁的话，虽然确实是线程安全的，但是也是没有必要的，因为只有一处修改数据的代码： 1data = new Object(); 后面对于 data 仅仅是读取。如果还一直使用写锁的话，就不能让多个线程同时来读取了，持有写锁是浪费资源的，降低了整体的效率，所以这个时候利用锁的降级是很好的办法，可以提高整体性能。 支持锁的降级，不支持升级 如果运行下面这段代码，在不释放读锁的情况下直接尝试获取写锁，也就是锁的升级，会让线程直接阻塞，程序是无法运行的： 123456789101112final static ReentrantReadWriteLock rwl = new ReentrantReadWriteLock(); public static void main(String[] args) &#123; upgrade();&#125; public static void upgrade() &#123; rwl.readLock().lock(); System.out.println(\"获取到了读锁\"); rwl.writeLock().lock(); System.out.println(\"成功升级\");&#125; 这段代码会打印出“获取到了读锁”，但是却不会打印出“成功升级”，因为 ReentrantReadWriteLock 不支持读锁升级到写锁。 为什么不支持锁的升级？ 读写锁的特点是如果线程都申请读锁，是可以多个线程同时持有的，可是如果是写锁，只能有一个线程持有，并且不可能存在读锁和写锁同时持有的情况。 正是因为不可能有读锁和写锁同时持有的情况，所以升级写锁的过程中，需要等到所有的读锁都释放，此时才能进行升级。 假设有 A，B 和 C 三个线程，它们都已持有读锁。假设线程 A 尝试从读锁升级到写锁。那么它必须等待 B 和 C 释放掉已经获取到的读锁。如果随着时间推移，B 和 C 逐渐释放了它们的读锁，此时线程 A 确实是可以成功升级并获取写锁。 但要考虑一种特殊情况，假设线程 A 和 B 都想升级到写锁，那么对于线程 A 而言，它需要等待其他所有线程，包括线程 B 在内释放读锁。而线程 B 也需要等待所有的线程，包括线程 A 释放读锁。这就是一种非常典型的死锁的情况。谁都愿不愿意率先释放掉自己手中的锁。 但是读写锁的升级并不是不可能的，也有可以实现的方案，如果保证每次只有一个线程可以升级，那么就可以保证线程安全。只不过最常见的 ReentrantReadWriteLock 对此并不支持。 9.什么是自旋锁？自旋的好处和后果是什么呢？什么是自旋 “自旋”可以理解为“自我旋转”，这里的“旋转”指“循环”，比如 while 循环或者 for 循环。“自旋”就是自己在这里不停地循环，直到目标达成。而不像普通的锁那样，如果获取不到锁就进入阻塞。 对比自旋和非自旋的获取锁的流程 (1).自旋锁，它并不会放弃 CPU 时间片，而是通过自旋等待锁的释放，也就是说，它会不停地再次尝试获取锁，如果失败就再次尝试，直到成功为止。 (2).非自旋锁，非自旋锁和自旋锁是完全不一样的，如果它发现此时获取不到锁，它就把自己的线程切换状态，让线程休眠，然后 CPU 就可以在这段时间去做很多其他的事情，直到之前持有这把锁的线程释放了锁，于是 CPU 再把之前的线程恢复回来，让这个线程再去尝试获取这把锁。如果再次失败，就再次让线程休眠，如果成功，一样可以成功获取到同步资源的锁。 自旋锁的好处 首先，阻塞和唤醒线程都是需要高昂的开销的，如果同步代码块中的内容不复杂，那么可能转换线程带来的开销比实际业务代码执行的开销还要大。 在很多场景下，可能同步代码块的内容并不多，所以需要的执行时间也很短，如果仅仅为了这点时间就去切换线程状态，那么其实不如让线程不切换状态，而是让它自旋地尝试获取锁，等待其他线程释放锁，有时只需要稍等一下，就可以避免上下文切换等开销，提高了效率。 用一句话总结自旋锁的好处，那就是自旋锁用循环去不停地尝试获取锁，让线程始终处于 Runnable 状态，节省了线程状态切换带来的开销。 AtomicLong 的实现 在 Java 1.5 版本及以上的并发包中，也就是 java.util.concurrent 的包中，里面的原子类基本都是自旋锁的实现。 比如我们看一个 AtomicLong 的实现，里面有一个 getAndIncrement 方法，源码如下： 123public final long getAndIncrement() &#123; return unsafe.getAndAddLong(this, valueOffset, 1L);&#125; 可以看到它调用了一个 unsafe.getAndAddLong，所以我们再来看这个方法： 1234567public final long getAndAddLong (Object var1,long var2, long var4)&#123; long var6; do &#123; var6 = this.getLongVolatile(var1, var2); &#125; while (!this.compareAndSwapLong(var1, var2, var6, var6 + var4)); return var6;&#125; 这里的 do-while 循环就是一个自旋操作，如果在修改过程中遇到了其他线程竞争导致没修改成功的情况，就会 while 循环里进行死循环，直到修改成功为止。 自己实现一个可重入的自旋锁 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859/** * 描述： 实现一个可重入的自旋锁 */public class ReentrantSpinLock &#123; private AtomicReference&lt;Thread&gt; owner = new AtomicReference&lt;&gt;(); //重入次数 private int count = 0; public void lock() &#123; Thread t = Thread.currentThread(); if (t == owner.get()) &#123; ++count; return; &#125; //自旋获取锁 while (!owner.compareAndSet(null, t)) &#123; System.out.println(\"自旋了\"); &#125; &#125; public void unlock() &#123; Thread t = Thread.currentThread(); //只有持有锁的线程才能解锁 if (t == owner.get()) &#123; if (count &gt; 0) &#123; --count; &#125; else &#123; //此处无需CAS操作，因为没有竞争，因为只有线程持有者才能解锁 owner.set(null); &#125; &#125; &#125; public static void main(String[] args) &#123; ReentrantSpinLock spinLock = new ReentrantSpinLock(); Runnable runnable = new Runnable() &#123; @Override public void run() &#123; System.out.println(Thread.currentThread().getName() + \"开始尝试获取自旋锁\"); spinLock.lock(); try &#123; System.out.println(Thread.currentThread().getName() + \"获取到了自旋锁\"); Thread.sleep(4000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; spinLock.unlock(); System.out.println(Thread.currentThread().getName() + \"释放了了自旋锁\"); &#125; &#125; &#125;; Thread thread1 = new Thread(runnable); Thread thread2 = new Thread(runnable); thread1.start(); thread2.start(); &#125;&#125; 代码的运行结果是： 1234567891011...自旋了自旋了自旋了自旋了自旋了自旋了自旋了自旋了Thread-0释放了了自旋锁Thread-1获取到了自旋锁 前面会打印出很多“自旋了”，说明自旋期间，CPU依然在不停运转。 缺点 自旋最大的缺点就在于虽然避免了线程切换的开销，但是它在避免线程切换开销的同时也带来了新的开销，因为它需要不停得去尝试获取锁。如果这把锁一直不能被释放，那么这种尝试只是无用的尝试，会白白浪费处理器资源。也就是说，虽然一开始自旋锁的开销低于线程切换，但是随着时间的增加，这种开销也是水涨船高，后期甚至会超过线程切换的开销，得不偿失。 适用场景 自旋锁适用于并发度不是特别高的场景，以及临界区比较短小的情况，这样我们可以利用避免线程切换来提高效率。 可是如果临界区很大，线程一旦拿到锁，很久才会释放的话，那就不合适用自旋锁，因为自旋会一直占用 CPU 却无法拿到锁，白白消耗资源。 10.JVM 对锁进行了哪些优化？相比于 JDK 1.5，在 JDK 1.6 中 HotSopt 虚拟机对 synchronized 内置锁的性能进行了很多优化，包括自适应的自旋、锁消除、锁粗化、偏向锁、轻量级锁等。有了这些优化措施后，synchronized 锁的性能得到了大幅提高。 自适应的自旋锁 在 JDK 1.6 中引入了自适应的自旋锁来解决长时间自旋的问题。自适应意味着自旋的时间不再固定，而是会根据最近自旋尝试的成功率、失败率，以及当前锁的拥有者的状态等多种因素来共同决定。自旋的持续时间是变化的，自旋锁变“聪明”了。比如，如果最近尝试自旋获取某一把锁成功了，那么下一次可能还会继续使用自旋，并且允许自旋更长的时间；但是如果最近自旋获取某一把锁失败了，那么可能会省略掉自旋的过程，以便减少无用的自旋，提高效率。 锁消除 1234567891011121314151617181920212223242526272829public class Person &#123; private String name; private int age; public Person(String personName, int personAge) &#123; name = personName; age = personAge; &#125; public Person(Person p) &#123; this(p.getName(), p.getAge()); &#125; public String getName() &#123; return name; &#125; public int getAge() &#123; return age; &#125;&#125;class Employee &#123; private Person person; // makes a defensive copy to protect against modifications by caller public Person getPerson() &#123; return new Person(person); &#125; public void printEmployeeDetail(Employee emp) &#123; Person person = emp.getPerson(); // this caller does not modify the object, so defensive copy was unnecessary System.out.println(\"Employee's name: \" + person.getName() + \"; age: \" + person.getAge()); &#125;&#125; 在这段代码中，我们看到下方的 Employee 类中的 getPerson() 方法，这个方法中使用了类里面的 person 对象，并且新建一个和它属性完全相同的新的 person 对象，目的是防止方法调用者修改原来的 person 对象。但是在这个例子中，其实是没有任何必要新建对象的，因为我们的 printEmployeeDetail() 方法没有对这个对象做出任何的修改，仅仅是打印，既然如此，我们其实可以直接打印最开始的 person 对象，而无须新建一个新的。 如果编译器可以确定最开始的 person 对象不会被修改的话，它可能会优化并且消除这个新建 person 的过程。 根据这样的思想，接下来我们就来举一个锁消除的例子，经过逃逸分析之后，如果发现某些对象不可能被其他线程访问到，那么就可以把它们当成栈上数据，栈上数据由于只有本线程可以访问，自然是线程安全的，也就无需加锁，所以会把这样的锁给自动去除掉。 例如，我们的 StringBuffer 的 append 方法如下所示： 123456@Overridepublic synchronized StringBuffer append(Object obj) &#123; toStringCache = null; super.append(String.valueOf(obj)); return this;&#125; 从代码中可以看出，这个方法是被 synchronized 修饰的同步方法，因为它可能会被多个线程同时使用。 但是在大多数情况下，它只会在一个线程内被使用，如果编译器能确定这个 StringBuffer 对象只会在一个线程内被使用，就代表肯定是线程安全的，那么我们的编译器便会做出优化，把对应的 synchronized 给消除，省去加锁和解锁的操作，以便增加整体的效率。 锁粗化 如果释放了锁，紧接着什么都没做，又重新获取锁，例如下面这段代码所示： 1234567891011public void lockCoarsening() &#123; synchronized (this) &#123; //do something &#125; synchronized (this) &#123; //do something &#125; synchronized (this) &#123; //do something &#125;&#125; 那么其实这种释放和重新获取锁是完全没有必要的，如果我们把同步区域扩大，也就是只在最开始加一次锁，并且在最后直接解锁，那么就可以把中间这些无意义的解锁和加锁的过程消除，相当于是把几个 synchronized 块合并为一个较大的同步块。这样做的好处在于在线程执行这些代码时，就无须频繁申请与释放锁了，这样就减少了性能开销。 不过，这样做也有一个副作用，那就是会让同步区域变大。如果在循环中也这样做，如代码所示： 12345for (int i = 0; i &lt; 1000; i++) &#123; synchronized (this) &#123; //do something &#125;&#125; 也就是在第一次循环的开始，就开始扩大同步区域并持有锁，直到最后一次循环结束，才结束同步代码块释放锁的话，这就会导致其他线程长时间无法获得锁。所以，这里的锁粗化不适用于循环的场景，仅适用于非循环的场景。 锁粗化功能是默认打开的，用 -XX:-EliminateLocks 可以关闭该功能。 偏向锁/轻量级锁/重量级锁 这三种锁是特指 synchronized 锁的状态的，通过在对象头中的 mark word 来表明锁的状态。 偏向锁 对于偏向锁而言，它的思想是如果自始至终，对于这把锁都不存在竞争，那么其实就没必要上锁，只要打个标记就行了。一个对象在被初始化后，如果还没有任何线程来获取它的锁时，它就是可偏向的，当有第一个线程来访问它尝试获取锁的时候，它就记录下来这个线程，如果后面尝试获取锁的线程正是这个偏向锁的拥有者，就可以直接获取锁，开销很小。 轻量级锁 JVM 的开发者发现在很多情况下，synchronized 中的代码块是被多个线程交替执行的，也就是说，并不存在实际的竞争，或者是只有短时间的锁竞争，用 CAS 就可以解决。这种情况下，重量级锁是没必要的。轻量级锁指当锁原来是偏向锁的时候，被另一个线程所访问，说明存在竞争，那么偏向锁就会升级为轻量级锁，线程会通过自旋的方式尝试获取锁，不会阻塞。 重量级锁 这种锁利用操作系统的同步机制实现，所以开销比较大。当多个线程直接有实际竞争，并且锁竞争时间比较长的时候，此时偏向锁和轻量级锁都不能满足需求，锁就会膨胀为重量级锁。重量级锁会让其他申请却拿不到锁的线程进入阻塞状态。 锁升级的路径 如图所示，从无锁到偏向锁，再到轻量级锁，最后到重量级锁。结合前面讲过的知识，偏向锁性能最好，避免了 CAS 操作。而轻量级锁利用自旋和 CAS 避免了重量级锁带来的线程阻塞和唤醒，性能中等。重量级锁则会把获取不到锁的线程阻塞，性能最差。 JVM 默认会优先使用偏向锁，如果有必要的话才逐步升级，这大幅提高了锁的性能。","tags":[{"name":"java","slug":"java","permalink":"https://sunshine-zwq.gitee.io/tags/java/"},{"name":"并发编程","slug":"并发编程","permalink":"https://sunshine-zwq.gitee.io/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"},{"name":"面试","slug":"面试","permalink":"https://sunshine-zwq.gitee.io/tags/%E9%9D%A2%E8%AF%95/"}]},{"title":"Java并发编程常见问题-死锁问题","date":"2020-12-16T03:31:23.000Z","path":"2020/12/16/Java并发编程常见问题-死锁问题/","text":"1.如何写一个必然死锁的例子？什么是死锁 死锁是一种状态，当两个（或多个）线程（或进程）相互持有对方所需要的资源，却又都不主动释放自己手中所持有的资源，导致大家都获取不到自己想要的资源，所有相关的线程（或进程）都无法继续往下执行，在未改变这种状态之前都不能向前推进，我们就把这种状态称为死锁状态，认为它们发生了死锁。通俗的讲，死锁就是两个或多个线程（或进程）被无限期地阻塞，相互等待对方手中资源的一种状态。 (1).两个线程的例子 此时我们有两个线程，分别是线程 A 和线程 B，假设线程 A 现在持有了锁 A，线程 B 持有了锁 B，然后线程 A 尝试去获取锁 B，当然它获取不到，因为线程 B 还没有释放锁 B。然后线程 B 又来尝试获取锁 A，同样线程 B 也获取不到锁 A，因为锁 A 已经被线程 A 持有了。这样一来，线程 A 和线程 B 就发生了死锁，因为它们都相互持有对方想要的资源，却又不释放自己手中的资源，形成相互等待，而且会一直等待下去。 (2).多个线程造成死锁的情况 如果多个线程之间的依赖关系是环形，存在环路的依赖关系，那么也可能会发生死锁，如下图所示： 首先线程 1 持有了锁 A，然后线程 2 持有了锁 B，然后线程 3 持有了锁 C，现在每个线程都分别持有一把锁。接下来线程 1 想要去持有锁 B，可是它获取不到，因为现在锁 B 正在线程 2 的手里；接下来线程 2 又去尝试获取锁 C， 它同样也获取不到，因为现在锁 C 在线程 3 的手里；然后线程 3 去尝试获取锁 A ，当然它也获取不到，因为锁 A 现在在线程 1 的手里，这样一来线程 1、线程 2 和线程 3 相互之间就形成了一个环，这就是在多线程中发生死锁的情况。所以不仅是两个线程，多个线程同样也有可能会发生死锁的情况。 死锁的影响 死锁的影响在不同系统中是不一样的，影响的大小一部分取决于当前这个系统或者环境对死锁的处理能力。 (1).数据库中 例如，在数据库系统软件的设计中，考虑了监测死锁以及从死锁中恢复的情况。在执行一个事务的时候可能需要获取多把锁，并一直持有这些锁直到事务完成。在某个事务中持有的锁可能在其他事务中也需要，因此在两个事务之间有可能发生死锁的情况，一旦发生了死锁，如果没有外部干涉，那么两个事务就会永远的等待下去。但数据库系统不会放任这种情况发生，当数据库检测到这一组事务发生了死锁时，根据策略的不同，可能会选择放弃某一个事务，被放弃的事务就会释放掉它所持有的锁，从而使其他的事务继续顺利进行。此时程序可以重新执行被强行终止的事务，而这个事务现在就可以顺利执行了，因为所有跟它竞争资源的事务都已经在刚才执行完毕，并且释放资源了。 (2).JVM 中 在 JVM 中，对于死锁的处理能力就不如数据库那么强大了。如果在 JVM 中发生了死锁，JVM 并不会自动进行处理，所以一旦死锁发生，就会陷入无穷的等待。 几率不高但危害大 死锁的问题和其他的并发安全问题一样，是概率性的，也就是说，即使存在发生死锁的可能性，也并不是 100% 会发生的。如果每个锁的持有时间很短，那么发生冲突的概率就很低，所以死锁发生的概率也很低。但是在线上系统里，可能每天有几千万次的“获取锁”、“释放锁”操作，在巨量的次数面前，整个系统发生问题的几率就会被放大，只要有某几次操作是有风险的，就可能会导致死锁的发生。 也正是因为死锁“不一定会发生”的特点，导致提前找出死锁成为了一个难题。压力测试虽然可以检测出一部分可能发生死锁的情况，但是并不足以完全模拟真实、长期运行的场景，因此没有办法把所有潜在可能发生死锁的代码都找出来。 一旦发生了死锁，根据发生死锁的线程的职责不同，就可能会造成子系统崩溃、性能降低甚至整个系统崩溃等各种不良后果。而且死锁往往发生在高并发、高负载的情况下，因为可能会直接影响到很多用户，造成一系列的问题。以上就是死锁发生几率不高但是危害大的特点。 发生死锁的例子 123456789101112131415161718192021222324252627282930313233343536373839404142434445/** * 描述： 必定死锁的情况 */public class MustDeadLock implements Runnable &#123; public int flag; static Object o1 = new Object(); static Object o2 = new Object(); public void run() &#123; System.out.println(\"线程\"+Thread.currentThread().getName() + \"的flag为\" + flag); if (flag == 1) &#123; synchronized (o1) &#123; try &#123; Thread.sleep(500); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; synchronized (o2) &#123; System.out.println(\"线程1获得了两把锁\"); &#125; &#125; &#125; if (flag == 2) &#123; synchronized (o2) &#123; try &#123; Thread.sleep(500); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; synchronized (o1) &#123; System.out.println(\"线程2获得了两把锁\"); &#125; &#125; &#125; &#125; public static void main(String[] argv) &#123; MustDeadLock r1 = new MustDeadLock(); MustDeadLock r2 = new MustDeadLock(); r1.flag = 1; r2.flag = 2; Thread t1 = new Thread(r1, \"t1\"); Thread t2 = new Thread(r2, \"t2\"); t1.start(); t2.start(); &#125;&#125; 执行结果： 12线程t1的flag为1线程t2的flag为2 程序执行到此时还在继续执行，并没停止，并且它永远不会打印出“线程 1 获得了两把锁”或“线程 2 获得了两把锁”这样的语句，此时这里就发生了死锁。 2.发生死锁必须满足哪 4 个条件？发生死锁的 4 个必要条件 要想发生死锁有 4 个缺一不可的必要条件： 第 1 个叫互斥条件，它的意思是每个资源每次只能被一个线程（或进程，下同）使用，为什么资源不能同时被多个线程或进程使用呢？这是因为如果每个人都可以拿到想要的资源，那就不需要等待，所以是不可能发生死锁的。 第 2 个是请求与保持条件，它是指当一个线程因请求资源而阻塞时，则需对已获得的资源保持不放。如果在请求资源时阻塞了，并且会自动释放手中资源（例如锁）的话，那别人自然就能拿到我刚才释放的资源，也就不会形成死锁。 第 3 个是不剥夺条件，它是指线程已获得的资源，在未使用完之前，不会被强行剥夺。比如在数据库中，它就有可能去强行剥夺某一个事务所持有的资源，这样就不会发生死锁了。所以要想发生死锁，必须满足不剥夺条件，也就是说当现在的线程获得了某一个资源后，别人就不能来剥夺这个资源，这才有可能形成死锁。 第 4 个是循环等待条件，只有若干线程之间形成一种头尾相接的循环等待资源关系时，才有可能形成死锁，比如在两个线程之间，这种“循环等待”就意味着它们互相持有对方所需的资源、互相等待；而在三个或更多线程中，则需要形成环路，例如依次请求下一个线程已持有的资源等。 只要破坏任意一个条件就可以消除死锁！！！ 3.如何用命令行和代码定位死锁？命令：jstack jstack能看到我们 Java 线程的一些相关信息。如果是比较明显的死锁关系，那么这个工具就可以直接检测出来；如果死锁不明显，那么它无法直接检测出来，不过我们也可以借此来分析线程状态，进而就可以发现锁的相互依赖关系，所以这也是很有利于我们找到死锁的方式。 首先，运行一下必然发生死锁的 MustDeadLock 类： 123456789101112131415161718192021222324252627282930313233343536373839404142434445/** * 描述： 必定死锁的情况 */public class MustDeadLock implements Runnable &#123; public int flag; static Object o1 = new Object(); static Object o2 = new Object(); public void run() &#123; System.out.println(\"线程\"+Thread.currentThread().getName() + \"的flag为\" + flag); if (flag == 1) &#123; synchronized (o1) &#123; try &#123; Thread.sleep(500); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; synchronized (o2) &#123; System.out.println(\"线程1获得了两把锁\"); &#125; &#125; &#125; if (flag == 2) &#123; synchronized (o2) &#123; try &#123; Thread.sleep(500); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; synchronized (o1) &#123; System.out.println(\"线程2获得了两把锁\"); &#125; &#125; &#125; &#125; public static void main(String[] argv) &#123; MustDeadLock r1 = new MustDeadLock(); MustDeadLock r2 = new MustDeadLock(); r1.flag = 1; r2.flag = 2; Thread t1 = new Thread(r1, \"t1\"); Thread t2 = new Thread(r2, \"t2\"); t1.start(); t2.start(); &#125;&#125; 由于它发生了死锁，在我们没有干预的情况下，程序在运行后就不会停止；然后打开我们的终端，执行 ${JAVA_HOME}/bin/jps 这个命令，就可以查看到当前 Java 程序的 pid，执行结果如下： 123456402 MustDeadLock56403 Launcher56474 Jps55051 KotlinCompileDaemon 有多行，可以看到第一行是 MustDeadLock 这类的 pid 56402；然后我们继续执行下一个命令，{JAVA_HOME}/bin/jstack 加空格，接着输入我们刚才所拿到的这个类的 pid，也就是 56402，所以完整的命令是 {JAVA_HOME}/bin/jstack 56402；最后它会打印出很多信息，就包含了线程获取锁的信息，比如哪个线程获取哪个锁，它获得的锁是在哪个语句中获得的，它正在等待或者持有的锁是什么等，这些重要信息都会打印出来。我们截取一部分和死锁相关的有用信息，展示如下： 123456789101112131415161718192021Found one Java-level deadlock:&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&quot;t2&quot;: waiting to lock monitor 0x00007fa06c004a18 (object 0x000000076adabaf0, a java.lang.Object), which is held by &quot;t1&quot;&quot;t1&quot;: waiting to lock monitor 0x00007fa06c007358 (object 0x000000076adabb00, a java.lang.Object), which is held by &quot;t2&quot;Java stack information for the threads listed above:&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&#x3D;&quot;t2&quot;: at lesson67.MustDeadLock.run(MustDeadLock.java:31) - waiting to lock &lt;0x000000076adabaf0&gt; (a java.lang.Object) - locked &lt;0x000000076adabb00&gt; (a java.lang.Object) at java.lang.Thread.run(Thread.java:748)&quot;t1&quot;: at lesson67.MustDeadLock.run(MustDeadLock.java:19) - waiting to lock &lt;0x000000076adabb00&gt; (a java.lang.Object) - locked &lt;0x000000076adabaf0&gt; (a java.lang.Object) at java.lang.Thread.run(Thread.java:748)Found 1 deadlock 在这里它首先会打印“Found one Java-level deadlock”，表明“找到了一个死锁”，然后是更详细的信息，从中间这部分的信息中可以看出，t2 线程想要去获取这个尾号为 af0 的锁对象，但是它被 t1 线程持有，同时 t2 持有尾号为 b00 的锁对象；相反，t1 想要获取尾号为 b00 的锁对象，但是它被 t2 线程持有，同时 t1 持有的却是尾号为 af0 的锁对象，这就形成了一个依赖环路，发生了死锁。最后它还打印出了“Found 1 deadlock.”，可以看出，jstack 工具不但帮我们找到了死锁，甚至还把哪个线程、想要获取哪个锁、形成什么样的环路都告诉我们了，当我们有了这样的信息之后，死锁就非常容易定位了，所以接下来我们就可以进一步修改代码，来避免死锁了。 代码：ThreadMXBean 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152public class DetectDeadLock implements Runnable &#123; public int flag; static Object o1 = new Object(); static Object o2 = new Object(); public void run() &#123; System.out.println(Thread.currentThread().getName()+\" flag = \" + flag); if (flag == 1) &#123; synchronized (o1) &#123; try &#123; Thread.sleep(500); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; synchronized (o2) &#123; System.out.println(\"线程1获得了两把锁\"); &#125; &#125; &#125; if (flag == 2) &#123; synchronized (o2) &#123; try &#123; Thread.sleep(500); &#125; catch (Exception e) &#123; e.printStackTrace(); &#125; synchronized (o1) &#123; System.out.println(\"线程2获得了两把锁\"); &#125; &#125; &#125; &#125; public static void main(String[] argv) throws InterruptedException &#123; DetectDeadLock r1 = new DetectDeadLock(); DetectDeadLock r2 = new DetectDeadLock(); r1.flag = 1; r2.flag = 2; Thread t1 = new Thread(r1,\"t1\"); Thread t2 = new Thread(r2,\"t2\"); t1.start(); t2.start(); Thread.sleep(1000); ThreadMXBean threadMXBean = ManagementFactory.getThreadMXBean(); long[] deadlockedThreads = threadMXBean.findDeadlockedThreads(); if (deadlockedThreads != null &amp;&amp; deadlockedThreads.length &gt; 0) &#123; for (int i = 0; i &lt; deadlockedThreads.length; i++) &#123; ThreadInfo threadInfo = threadMXBean.getThreadInfo(deadlockedThreads[i]); System.out.println(\"线程id为\"+threadInfo.getThreadId()+\",线程名为\" + threadInfo.getThreadName()+\"的线程已经发生死锁，需要的锁正被线程\"+threadInfo.getLockOwnerName()+\"持有。\"); &#125; &#125; &#125;&#125; 这个类是在前面 MustDeadLock 类的基础上做了升级，在 main 函数中，在启动 t1 和 t2 之后的代码，是我们本次新加入的代码，我们用 Thread.sleep(1000) 来确保已经形成死锁，然后利用 ThreadMXBean 来检查死锁。 通过 ThreadMXBean 的 findDeadlockedThreads 方法，可以获取到一个 deadlockedThreads 的数组，然后进行判断，当这个数组不为空且长度大于 0 的时候，我们逐个打印出对应的线程信息。比如我们打印出了线程 id，也打印出了线程名，同时打印出了它所需要的那把锁正被哪个线程所持有，那么这一部分代码的运行结果如下： 1234t1 flag &#x3D; 1t2 flag &#x3D; 2线程 id 为 12，线程名为 t2 的线程已经发生死锁，需要的锁正被线程 t1 持有。线程 id 为 11，线程名为 t1 的线程已经发生死锁，需要的锁正被线程 t2 持有。 可以看出，ThreadMXBean 也可以帮我们找到并定位死锁，如果我们在业务代码中加入这样的检测，那我们就可以在发生死锁的时候及时地定位，同时进行报警等其他处理，也就增强了我们程序的健壮性。 4.有哪些解决死锁问题的策略？线上发生死锁应该怎么办 如果线上环境发生了死锁，那么其实不良后果就已经造成了，修复死锁的最好时机在于“防患于未然”，而不是事后补救。就好比发生火灾时，一旦着了大火，想要不造成损失去扑灭几乎已经不可能了。死锁也是一样的，如果线上发生死锁问题，为了尽快减小损失，最好的办法是保存 JVM 信息、日志等“案发现场”的数据，然后立刻重启服务，来尝试修复死锁。为什么说重启服务能解决这个问题呢？因为发生死锁往往要有很多前提条件的，并且当并发度足够高的时候才有可能会发生死锁，所以重启后再次立刻发生死锁的几率并不是很大，当我们重启服务器之后，就可以暂时保证线上服务的可用，然后利用刚才保存过的案发现场的信息，排查死锁、修改代码，最终重新发布。 常见修复策略 三种主要的修复策略，分别是： 避免策略 检测与恢复策略 鸵鸟策略 (1).避免策略避免策略最主要的思路就是，优化代码逻辑，从根本上消除发生死锁的可能性。通常而言，发生死锁的一个主要原因是顺序相反的去获取不同的锁。因此我们就演示如何通过调整锁的获取顺序来避免死锁。 来看一下转账时发生死锁的情况。这个例子是一个示意性的，是为了学习死锁所而写的例子，所以和真实的银行系统的设计有很大不同，不过没关系，因为我们主要看的是如何避免死锁，而不是转账的业务逻辑。 a).发生了死锁 我们的转账系统为了保证线程安全，在转账前需要首先获取到两把锁（两个锁对象），分别是被转出的账户和被转入的账户。如果不做这一层限制，那么在某一个线程修改余额的期间，可能会有其他线程同时修改该变量，可能导致线程安全问题。所以在没有获取到这两把锁之前，是不能对余额进行操作的；只有获取到这两把锁之后，才能进行接下来真正的转账操作。当然，如果要转出的余额大于账户的余额，也不能转账，因为不允许余额变成负数。 而这期间就隐藏着发生死锁的可能，我们来看下代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748public class TransferMoney implements Runnable &#123; int flag; static Account a = new Account(500); static Account b = new Account(500); static class Account &#123; public Account(int balance) &#123; this.balance = balance; &#125; int balance; &#125; @Override public void run() &#123; if (flag == 1) &#123; transferMoney(a, b, 200); &#125; if (flag == 0) &#123; transferMoney(b, a, 200); &#125; &#125; public static void transferMoney(Account from, Account to, int amount) &#123; //先获取两把锁，然后开始转账 synchronized (to) &#123; synchronized (from) &#123; if (from.balance - amount &lt; 0) &#123; System.out.println(\"余额不足，转账失败。\"); return; &#125; from.balance -= amount; to.balance += amount; System.out.println(\"成功转账\" + amount + \"元\"); &#125; &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; TransferMoney r1 = new TransferMoney(); TransferMoney r2 = new TransferMoney(); r1.flag = 1; r2.flag = 0; Thread t1 = new Thread(r1); Thread t2 = new Thread(r2); t1.start(); t2.start(); t1.join(); t2.join(); System.out.println(\"a的余额\" + a.balance); System.out.println(\"b的余额\" + b.balance); &#125; &#125; 执行结果如下： 1234成功转账200元成功转账200元a的余额500b的余额500 代码是可以正常执行的，打印结果也是符合逻辑的。此时并没有发生死锁，因为每个锁的持有时间很短，同时释放也很快，所以在低并发的情况下，不容易发生死锁的现象。对代码做一些小调整，让它发生死锁。 在两个 synchronized 之间加上一个 Thread.sleep(500)，来模拟银行网络迟延等情况，那么 transferMoney 方法就变为： 12345678910111213141516171819public static void transferMoney(Account from, Account to, int amount) &#123; //先获取两把锁，然后开始转账 synchronized (to) &#123; try &#123; Thread.sleep(500); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; synchronized (from) &#123; if (from.balance - amount &lt; 0) &#123; System.out.println(\"余额不足，转账失败。\"); return; &#125; from.balance -= amount; to.balance += amount; System.out.println(\"成功转账\" + amount + \"元\"); &#125; &#125;&#125; 此时再运行程序，会有很大的概率发生死锁，从而导致控制台中不打印任何语句，而且程序也不会停止。 分析一下它为什么会发生死锁，最主要原因就是，两个不同的线程获取两个锁的顺序是相反的（第一个线程获取的这两个账户和第二个线程获取的这两个账户顺序恰好相反，第一个线程的“转出账户”正是第二个线程的“转入账户”），所以我们就可以从这个“相反顺序”的角度出发，来解决死锁问题。 b).实际上不在乎获取锁的顺序 经过思考，可以发现，其实转账时，并不在乎两把锁的相对获取顺序。转账的时候，我们无论先获取到转出账户锁对象，还是先获取到转入账户锁对象，只要最终能拿到两把锁，就能进行安全的操作。所以我们来调整一下获取锁的顺序，使得先获取的账户和该账户是“转入”或“转出”无关，而是使用 HashCode 的值来决定顺序，从而保证线程安全。 修复之后的 transferMoney 方法如下： 1234567891011121314151617181920212223242526272829public static void transferMoney(Account from, Account to, int amount) &#123; int fromHash = System.identityHashCode(from); int toHash = System.identityHashCode(to); if (fromHash &lt; toHash) &#123; synchronized (from) &#123; synchronized (to) &#123; if (from.balance - amount &lt; 0) &#123; System.out.println(\"余额不足，转账失败。\"); return; &#125; from.balance -= amount; to.balance += amount; System.out.println(\"成功转账\" + amount + \"元\"); &#125; &#125; &#125; else if (fromHash &gt; toHash) &#123; synchronized (to) &#123; synchronized (from) &#123; if (from.balance - amount &lt; 0) &#123; System.out.println(\"余额不足，转账失败。\"); return; &#125; from.balance -= amount; to.balance += amount; System.out.println(\"成功转账\" + amount + \"元\"); &#125; &#125; &#125;&#125; 可以看到，分别计算出这两个 Account 的 HashCode，然后根据 HashCode 的大小来决定获取锁的顺序。这样一来，不论是哪个线程先执行，不论是转出还是被转入，它获取锁的顺序都会严格根据 HashCode 的值来决定，那么大家获取锁的顺序就一样了，就不会出现获取锁顺序相反的情况，也就避免了死锁。 c).有主键就更安全、方便 用主键决定锁获取顺序的方式，它会更加的安全方便。刚才我们使用了 HashCode 作为排序的标准，因为 HashCode 比较通用，每个对象都有，不过这依然有极小的概率会发生 HashCode 相同的情况。在实际生产中，需要排序的往往是一个实体类，而一个实体类一般都会有一个主键 ID，主键 ID 具有唯一、不重复的特点，所以如果我们这个类包含主键属性的话就方便多了，我们也没必要去计算 HashCode，直接使用它的主键 ID 来进行排序，由主键 ID 大小来决定获取锁的顺序，就可以确保避免死锁。 (2).检测与恢复策略什么是死锁检测算法？ 它和之前避免死锁的策略不一样，避免死锁是通过逻辑让死锁不发生，而这里的检测与恢复策略，是先允许系统发生死锁，然后再解除。例如系统可以在每次调用锁的时候，都记录下来调用信息，形成一个“锁的调用链路图”，然后隔一段时间就用死锁检测算法来检测一下，搜索这个图中是否存在环路，一旦发生死锁，就可以用死锁恢复机制，比如剥夺某一个资源，来解开死锁，进行恢复。所以它的思路和之前的死锁避免策略是有很大不同的。 a).方法1——线程终止 第一种解开死锁的方法是线程（或进程，下同）终止，在这里，系统会逐个去终止已经陷入死锁的线程，线程被终止，同时释放资源，这样死锁就会被解开。 当然这个终止是需要讲究顺序的，一般有以下几个考量指标： 优先级：一般来说，终止时会考虑到线程或者进程的优先级，先终止优先级低的线程。例如，前台线程会涉及界面显示，这对用户而言是很重要的，所以前台线程的优先级往往高于后台线程。 已占用资源、还需要的资源：同时也会考虑到某个线程占有的资源有多少，还需要的资源有多少？如果某线程已经占有了一大堆资源，只需要最后一点点资源就可以顺利完成任务，那么系统可能就不会优先选择终止这样的线程，会选择终止别的线程来优先促成该线程的完成。 已经运行时间：另外还可以考虑的一个因素就是已经运行的时间，比如当前这个线程已经运行了很多个小时，甚至很多天了，很快就能完成任务了，那么终止这个线程可能不是一个明智的选择，我们可以让那些刚刚开始运行的线程终止，并在之后把它们重新启动起来，这样成本更低。 b).方法2——资源抢占 第二个解开死锁的方法就是资源抢占。其实，我们不需要把整个的线程终止，而是只需要把它已经获得的资源进行剥夺，比如让线程回退几步、 释放资源，这样一来就不用终止掉整个线程了，这样造成的后果会比刚才终止整个线程的后果更小一些，成本更低。 当然这种方式也有一个缺点，那就是如果算法不好的话，我们抢占的那个线程可能一直是同一个线程，就会造成线程饥饿。也就是说，这个线程一直被剥夺它已经得到的资源，那么它就长期得不到运行。 (3).鸵鸟策略鸵鸟策略以鸵鸟命名，因为鸵鸟有一个特点，就是遇到危险的时候，它会把头埋到沙子里，这样一来它就看不到危险了。 鸵鸟策略的意思就是，如果我们的系统发生死锁的概率不高，并且一旦发生其后果不是特别严重的话，我们就可以选择先忽略它。直到死锁发生的时候，我们再人工修复，比如重启服务，这并不是不可以的。如果我们的系统用的人比较少，比如是内部的系统，那么在并发量极低的情况下，它可能几年都不会发生死锁。对此我们考虑到投入产出比，自然也没有必要去对死锁问题进行特殊的处理，这是需要根据我们的业务场景进行合理选择的。 5.讲一讲经典的哲学家就餐问题问题描述 哲学家就餐问题也被称为刀叉问题，或者吃面问题。我们先来描述一下这个问题所要说明的事情，这个问题如下图所示： 有 5 个哲学家，他们面前都有一双筷子，即左手有一根筷子，右手有一根筷子。也就是说，哲学家左手要拿到一根筷子，右手也要拿到一根筷子，在这种情况下哲学家才能吃饭。 为什么选择哲学家呢？因为哲学家的特点是喜欢思考，所以我们可以把哲学家一天的行为抽象为思考，然后吃饭，并且他们吃饭的时候要用一双筷子，而不能只用一根筷子。 (1).主流程 我们来看一下哲学家就餐的主流程。哲学家如果想吃饭，他会先尝试拿起左手的筷子，然后再尝试拿起右手的筷子，如果某一根筷子被别人使用了，他就得等待他人用完，用完之后他人自然会把筷子放回原位，接着他把筷子拿起来就可以吃了（不考虑卫生问题）。这就是哲学家就餐的最主要流程。 (2).流程的伪代码 12345678910111213while(true) &#123; // 思考人生、宇宙、万物... think(); // 思考后感到饿了，需要拿筷子开始吃饭 pick_up_left_chopstick(); pick_up_right_chopstick(); eat(); put_down_right_chopstick(); put_down_left_chopstick(); // 吃完饭后，继续思考人生、宇宙、万物...&#125; while(true) 代表整个是一个无限循环。在每个循环中，哲学家首先会开始思考，思考一段时间之后（这个时间长度可以是随机的），他感到饿了，就准备开始吃饭。在吃饭之前必须先拿到左手的筷子，再拿到右手的筷子，然后才开始吃饭；吃完之后，先放回右手的筷子，再放回左手的筷子；由于这是个 while 循环，所以他就会继续思考人生，开启下一个循环。这就是整个过程。 有死锁和资源耗尽的风险 存在发生死锁的风险。如下面的动画所示： 根据我们的逻辑规定，在拿起左手边的筷子之后，下一步是去拿右手的筷子。大部分情况下，右边的哲学家正在思考，所以当前哲学家的右手边的筷子是空闲的，或者如果右边的哲学家正在吃饭，那么当前的哲学家就等右边的哲学家吃完饭并释放筷子，于是当前哲学家就能拿到了他右手边的筷子了。 但是，如果每个哲学家都同时拿起左手的筷子，那么就形成了环形依赖，在这种特殊的情况下，每个人都拿着左手的筷子，都缺少右手的筷子，那么就没有人可以开始吃饭了，自然也就没有人会放下手中的筷子。这就陷入了死锁，形成了一个相互等待的情况。代码如下所示： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546public class DiningPhilosophers &#123; public static class Philosopher implements Runnable &#123; private Object leftChopstick; private Object rightChopstick; public Philosopher(Object leftChopstick, Object rightChopstick) &#123; this.leftChopstick = leftChopstick; this.rightChopstick = rightChopstick; &#125; @Override public void run() &#123; try &#123; while (true) &#123; doAction(\"思考人生、宇宙、万物、灵魂...\"); synchronized (leftChopstick) &#123; doAction(\"拿起左边的筷子\"); synchronized (rightChopstick) &#123; doAction(\"拿起右边的筷子\"); doAction(\"吃饭\"); doAction(\"放下右边的筷子\"); &#125; doAction(\"放下左边的筷子\"); &#125; &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; private void doAction(String action) throws InterruptedException &#123; System.out.println(Thread.currentThread().getName() + \" \" + action); Thread.sleep((long) (Math.random() * 10)); &#125; &#125; public static void main(String[] args) &#123; Philosopher[] philosophers = new Philosopher[5]; Object[] chopsticks = new Object[philosophers.length]; for (int i = 0; i &lt; chopsticks.length; i++) &#123; chopsticks[i] = new Object(); &#125; for (int i = 0; i &lt; philosophers.length; i++) &#123; Object leftChopstick = chopsticks[i]; Object rightChopstick = chopsticks[(i + 1) % chopsticks.length]; philosophers[i] = new Philosopher(rightChopstick, leftChopstick); new Thread(philosophers[i], \"哲学家\" + (i + 1) + \"号\").start(); &#125; &#125;&#125; 在这个代码中，有一个内部类叫作 Philosophers，是哲学家的意思。在创建这个哲学家实例，也就是调用构造方法的时候，需要传入两个参数，分别是左手的筷子和右手的筷子。Philosophers 类实现了 Runnable 接口，在它的 run 方法中是无限循环，每个循环中，会多次调用 doAction 方法。在这里的 doAction 方法的定义在下方，这个方法实际上就是把当前输入的字符串给打印出来，并且去进行一段随机时间的休眠。 这里的随机休眠是为了模拟真实的场景，因为每个哲学家的思考、吃饭和拿筷子的时间会各不相同。同样，在线上的实际场景中，这个时间也肯定是不相同的，所以我们用随机数来模拟。 继续看 while 中的代码，哲学家会首先思考人生，然后获取左边筷子这把锁，并打印出“拿起左边的筷子”；接着他去获取右边筷子这把锁，并会打印出“拿起右边的筷子”、“吃饭”，并且“放下右边的筷子”，接下来，他会退出右边筷子的这个同步代码块，释放锁；最后打印出“放下左边的筷子”，随即退出左边筷子的这个同步代码块，释放锁。这样就完成了这个过程，当然他会继续进行 while 循环。 main 方法中新建了 5 个哲学家，并按照哲学家的数量去新建对应数量的筷子，并且把它们都初始化出来。筷子只用于充当锁对象，所以就把它定义为一个普通的 Object 类型。 接下来，需要初始化哲学家。初始化哲学家需要两个入参，分别是左手筷子和右手筷子，在这里会选取之前定义好的 chopsticks 数组中的对象来给 leftChopstick 和 rightChopstick 进行合理的赋值。当然有一种特殊情况，那就是考虑到最后一个哲学家右手的筷子，由于它已经转完了桌子的一圈，所以他实际上拿的还是第一根筷子，在这里会进行一个取余操作。 创建完哲学家之后，就会把它作为 Runnable 对象，传入 Thread，创建一个线程并启动。在 for 循环执行完毕之后，5 个哲学家都启动了起来，于是他们就开始思考并且吃饭。其中一种可能的执行结果如下所示： 12345678910哲学家1号 思考人生、宇宙、万物...哲学家3号 思考人生、宇宙、万物...哲学家2号 思考人生、宇宙、万物...哲学家4号 思考人生、宇宙、万物...哲学家5号 思考人生、宇宙、万物...哲学家4号 拿起左边的筷子哲学家5号 拿起左边的筷子哲学家1号 拿起左边的筷子哲学家3号 拿起左边的筷子哲学家2号 拿起左边的筷子 哲学家 1、3、2、4、5 几乎同时开始思考，然后，假设他们思考的时间比较相近，于是他们都在几乎同一时刻想开始吃饭，都纷纷拿起左手的筷子，这时就陷入了死锁状态，没有人可以拿到右手的筷子，也就没有人可以吃饭，于是陷入了无穷等待，这就是经典的哲学家就餐问题。 多种解决方案 要想解决死锁问题，只要破坏死锁四个必要条件的任何一个都可以。 (1).服务员检查 第一个解决方案就是引入服务员检查机制。比如我们引入一个服务员，当每次哲学家要吃饭时，他需要先询问服务员：我现在能否去拿筷子吃饭？此时，服务员先判断他拿筷子有没有发生死锁的可能，假如有的话，服务员会说：现在不允许你吃饭。这是一种解决方案。 (2).领导调节 可以引入一个领导，这个领导进行定期巡视。如果他发现已经发生死锁了，就会剥夺某一个哲学家的筷子，让他放下。这样一来，由于这个人的牺牲，其他的哲学家就都可以吃饭了。这也是一种解决方案。 (3).改变一个哲学家拿筷子的顺序 我们还可以利用死锁避免策略，那就是从逻辑上去避免死锁的发生，比如改变其中一个哲学家拿筷子的顺序。我们可以让 4 个哲学家都先拿左边的筷子再拿右边的筷子，但是有一名哲学家与他们相反，他是先拿右边的再拿左边的，这样一来就不会出现循环等待同一边筷子的情况，也就不会发生死锁了。 死锁解决 我们把“改变一个哲学家拿筷子的顺序”这件事情用代码来写一下，修改后的 main 方法如下： 1234567891011121314151617public static void main(String[] args) &#123; Philosopher[] philosophers = new Philosopher[5]; Object[] chopsticks = new Object[philosophers.length]; for (int i = 0; i &lt; chopsticks.length; i++) &#123; chopsticks[i] = new Object(); &#125; for (int i = 0; i &lt; philosophers.length; i++) &#123; Object leftChopstick = chopsticks[i]; Object rightChopstick = chopsticks[(i + 1) % chopsticks.length]; if (i == philosophers.length - 1) &#123; philosophers[i] = new Philosopher(rightChopstick, leftChopstick); &#125; else &#123; philosophers[i] = new Philosopher(leftChopstick, rightChopstick); &#125; new Thread(philosophers[i], \"哲学家\" + (i + 1) + \"号\").start(); &#125;&#125; 在这里最主要的变化是，我们实例化哲学家对象的时候，传入的参数原本都是先传入左边的筷子再传入右边的，但是当我们发现他是最后一个哲学家的时候，也就是 if (i == philosophers.length - 1) ，在这种情况下，我们给它传入的筷子顺序恰好相反，这样一来，他拿筷子的顺序也就相反了，他会先拿起右边的筷子，再拿起左边的筷子。那么这个程序运行的结果，是所有哲学家都可以正常地去进行思考和就餐了，并且不会发生死锁。","tags":[{"name":"java","slug":"java","permalink":"https://sunshine-zwq.gitee.io/tags/java/"},{"name":"并发编程","slug":"并发编程","permalink":"https://sunshine-zwq.gitee.io/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"},{"name":"面试","slug":"面试","permalink":"https://sunshine-zwq.gitee.io/tags/%E9%9D%A2%E8%AF%95/"}]},{"title":"Java并发编程常见问题-CAS原理与原子类","date":"2020-12-16T02:06:31.000Z","path":"2020/12/16/Java并发编程常见问题-CAS原理与原子类/","text":"1.什么是 CAS？CAS 简介 CAS 的英文全称是 Compare-And-Swap，中文叫做“比较并交换”，它是一种思想、一种算法。它是原子类的底层原理，同时也是乐观锁的原理。 在多线程的情况下，各个代码的执行顺序是不能确定的，所以为了保证并发安全，我们可以使用互斥锁。而 CAS 的特点是避免使用互斥锁，当多个线程同时使用 CAS 更新同一个变量时，只有其中一个线程能够操作成功，而其他线程都会更新失败。不过和同步互斥锁不同的是，更新失败的线程并不会被阻塞，而是被告知这次由于竞争而导致的操作失败，但还可以再次尝试。 CAS 被广泛应用在并发编程领域中，以实现那些不会被打断的数据交换操作，从而就实现了无锁的线程安全。 CAS 的思路 在大多数处理器的指令中，都会实现 CAS 相关的指令，这一条指令就可以完成“比较并交换”的操作，也正是由于这是一条（而不是多条）CPU 指令，所以 CAS 相关的指令是具备原子性的，这个组合操作在执行期间不会被打断，这样就能保证并发安全。由于这个原子性是由 CPU 保证的，所以无需我们程序员来操心。 CAS 有三个操作数：内存值 V、预期值 A、要修改的值 B。CAS 最核心的思路就是，仅当预期值 A 和当前的内存值 V 相同时，才将内存值修改为 B。 CAS 的语义 CAS 的等价语义的代码，如下所示： 1234567891011121314/** * 描述： 模拟CAS操作，等价代码 */ public class SimulatedCAS &#123; private int value; public synchronized int compareAndSwap(int expectedValue, int newValue) &#123; int oldValue = value; if (oldValue == expectedValue) &#123; value = newValue; &#125; return oldValue; &#125;&#125; compareAndSwap 方法是被 synchronized 修饰的，我们用同步方法为 CAS 的等价代码保证了原子性。 2.CAS 和乐观锁的关系，什么时候会用到 CAS？并发容器 Doug Lea 大神在 JUC 包中大量使用了 CAS 技术，该技术既能保证安全性，又不需要使用互斥锁，能大大提升工具类的性能。下面通过两个例子来展示 CAS 在并发容器中的使用情况。 (1).案例一：ConcurrentHashMap 并发容器 ConcurrentHashMap 截取部分 putVal 方法的代码，如下所示： 12345678910111213141516final V putVal(K key, V value, boolean onlyIfAbsent) &#123; if (key == null || value == null) throw new NullPointerException(); int hash = spread(key.hashCode()); int binCount = 0; for (Node&lt;K,V&gt;[] tab = table;;) &#123; Node&lt;K,V&gt; f; int n, i, fh; if (tab == null || (n = tab.length) == 0) tab = initTable(); else if ((f = tabAt(tab, i = (n - 1) &amp; hash)) == null) &#123; if (casTabAt(tab, i, null, new Node&lt;K,V&gt;(hash, key, value, null))) break; // no lock when adding to empty bin &#125; //以下部分省略 ...&#125; 在第 10 行，有一个醒目的方法，它就是 “casTabAt”，这个方法名就带有 “CAS”，可以猜测它一定是和 CAS 密不可分了，下面给出 casTabAt 方法的代码实现： 1234static final &lt;K,V&gt; boolean casTabAt(Node&lt;K,V&gt;[] tab, int i, Node&lt;K,V&gt; c, Node&lt;K,V&gt; v) &#123; return U.compareAndSwapObject(tab, ((long)i &lt;&lt; ASHIFT) + ABASE, c, v);&#125; 该方法里面只有一行代码，即调用变量 U 的 compareAndSwapObject 的方法，那么，这个变量 U 是什么类型的呢？U 的定义是： 1private static final sun.misc.Unsafe U 可以看出，U 是 Unsafe 类型的，Unsafe 类包含 compareAndSwapInt、compareAndSwapLong、compareAndSwapObject 等和 CAS 密切相关的 native 层的方法，其底层正是利用 CPU 对 CAS 指令的支持实现的。 上面介绍的 casTabAt 方法，不仅被用在了 ConcurrentHashMap 的 putVal 方法中，还被用在了 merge、compute、computeIfAbsent、transfer 等重要的方法中，所以 ConcurrentHashMap 对于 CAS 的应用是比较广泛的。 (2).案例二：ConcurrentLinkedQueue 非阻塞并发队列 ConcurrentLinkedQueue 的 offer 方法里也有 CAS 的身影，offer 方法的代码如下所示： 123456789101112131415161718public boolean offer(E e) &#123; checkNotNull(e); final Node&lt;E&gt; newNode = new Node&lt;E&gt;(e); for (Node&lt;E&gt; t = tail, p = t;;) &#123; Node&lt;E&gt; q = p.next; if (q == null) &#123; if (p.casNext(null, newNode)) &#123; if (p != t) casTail(t, newNode); return true; &#125; &#125; else if (p == q) p = (t != (t = tail)) ? t : head; else p = (p != t &amp;&amp; t != (t = tail)) ? t : q; &#125;&#125; 可以看出，在 offer 方法中，有一个 for 循环，这是一个死循环，在第 8 行有一个与 CAS 相关的方法，是 casNext 方法，用于更新节点。那么如果执行 p 的 casNext 方法失败的话，casNext 会返回 false，那么显然代码会继续在 for 循环中进行下一次的尝试。所以在这里也可以很明显的看出 ConcurrentLinkedQueue 的 offer 方法使用到了 CAS。 数据库 在我们的数据库中，也存在对乐观锁和 CAS 思想的应用。在更新数据时，我们可以利用 version 字段在数据库中实现乐观锁和 CAS 操作，而在获取和修改数据时都不需要加悲观锁。 具体思路如下：当我们获取完数据，并计算完毕，准备更新数据时，会检查现在的版本号与之前获取数据时的版本号是否一致，如果一致就说明在计算期间数据没有被更新过，可以直接更新本次数据；如果版本号不一致，则说明计算期间已经有其他线程修改过这个数据了，那就可以选择重新获取数据，重新计算，然后再次尝试更新数据。 假设取出数据的时候 version 版本为 1，相应的 SQL 语句示例如下所示： 1UPDATE student SET name = ‘小王’, version = 2 WHERE id = 10 AND version = 1 这样一来就可以用 CAS 的思想去实现本次的更新操作，它会先去比较 version 是不是最开始获取到的 1，如果和初始值相同才去进行 name 字段的修改，同时也要把 version 的值加一。 原子类 AtomicInteger 的 getAndAdd 方法代码如下所示： 123public final int getAndAdd(int delta) &#123; return unsafe.getAndAddInt(this, valueOffset, delta);&#125; 从上面的三行代码中可以看到，return 的内容是 Unsafe 的 getAndAddInt 方法的执行结果，接下来看一下 getAndAddInt 方法的具体实现，代码如下所示： 1234567public final int getAndAddInt(Object var1, long var2, int var4) &#123; int var5; do &#123; var5 = this.getIntVolatile(var1, var2); &#125; while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4)); return var5;&#125; compareAndSwapInt 方法会传入多个参数，分别是 var1、var2、 var5、var5 + var4，其实它们代表 object、offset、expectedValue 和 newValue。 第一个参数 object 就是将要修改的对象，传入的是 this，也就是 atomicInteger 这个对象本身； 第二个参数是 offset，也就是偏移量，借助它就可以获取到 value 的数值； 第三个参数 expectedValue，代表“期望值”，传入的是刚才获取到的 var5； 而最后一个参数 newValue 是希望修改为的新值 ，等于之前取到的数值 var5 再加上 var4，而 var4 就是我们之前所传入的 delta，delta 就是我们希望原子类所改变的数值，比如可以传入 +1，也可以传入 -1。 所以 compareAndSwapInt 方法的作用就是，判断如果现在原子类里 value 的值和之前获取到的 var5 相等的话，那么就把计算出来的 var5 + var4 给更新上去，所以说这行代码就实现了 CAS 的过程。 一旦 CAS 操作成功，就会退出这个 while 循环，但是也有可能操作失败。如果操作失败就意味着在获取到 var5 之后，并且在 CAS 操作之前，value 的数值已经发生变化了，证明有其他线程修改过这个变量。 这样一来，就会再次执行循环体里面的代码，重新获取 var5 的值，也就是获取最新的原子变量的数值，并且再次利用 CAS 去尝试更新，直到更新成功为止，所以这是一个死循环。 总结一下，Unsafe 的 getAndAddInt 方法是通过循环 + CAS 的方式来实现的，在此过程中，它会通过 compareAndSwapInt 方法来尝试更新 value 的值，如果更新失败就重新获取，然后再次尝试更新，直到更新成功。 3.CAS有什么缺点？主要有3个缺点，分别是 ABA 问题、自旋时间过长、线程安全的范围不能灵活控制。 ABA 问题 首先，CAS 最大的缺点就是 ABA 问题。 决定 CAS 是否进行 swap 的判断标准是“当前的值和预期的值是否一致”，如果一致，就认为在此期间这个数值没有发生过变动，这在大多数情况下是没有问题的。 但是在有的业务场景下，我们想确切知道从上一次看到这个值以来到现在，这个值是否发生过变化。例如，这个值假设从 A 变成了 B，再由 B 变回了 A，此时，我们不仅认为它发生了变化，并且会认为它变化了两次。 在这种场景下，我们使用 CAS，就看不到这两次的变化，因为仅判断“当前的值和预期的值是否一致”就是不够的了。CAS 检查的并不是值有没有发生过变化，而是去比较这当前的值和预期值是不是相等，如果变量的值从旧值 A 变成了新值 B 再变回旧值 A，由于最开始的值 A 和现在的值 A 是相等的，所以 CAS 会认为变量的值在此期间没有发生过变化。所以，CAS 并不能检测出在此期间值是不是被修改过，它只能检查出现在的值和最初的值是不是一样。 如果发生了 ABA 问题，那么线程一就根本无法知晓在计算过程中是否有其他线程把这个值修改过，由于第一个线程发现当前值和预期值是相等的，所以就会认为在此期间没有线程修改过变量的值，所以它接下来的一些操作逻辑，是按照在此期间这个值没被修改过”的逻辑去处理的，比如它可能会打印日志：“本次修改十分顺利”，但是它本应触发其他的逻辑，比如当它发现了在此期间有其他线程修改过这个值，其实本应该打印的是“本次修改过程受到了干扰”。 那么如何解决这个问题呢？添加一个版本号就可以解决。 我们在变量值自身之外，再添加一个版本号，那么这个值的变化路径就从 A→B→A 变成了 1A→2B→3A，这样一来，就可以通过对比版本号来判断值是否变化过，这比我们直接去对比两个值是否一致要更靠谱，所以通过这样的思路就可以解决 ABA 的问题了。 在 atomic 包中提供了 AtomicStampedReference 这个类，它是专门用来解决 ABA 问题的，解决思路正是利用版本号，AtomicStampedReference 会维护一种类似 &lt;Object,int&gt;的数据结构，其中的 int 就是用于计数的，也就是版本号，它可以对这个对象和 int 版本号同时进行原子更新，从而也就解决了 ABA 问题。因为我们去判断它是否被修改过，不再是以值是否发生变化为标准，而是以版本号是否变化为标准，即使值一样，它们的版本号也是不同的。 自旋时间过长 CAS 的第二个缺点就是自旋时间过长。 由于单次 CAS 不一定能执行成功，所以 CAS 往往是配合着循环来实现的，有的时候甚至是死循环，不停地进行重试，直到线程竞争不激烈的时候，才能修改成功。 可是如果我们的应用场景本身就是高并发的场景，就有可能导致 CAS 一直都操作不成功，这样的话，循环时间就会越来越长。而且在此期间，CPU 资源也是一直在被消耗的，这会对性能产生很大的影响。所以这就要求我们，要根据实际情况来选择是否使用 CAS，在高并发的场景下，通常 CAS 的效率是不高的。 范围不能灵活控制 CAS 的第三个缺点就是不能灵活控制线程安全的范围。 通常我们去执行 CAS 的时候，是针对某一个，而不是多个共享变量的，这个变量可能是 Integer 类型，也有可能是 Long 类型、对象类型等等，但是我们不能针对多个共享变量同时进行 CAS 操作，因为这多个变量之间是独立的，简单的把原子操作组合到一起，并不具备原子性。因此如果我们想对多个对象同时进行 CAS 操作并想保证线程安全的话，是比较困难的。 有一个解决方案，那就是利用一个新的类，来整合刚才这一组共享变量，这个新的类中的多个成员变量就是刚才的那多个共享变量，然后再利用 atomic 包中的 AtomicReference 来把这个新对象整体进行 CAS 操作，这样就可以保证线程安全。 相比之下，如果我们使用其他的线程安全技术，那么调整线程安全的范围就可能变得非常容易，比如我们用 synchronized 关键字时，如果想把更多的代码加锁，那么只需要把更多的代码放到同步代码块里面就可以了。 4.原子类是如何利用 CAS 保证线程安全的？什么是原子类？原子类有什么作用？ 在编程领域里，原子性意味着“一组操作要么全都操作成功，要么全都失败，不能只操作成功其中的一部分”。而 java.util.concurrent.atomic 下的类，就是具有原子性的类，可以原子性地执行添加、递增、递减等操作。比如多线程下的线程不安全的 i++ 问题，到了原子类这里，就可以用功能相同且线程安全的 getAndIncrement 方法来优雅地解决。 原子类的作用和锁有类似之处，是为了保证并发情况下线程安全。不过原子类相比于锁，有一定的优势： 粒度更细：原子变量可以把竞争范围缩小到变量级别，通常情况下，锁的粒度都要大于原子变量的粒度。 效率更高：除了高度竞争的情况之外，使用原子类的效率通常会比使用同步互斥锁的效率更高，因为原子类底层利用了 CAS 操作，不会阻塞线程。 6 类原子类纵览 具体类 类型 Atomic* 基本类型原子类 AtomicInteger、AtomicLong、AtomicBoolean Atomic*Array 数组类型原子类 AtomicIntegerArray、AtomicLongArray、AtomicReferenceArray Atomic*Reference 引用类型原子类 AtomicReference、AtomicStampedReference、AtomicMarkableReference Atomic*FieldUpdater 升级类型原子类 AtomicIntegerfieldupdater、AtomicLongFieldUpdater、AtomicReferenceFieldUpdater Adder 累加器 LongAdder、DoubleAdder Accumulator 积累器 LongAccumulator、DoubleAccumulator Atomic\\ 基本类型原子类 第一类 Atomic*，我们把它称为基本类型原子类，它包括三种，分别是 AtomicInteger、AtomicLong 和 AtomicBoolean。 我们来介绍一下最为典型的 AtomicInteger。对于这个类型而言，它是对于 int 类型的封装，并且提供了原子性的访问和更新。也就是说，我们如果需要一个整型的变量，并且这个变量会被运用在并发场景之下，我们可以不用基本类型 int，也不使用包装类型 Integer，而是直接使用 AtomicInteger，这样一来就自动具备了原子能力，使用起来非常方便。 AtomicInteger 类常用方法 AtomicInteger 类有以下几个常用的方法： public final int get() //获取当前的值 因为它本身是一个 Java 类，而不再是一个基本类型，所以要想获取值还是需要一些方法，比如通过 get 方法就可以获取到当前的值。 public final int getAndSet(int newValue) //获取当前的值，并设置新的值 接下来的几个方法和它平时的操作相关： public final int getAndIncrement() //获取当前的值，并自增 public final int getAndDecrement() //获取当前的值，并自减 public final int getAndAdd(int delta) //获取当前的值，并加上预期的值 这个参数就是想让当前这个原子类改变多少值，可以是正数也可以是负数，如果是正数就是增加，如果是负数就是减少。而刚才的 getAndIncrement 和 getAndDecrement 修改的数值默认为 +1 或 -1，如果不能满足需求，我们就可以使用 getAndAdd 方法来直接一次性地加减我们想要的数值。 boolean compareAndSet(int expect, int update) //如果输入的数值等于预期值，则以原子方式将该值更新为输入值（update） 这个方法也是 CAS 的一个重要体现。 Array 数组类型原子类 第二大类 Atomic*Array 数组类型原子类，数组里的元素，都可以保证其原子性，比如 AtomicIntegerArray 相当于把 AtomicInteger 聚合起来，组合成一个数组。这样一来，我们如果想用一个每一个元素都具备原子性的数组的话， 就可以使用 Atomic*Array。 它一共分为 3 种，分别是： AtomicIntegerArray：整形数组原子类； AtomicLongArray：长整形数组原子类； AtomicReferenceArray ：引用类型数组原子类。 Atomic\\Reference 引用类型原子类 第三种 AtomicReference 引用类型原子类。AtomicReference 类的作用和AtomicInteger 并没有本质区别， AtomicInteger 可以让一个整数保证原子性，而AtomicReference 可以让一个对象保证原子性。这样一来，AtomicReference 的能力明显比 AtomicInteger 强，因为一个对象里可以包含很多属性。 在这个类别之下，除了 AtomicReference 之外，还有： AtomicStampedReference：它是对 AtomicReference 的升级，在此基础上还加了时间戳，用于解决 CAS 的 ABA 问题。 AtomicMarkableReference：和 AtomicReference 类似，多了一个绑定的布尔值，可以用于表示该对象已删除等场景。 Atomic\\FieldUpdater 原子更新器 第四类是 Atomic\\FieldUpdater，我们把它称为原子更新器，一共有三种，分别是。 AtomicIntegerFieldUpdater：原子更新整形的更新器； AtomicLongFieldUpdater：原子更新长整形的更新器； AtomicReferenceFieldUpdater：原子更新引用的更新器。 如果我们之前已经有了一个变量，比如是整型的 int，实际它并不具备原子性。可是木已成舟，这个变量已经被定义好了，此时我们有没有办法可以让它拥有原子性呢？办法是有的，就是利用 Atomic*FieldUpdater，如果它是整型的，就使用 AtomicIntegerFieldUpdater 把已经声明的变量进行升级，这样一来这个变量就拥有了 CAS 操作的能力。 这里的非互斥同步手段，是把我们已经声明好的变量进行 CAS 操作以达到同步的目的。那么你可能会想，既然想让这个变量具备原子性，为什么不在一开始就声明为 AtomicInteger？这样也免去了升级的过程，难道是一开始设计的时候不合理吗？这里有以下几种情况： 第一种情况是出于历史原因考虑，那么如果出于历史原因的话，之前这个变量已经被声明过了而且被广泛运用，那么修改它成本很高，所以我们可以利用升级的原子类。 另外还有一个使用场景，如果我们在大部分情况下并不需要使用到它的原子性，只在少数情况，比如每天只有定时一两次需要原子操作的话，我们其实没有必要把原来的变量声明为原子类型的变量，因为 AtomicInteger 比普通的变量更加耗费资源。所以如果我们有成千上万个原子类的实例的话，它占用的内存也会远比我们成千上万个普通类型占用的内存高。所以在这种情况下，我们可以利用 AtomicIntegerFieldUpdater 进行合理升级，节约内存。 看一段代码： 12345678910111213141516171819202122232425262728293031323334public class AtomicIntegerFieldUpdaterDemo implements Runnable&#123; static Score math; static Score computer; public static AtomicIntegerFieldUpdater&lt;Score&gt; scoreUpdater = AtomicIntegerFieldUpdater .newUpdater(Score.class, \"score\"); @Override public void run() &#123; for (int i = 0; i &lt; 1000; i++) &#123; computer.score++; scoreUpdater.getAndIncrement(math); &#125; &#125; public static class Score &#123; volatile int score; &#125; public static void main(String[] args) throws InterruptedException &#123; math =new Score(); computer =new Score(); AtomicIntegerFieldUpdaterDemo2 r = new AtomicIntegerFieldUpdaterDemo2(); Thread t1 = new Thread(r); Thread t2 = new Thread(r); t1.start(); t2.start(); t1.join(); t2.join(); System.out.println(\"普通变量的结果：\"+ computer.score); System.out.println(\"升级后的结果：\"+ math.score); &#125;&#125; 这段代码就演示了这个类的用法，比如说有两个类，它们都是 Score 类型的，Score 类型内部会有一个分数，也叫作 core，那么这两个分数的实例分别叫作数学 math 和计算机 computer，然后我们还声明了一个 AtomicIntegerFieldUpdater，在它构造的时候传入了两个参数，第一个是 Score.class，这是类名，第二个是属性名，叫作 score。 接下来看一下 run 方法，run 方法里面会对这两个实例分别进行自加操作。 第一个是 computer，这里的 computer 我们调用的是它内部的 score，也就是说我们直接调用了 int 变量的自加操作，这在多线程下是线程非安全的。 第二个自加是利用了刚才声明的 scoreUpdater 并且使用了它的 getAndIncrement 方法并且传入了 math，这是一种正确使用AtomicIntegerFieldUpdater 的用法，这样可以线程安全地进行自加操作。 接下来我们看下 main 函数。在 main 函数中，我们首先把 math 和 computer 定义了出来，然后分别启动了两个线程，每个线程都去执行我们刚才所介绍过的 run 方法。这样一来，两个 score，也就是 math 和 computer 都会分别被加 2000 次，最后我们在 join 等待之后把结果打印了出来，这个程序的运行结果如下： 普通变量的结果：1942升级后的结果：2000 可以看出，正如我们所预料的那样，普通变量由于不具备线程安全性，所以在多线程操作的情况下，它虽然看似进行了 2000 次操作，但有一些操作被冲突抵消了，所以最终结果小于 2000。可是使用AtomicIntegerFieldUpdater 这个工具之后，就可以做到把一个普通类型的 score 变量进行原子的自加操作，最后的结果也和加的次数是一样的，也就是 2000。可以看出，这个类的功能还是非常强大的。 Adder 加法器 它里面有两种加法器，分别叫作 LongAdder 和 DoubleAdder。 Accumulator 积累器 最后一种叫 Accumulator 积累器，分别是 LongAccumulator 和 DoubleAccumulator。 以 AtomicInteger 为例，分析在 Java 中如何利用 CAS 实现原子操作？ getAndAdd 方法的代码在 Java 1.8 中的实现如下： 1234//JDK 1.8实现public final int getAndAdd(int delta) &#123; return unsafe.getAndAddInt(this, valueOffset, delta);&#125; 可以看出，里面使用了 Unsafe 这个类，并且调用了 unsafe.getAndAddInt 方法。所以这里需要简要介绍一下 Unsafe 类。 Unsafe 类 Unsafe 其实是 CAS 的核心类。由于 Java 无法直接访问底层操作系统，而是需要通过 native 方法来实现。不过尽管如此，JVM 还是留了一个后门，在 JDK 中有一个 Unsafe 类，它提供了硬件级别的原子操作，我们可以利用它直接操作内存数据。 来看一下 AtomicInteger 的一些重要代码，如下所示： 12345678910111213141516public class AtomicInteger extends Number implements java.io.Serializable &#123; // setup to use Unsafe.compareAndSwapInt for updates private static final Unsafe unsafe = Unsafe.getUnsafe(); private static final long valueOffset; static &#123; try &#123; valueOffset = unsafe.objectFieldOffset (AtomicInteger.class.getDeclaredField(\"value\")); &#125; catch (Exception ex) &#123; throw new Error(ex); &#125; &#125; private volatile int value; public final int get() &#123;return value;&#125; ...&#125; 可以看出，在数据定义的部分，首先还获取了 Unsafe 实例，并且定义了 valueOffset。我们往下看到 static 代码块，这个代码块会在类加载的时候执行，执行时我们会调用 Unsafe 的 objectFieldOffset 方法，从而得到当前这个原子类的 value 的偏移量，并且赋给 valueOffset 变量，这样一来我们就获取到了 value 的偏移量，它的含义是在内存中的偏移地址，因为 Unsafe 就是根据内存偏移地址获取数据的原值的，这样我们就能通过 Unsafe 来实现 CAS 了。 value 是用 volatile 修饰的，它就是我们原子类存储的值的变量，由于它被 volatile 修饰，我们就可以保证在多线程之间看到的 value 是同一份，保证了可见性。 接下来继续看 Unsafe 的 getAndAddInt 方法的实现，代码如下： 1234567public final int getAndAddInt(Object var1, long var2, int var4) &#123; int var5; do &#123; var5 = this.getIntVolatile(var1, var2); &#125; while(!this.compareAndSwapInt(var1, var2, var5, var5 + var4)); return var5;&#125; 这部分源码解析详见上面的1.什么是CAS。 总结一下，Unsafe 的 getAndAddInt 方法是通过循环 + CAS 的方式来实现的，在此过程中，它会通过 compareAndSwapInt 方法来尝试更新 value 的值，如果更新失败就重新获取，然后再次尝试更新，直到更新成功。 5.AtomicInteger 在高并发下性能不好，如何解决？为什么？在并发的场景下，如果我们需要实现计数器，可以利用 AtomicInteger 和 AtomicLong，这样一来，就可以避免加锁和复杂的代码逻辑，有了它们之后，我们只需要执行对应的封装好的方法，例如对这两个变量进行原子的增操作或原子的减操作，就可以满足大部分业务场景的需求。 不过，虽然它们很好用，但是如果业务场景是并发量很大的，这两个原子类实际上会有较大的性能问题，这是为什么呢？ AtomicLong 存在的问题 来看一段代码： 123456789101112131415161718192021222324252627282930/*** 描述： 在16个线程下使用AtomicLong*/public class AtomicLongDemo &#123; public static void main(String[] args) throws InterruptedException &#123; AtomicLong counter = new AtomicLong(0); ExecutorService service = Executors.newFixedThreadPool(16); for (int i = 0; i &lt; 100; i++) &#123; service.submit(new Task(counter)); &#125; Thread.sleep(2000); System.out.println(counter.get()); &#125; static class Task implements Runnable &#123; private final AtomicLong counter; public Task(AtomicLong counter) &#123; this.counter = counter; &#125; @Override public void run() &#123; counter.incrementAndGet(); &#125; &#125;&#125; 在这段代码中可以看出，我们新建了一个原始值为 0 的 AtomicLong。然后，有一个线程数为 16 的线程池，并且往这个线程池中添加了 100 次相同的一个任务。 那我们往下看这个任务是什么。在下面的 Task 类中可以看到，这个任务实际上就是每一次去调用 AtomicLong 的 incrementAndGet 方法，相当于一次自加操作。这样一来，整个类的作用就是把这个原子类从 0 开始，添加 100 个任务，每个任务自加一次。 这段代码的运行结果毫无疑问是 100，虽然是多线程并发访问，但是 AtomicLong 依然可以保证 incrementAndGet 操作的原子性，所以不会发生线程安全问题。 不过如果我们深入一步去看内部情景的话，你可能会感到意外。我们把模型简化成只有两个线程在同时工作的并发场景，因为两个线程和更多个线程本质上是一样的。如图所示： 我们可以看到在这个图中，每一个线程是运行在自己的 core 中的，并且它们都有一个本地内存是自己独用的。在本地内存下方，有两个 CPU 核心共用的共享内存。 对于 AtomicLong 内部的 value 属性而言，也就是保存当前 AtomicLong 数值的属性，它是被 volatile 修饰的，所以它需要保证自身可见性。 这样一来，每一次它的数值有变化的时候，它都需要进行 flush 和 refresh。比如说，如果开始时，ctr 的数值为 0 的话，那么如图所示，一旦 core 1 把它改成 1 的话，它首先会在左侧把这个 1 的最新结果给 flush 到下方的共享内存。然后，再到右侧去往上 refresh 到核心 2 的本地内存。这样一来，对于核心 2 而言，它才能感知到这次变化。 由于竞争很激烈，这样的 flush 和 refresh 操作耗费了很多资源，而且 CAS 也会经常失败。 LongAdder 带来的改进和原理 在 JDK 8 中又新增了 LongAdder 这个类，这是一个针对 Long 类型的操作工具类。那么既然已经有了 AtomicLong，为何又要新增 LongAdder 这么一个类呢？ 我们同样是用一个例子来说明。下面这个例子和刚才的例子很相似，只不过我们把工具类从 AtomicLong 变成了 LongAdder。其他的不同之处还在于最终打印结果的时候，调用的方法从原来的 get 变成了现在的 sum 方法。而其他的逻辑都一样。 我们来看一下使用 LongAdder 的代码示例： 1234567891011121314151617181920212223242526272829/*** 描述： 在16个线程下使用LongAdder*/public class LongAdderDemo &#123; public static void main(String[] args) throws InterruptedException &#123; LongAdder counter = new LongAdder(); ExecutorService service = Executors.newFixedThreadPool(16); for (int i = 0; i &lt; 100; i++) &#123; service.submit(new Task(counter)); &#125; Thread.sleep(2000); System.out.println(counter.sum()); &#125; static class Task implements Runnable &#123; private final LongAdder counter; public Task(LongAdder counter) &#123; this.counter = counter; &#125; @Override public void run() &#123; counter.increment(); &#125; &#125;&#125; 代码的运行结果同样是 100，但是运行速度比刚才 AtomicLong 的实现要快。下面解释一下，为什么高并发下 LongAdder 比 AtomicLong 效率更高。 因为 LongAdder 引入了分段累加的概念，内部一共有两个参数参与计数：第一个叫作 base，它是一个变量，第二个是 Cell[] ，是一个数组。 其中的 base 是用在竞争不激烈的情况下的，可以直接把累加结果改到 base 变量上。 那么，当竞争激烈的时候，就要用到我们的 Cell[] 数组了。一旦竞争激烈，各个线程会分散累加到自己所对应的那个 Cell[] 数组的某一个对象中，而不会大家共用同一个。 这样一来，LongAdder 会把不同线程对应到不同的 Cell 上进行修改，降低了冲突的概率，这是一种分段的理念，提高了并发性，这就和 Java 7 的 ConcurrentHashMap 的 16 个 Segment 的思想类似。 竞争激烈的时候，LongAdder 会通过计算出每个线程的 hash 值来给线程分配到不同的 Cell 上去，每个 Cell 相当于是一个独立的计数器，这样一来就不会和其他的计数器干扰，Cell 之间并不存在竞争关系，所以在自加的过程中，就大大减少了刚才的 flush 和 refresh，以及降低了冲突的概率，这就是为什么 LongAdder 的吞吐量比 AtomicLong 大的原因，本质是空间换时间，因为它有多个计数器同时在工作，所以占用的内存也要相对更大一些。 那么 LongAdder 最终是如何实现多线程计数的呢？答案就在最后一步的求和 sum 方法，执行 LongAdder.sum() 的时候，会把各个线程里的 Cell 累计求和，并加上 base，形成最终的总和。代码如下： 1234567891011public long sum() &#123; Cell[] as = cells; Cell a; long sum = base; if (as != null) &#123; for (int i = 0; i &lt; as.length; ++i) &#123; if ((a = as[i]) != null) sum += a.value; &#125; &#125; return sum;&#125; 在这个 sum 方法中可以看到，思路非常清晰。先取 base 的值，然后遍历所有 Cell，把每个 Cell 的值都加上去，形成最终的总和。由于在统计的时候并没有进行加锁操作，所以这里得出的 sum 不一定是完全准确的，因为有可能在计算 sum 的过程中 Cell 的值被修改了。 如何选择 在低竞争的情况下，AtomicLong 和 LongAdder 这两个类具有相似的特征，吞吐量也是相似的，因为竞争不高。但是在竞争激烈的情况下，LongAdder 的预期吞吐量要高得多，经过试验，LongAdder 的吞吐量大约是 AtomicLong 的十倍，不过凡事总要付出代价，LongAdder 在保证高效的同时，也需要消耗更多的空间。 AtomicLong 可否被 LongAdder 替代？ 答案：不是，这需要区分场景。 LongAdder 只提供了 add、increment 等简单的方法，适合的是统计求和计数的场景，场景比较单一，而 AtomicLong 还具有 compareAndSet 等高级方法，可以应对除了加减之外的更复杂的需要 CAS 的场景。 结论：如果我们的场景仅仅是需要用到加和减操作的话，那么可以直接使用更高效的 LongAdder，但如果我们需要利用 CAS 比如 compareAndSet 等操作的话，就需要使用 AtomicLong 来完成。 6.原子类和 volatile 有什么异同？volatile 和原子类的异同 首先看一个案例。如图所示，有两个线程： 在图中左上角可以看出，有一个公共的 boolean flag 标记位，最开始赋值为 true，然后线程 2 会进入一个 while 循环，并且根据这个 flag 也就是标记位的值来决定是否继续执行或着退出。 最开始由于 flag 的值是 true，所以首先会在这里执行一定时期的循环。然后假设在某一时刻，线程 1 把这个 flag 的值改为 false 了，它所希望的是，线程 2 看到这个变化后停止运行。 但是这样做其实是有风险的，线程 2 可能并不能立刻停下来，也有可能过一段时间才会停止，甚至在最极端的情况下可能永远都不会停止。 为了理解发生这种情况的原因，我们首先来看一下 CPU 的内存结构，这里是一个双核的 CPU 的简单示意图： 可以看出，线程 1 和线程 2 分别在不同的 CPU 核心上运行，每一个核心都有自己的本地内存，并且在下方也有它们共享的内存。 最开始它们都可以读取到 flag 为 true ，不过当线程 1 这个值改为 false 之后，线程 2 并不能及时看到这次修改，因为线程 2 不能直接访问线程 1 的本地内存，这样的问题就是一个非常典型的可见性问题。 要想解决这个问题，我们只需要在变量的前面加上 volatile 关键字修饰，只要我们加上这个关键字，那么每一次变量被修改的时候，其他线程对此都可见，这样一旦线程 1 改变了这个值，那么线程 2 就可以立刻看到，因此就可以退出 while 循环了。 之所以加了关键字之后就就可以让它拥有可见性，原因在于有了这个关键字之后，线程 1 的更改会被 flush 到共享内存中，然后又会被 refresh 到线程 2 的本地内存中，这样线程 2 就能感受到这个变化了，所以 volatile 这个关键字最主要是用来解决可见性问题的，可以一定程度上保证线程安全。 现在让我们回顾一下很熟悉的多线程同时进行 value++ 的场景，如图所示： 如果它被初始化为每个线程都加 1000 次，最终的结果很可能不是 2000。由于 value++ 不是原子的，所以在多线程的情况下，会出现线程安全问题。但是如果我们在这里使用 volatile 关键字，能不能解决问题呢？ 很遗憾，答案是即便使用了 volatile 也是不能保证线程安全的，因为这里的问题不单单是可见性问题，还包含原子性问题。 我们有多种办法可以解决这里的问题，第 1 种是使用 synchronized 关键字，如图所示： 这样一来，两个线程就不能同时去更改 value 的数值，保证了 value++ 语句的原子性，并且 synchronized 同样保证了可见性，也就是说，当第 1 个线程修改了 value 值之后，第 2 个线程可以立刻看见本次修改的结果。 解决这个问题的第 2 个方法，就是使用我们的原子类，如图所示： 比如用一个 AtomicInteger，然后每个线程都调用它的 incrementAndGet 方法。 在利用了原子变量之后就无需加锁，我们可以使用它的 incrementAndGet 方法，这个操作底层由 CPU 指令保证原子性，所以即便是多个线程同时运行，也不会发生线程安全问题。 原子类和 volatile 的使用场景 可以看出，volatile 和原子类的使用场景是不一样的，如果我们有一个可见性问题，那么可以使用 volatile 关键字，但如果我们的问题是一个组合操作，需要用同步来解决原子性问题的话，那么可以使用原子变量，而不能使用 volatile 关键字。 通常情况下，volatile 可以用来修饰 boolean 类型的标记位，因为对于标记位来讲，直接的赋值操作本身就是具备原子性的，再加上 volatile 保证了可见性，那么就是线程安全的了。 而对于会被多个线程同时操作的计数器 Counter 的场景，这种场景的一个典型特点就是，它不仅仅是一个简单的赋值操作，而是需要先读取当前的值，然后在此基础上进行一定的修改，再把它给赋值回去。这样一来，我们的 volatile 就不足以保证这种情况的线程安全了。我们需要使用原子类来保证线程安全。 7.AtomicInteger 和 synchronized 的异同点？(1).原理 synchronized ：在执行同步代码之前，需要首先获取到 monitor 锁，执行完毕后，再释放锁。 原子类：保证线程安全的原理是利用了 CAS 操作。 (2).使用范围 对于原子类而言，它的使用范围是比较局限的。因为一个原子类仅仅是一个对象，不够灵活。而 synchronized 的使用范围要广泛得多。比如说 synchronized 既可以修饰一个方法，又可以修饰一段代码，相当于可以根据我们的需要，非常灵活地去控制它的应用范围。 所以仅有少量的场景，例如计数器等场景，我们可以使用原子类。而在其他更多的场景下，如果原子类不适用，那么我们就可以考虑用 synchronized 来解决这个问题。 (3).粒度 原子变量的粒度是比较小的，它可以把竞争范围缩小到变量级别。通常情况下，synchronized 锁的粒度都要大于原子变量的粒度。如果我们只把一行代码用 synchronized 给保护起来的话，有一点杀鸡焉用牛刀的感觉。 (4).性能 因为 synchronized 是一种典型的悲观锁，而原子类恰恰相反，它利用的是乐观锁。所以，我们在比较 synchronized 和 AtomicInteger 的时候，其实也就相当于比较了悲观锁和乐观锁的区别。 从性能上来考虑的话，悲观锁的操作相对来讲是比较重量级的。因为 synchronized 在竞争激烈的情况下，会让拿不到锁的线程阻塞，而原子类是永远不会让线程阻塞的。不过，虽然 synchronized 会让线程阻塞，但是这并不代表它的性能就比原子类差。 因为悲观锁的开销是固定的，也是一劳永逸的。随着时间的增加，这种开销并不会线性增长。 而乐观锁虽然在短期内的开销不大，但是随着时间的增加，它的开销也是逐步上涨的。 所以从性能的角度考虑，它们没有一个孰优孰劣的关系，而是要区分具体的使用场景。在竞争非常激烈的情况下，推荐使用 synchronized；而在竞争不激烈的情况下，使用原子类会得到更好的效果。 值得注意的是，synchronized 的性能随着 JDK 的升级，也得到了不断的优化。synchronized 会从无锁升级到偏向锁，再升级到轻量级锁，最后才会升级到让线程阻塞的重量级锁。因此synchronized 在竞争不激烈的情况下，性能也是不错的，不需要“谈虎色变”。 8.Java 8 中 Adder 和 Accumulator 有什么区别？Adder 的介绍 Adder 和 Accumulator 都是 Java 8 引入的，是相对比较新的类。对于 Adder 而言，比如最典型的 LongAdder，在高并发下 LongAdder 比 AtomicLong 效率更高，因为对于 AtomicLong 而言，它只适合用于低并发场景，否则在高并发的场景下，由于 CAS 的冲突概率大，会导致经常自旋，影响整体效率。 而 LongAdder 引入了分段锁的概念，当竞争不激烈的时候，所有线程都是通过 CAS 对同一个 Base 变量进行修改，但是当竞争激烈的时候，LongAdder 会把不同线程对应到不同的 Cell 上进行修改，降低了冲突的概率，从而提高了并发性。 Accumulator 的介绍 Accumulator 和 Adder 非常相似，实际上 Accumulator 就是一个更通用版本的 Adder，比如 LongAccumulator 是 LongAdder 的功能增强版，因为 LongAdder 的 API 只有对数值的加减，而 LongAccumulator 提供了自定义的函数操作。 举例说明一下，代码如下： 123456789public class LongAccumulatorDemo &#123; public static void main(String[] args) throws InterruptedException &#123; LongAccumulator accumulator = new LongAccumulator((x, y) -&gt; x + y, 0); ExecutorService executor = Executors.newFixedThreadPool(8); IntStream.range(1, 10).forEach(i -&gt; executor.submit(() -&gt; accumulator.accumulate(i))); Thread.sleep(2000); System.out.println(accumulator.getThenReset()); &#125;&#125; 在这段代码中： 首先新建了一个 LongAccumulator，同时给它传入了两个参数； 然后又新建了一个 8 线程的线程池，并且利用整形流也就是 IntStream 往线程池中提交了从 1 ~ 9 这 9 个任务； 之后等待了两秒钟，这两秒钟的作用是等待线程池的任务执行完毕； 最后把 accumulator 的值打印出来。 这段代码的运行结果是 45，代表 0+1+2+3+…+8+9=45 的结果，这个结果怎么理解呢？我们先重点看看新建的 LongAccumulator 的这一行语句： 1LongAccumulator accumulator = new LongAccumulator((x, y) -&gt; x + y, 0); 在这个语句中，我们传入了两个参数：LongAccumulator 的构造函数的第一个参数是二元表达式；第二个参数是 x 的初始值，传入的是 0。在二元表达式中，x 是上一次计算的结果（除了第一次的时候需要传入），y 是本次新传入的值。 案例分析 我们来看一下上面这段代码执行的过程，当执行 accumulator.accumulate(1) 的时候，首先要知道这时候 x 和 y 是什么，第一次执行时， x 是 LongAccumulator 构造函数中的第二个参数，也就是 0，而第一次执行时的 y 值就是本次 accumulator.accumulate(1) 方法所传入的 1；然后根据表达式 x+y，计算出 0+1=1，这个结果会赋值给下一次计算的 x，而下一次计算的 y 值就是 accumulator.accumulate(2) 传入的 2，所以下一次的计算结果是 1+2=3。 我们在 IntStream.range(1, 10).forEach(i -&gt; executor.submit(() -&gt; accumulator.accumulate(i))); 这一行语句中实际上利用了整型流，分别给线程池提交了从 1 ~ 9 这 9 个任务，相当于执行了： 123456accumulator.accumulate(1);accumulator.accumulate(2);accumulator.accumulate(3);...accumulator.accumulate(8);accumulator.accumulate(9); 那么根据上面的这个推演，就可以得出它的内部运行，这也就意味着，LongAccumulator 执行了： 1234567890+1&#x3D;1;1+2&#x3D;3;3+3&#x3D;6;6+4&#x3D;10;10+5&#x3D;15;15+6&#x3D;21;21+7&#x3D;28;28+8&#x3D;36;36+9&#x3D;45; 这里需要指出的是，这里的加的顺序是不固定的，并不是说会按照顺序从 1 开始逐步往上累加，它也有可能会变，比如说先加 5、再加 3、再加 6。但总之，由于加法有交换律，所以最终加出来的结果会保证是 45。这就是这个类的一个基本的作用和用法。 拓展功能 我们继续看一下它的功能强大之处。举几个例子，刚才我们给出的表达式是 x + y，其实同样也可以传入 x * y，或者写一个 Math.min(x, y)，相当于求 x 和 y 的最小值。同理，也可以去求 Math.max(x, y)，相当于求一个最大值。根据业务的需求来选择就可以了。代码如下： 1234LongAccumulator counter = new LongAccumulator((x, y) -&gt; x + y, 0);LongAccumulator result = new LongAccumulator((x, y) -&gt; x * y, 0);LongAccumulator min = new LongAccumulator((x, y) -&gt; Math.min(x, y), 0);LongAccumulator max = new LongAccumulator((x, y) -&gt; Math.max(x, y), 0); 在这里为什么不用 for 循环呢？比如说我们之前的例子，从 0 加到 9，我们直接写一个 for 循环不就可以了吗？ 确实，用 for 循环也能满足需求，但是用 for 循环的话，它执行的时候是串行，它一定是按照 0+1+2+3+…+8+9 这样的顺序相加的，但是 LongAccumulator 的一大优势就是可以利用线程池来为它工作。一旦使用了线程池，那么多个线程之间是可以并行计算的，效率要比之前的串行高得多。这也是为什么刚才说它加的顺序是不固定的，因为我们并不能保证各个线程之间的执行顺序，所能保证的就是最终的结果是确定的。 适用场景 第一点需要满足的条件，就是需要大量的计算，并且当需要并行计算的时候，我们可以考虑使用 LongAccumulator。 当计算量不大，或者串行计算就可以满足需求的时候，可以使用 for 循环；如果计算量大，需要提高计算的效率时，我们则可以利用线程池，再加上 LongAccumulator 来配合的话，就可以达到并行计算的效果，效率非常高。 第二点需要满足的要求，就是计算的执行顺序并不关键，也就是说它不要求各个计算之间的执行顺序，也就是说线程 1 可能在线程 5 之后执行，也可能在线程 5 之前执行，但是执行的先后并不影响最终的结果。 一些非常典型的满足这个条件的计算，就是类似于加法或者乘法，因为它们是有交换律的。同样，求最大值和最小值对于顺序也是没有要求的，因为最终只会得出所有数字中的最大值或者最小值，无论先提交哪个或后提交哪个，都不会影响到最终的结果。","tags":[{"name":"java","slug":"java","permalink":"https://sunshine-zwq.gitee.io/tags/java/"},{"name":"并发编程","slug":"并发编程","permalink":"https://sunshine-zwq.gitee.io/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"},{"name":"面试","slug":"面试","permalink":"https://sunshine-zwq.gitee.io/tags/%E9%9D%A2%E8%AF%95/"}]},{"title":"Java并发编程常见问题-Java内存模型","date":"2020-12-15T09:56:27.000Z","path":"2020/12/15/Java并发编程常见问题-Java内存模型/","text":"1.讲一讲什么是 Java 内存模型？容易混淆：JVM 内存结构 VS Java 内存模型 Java 作为一种面向对象的语言，有很多概念，从名称上看起来比较相似，比如 JVM 内存结构、Java 内存模型，这是两个截然不同的概念，但是很容易混淆。 两者的主要作用： JVM 内存结构和 Java 虚拟机的运行时区域有关； Java 内存模型和 Java 的并发编程有关。 JVM 内存结构 Java 代码运行在虚拟机上，而虚拟机在执行 Java 程序的过程中会把所管理的内存划分为若干个不同的数据区域，这些区域都有各自的用途。在《Java 虚拟机规范（Java SE 8）》中描述了 JVM 运行时内存区域结构可分为以下 6 个区： 堆区（Heap）：堆是存储类实例和数组的，通常是内存中最大的一块。实例很好理解，比如 new Object() 就会生成一个实例；而数组也是保存在堆上面的，因为在 Java 中，数组也是对象。 虚拟机栈（Java Virtual Machine Stacks）：它保存局部变量和部分结果，并在方法调用和返回中起作用。 方法区（Method Area）：它存储每个类的结构，例如运行时的常量池、字段和方法数据，以及方法和构造函数的代码，包括用于类初始化以及接口初始化的特殊方法。 本地方法栈（Native Method Stacks）：与虚拟机栈基本类似，区别在于虚拟机栈为虚拟机执行的 Java 方法服务，而本地方法栈则是为 Native 方法服务。 程序计数器（The PC Register）：是最小的一块内存区域，它的作用通常是保存当前正在执行的 JVM 指令地址。 运行时常量池（Run-Time Constant Pool）：是方法区的一部分，包含多种常量，范围从编译时已知的数字到必须在运行时解析的方法和字段引用。 注意，以上是 Java 虚拟机规范，不同的虚拟机实现会各有不同，一般会遵守规范。 从 Java 代码到 CPU 指令 编写的 Java 代码，最终还是要转化为 CPU 指令才能执行的。为了理解 Java 内存模型的作用，我们先来回顾一下从 Java 代码到最终执行的 CPU 指令的大致流程： 最开始，我们编写的 Java 代码，是 *.java文件； 在编译（包含词法分析、语义分析等步骤）后，在刚才的 *.java 文件之外，会多出一个新的 Java 字节码文件（*.class）； JVM 会分析刚才生成的字节码文件（*.class），并根据平台等因素，把字节码文件转化为具体平台上的机器指令； 机器指令则可以直接在 CPU 上运行，也就是最终的程序执行。 为什么需要 JMM（Java Memory Model，Java 内存模型） 在更早期的语言中，其实是不存在内存模型的概念的。 所以程序最终执行的效果会依赖于具体的处理器，而不同的处理器的规则又不一样，不同的处理器之间可能差异很大，因此同样的一段代码，可能在处理器 A 上运行正常，而在处理器 B 上运行的结果却不一致。同理，在没有 JMM 之前，不同的 JVM 的实现，也会带来不一样的“翻译”结果。 所以 Java 非常需要一个标准，来让 Java 开发者、编译器工程师和 JVM 工程师能够达成一致。达成一致后，我们就可以很清楚的知道什么样的代码最终可以达到什么样的运行效果，让多线程运行结果可以预期，这个标准就是 JMM，这就是需要 JMM 的原因。 JMM 是规范 JMM 是和多线程相关的一组规范，需要各个 JVM 的实现来遵守 JMM 规范，以便于开发者可以利用这些规范，更方便地开发多线程程序。这样一来，即便同一个程序在不同的虚拟机上运行，得到的程序结果也是一致的。 如果没有 JMM 内存模型来规范，那么很可能在经过了不同 JVM 的“翻译”之后，导致在不同的虚拟机上运行的结果不一样，那是很大的问题。 因此，JMM 与处理器、缓存、并发、编译器有关。它解决了 CPU 多级缓存、处理器优化、指令重排等导致的结果不可预期的问题。 JMM 是工具类和关键字的原理 之前我们使用了各种同步工具和关键字，包括 volatile、synchronized、Lock 等，其实它们的原理都涉及 JMM。正是 JMM 的参与和帮忙，才让各个同步工具和关键字能够发挥作用，帮我们开发出并发安全的程序。 比如我们写了关键字 synchronized，JVM 就会在 JMM 的规则下，“翻译”出合适的指令，包括限制指令之间的顺序，以便在即使发生了重排序的情况下，也能保证必要的“可见性”，这样一来，不同的 JVM 对于相同的代码的执行结果就变得可预期了，我们 Java 程序员就只需要用同步工具和关键字就可以开发出正确的并发程序了，这都要感谢 JMM。 JMM 里最重要 3 点内容，分别是：重排序、原子性、内存可见性。 2.什么是指令重排序？为什么要重排序？什么是重排序 假设我们写了一个 Java 程序，包含一系列的语句，我们会默认期望这些语句的实际运行顺序和写的代码顺序一致。但实际上，编译器、JVM 或者 CPU 都有可能出于优化等目的，对于实际指令执行的顺序进行调整，这就是重排序。 重排序的好处：提高处理速度 例如： 图中左侧是 3 行 Java 代码，右侧是这 3 行代码可能被转化成的指令。可以看出 a = 100 对应的是 Load a、Set to 100、Store a，意味着从主存中读取 a 的值，然后把值设置为 100，并存储回去，同理， b = 5 对应的是下面三行 Load b、Set to 5、Store b，最后的 a = a + 10，对应的是 Load a、Set to 110、Store a。如果你仔细观察，会发现这里有两次“Load a”和两次“Store a”，说明存在一定的重排序的优化空间。 经过重排序之后，情况如下图所示： 重排序后， a 的两次操作被放到一起，指令执行情况变为 Load a、Set to 100、Set to 110、 Store a。下面和 b 相关的指令不变，仍对应 Load b、 Set to 5、Store b。 可以看出，重排序后 a 的相关指令发生了变化，节省了一次 Load a 和一次 Store a。重排序通过减少执行指令，从而提高整体的运行速度，这就是重排序带来的优化和好处。 重排序的 3 种情况 （1）编译器优化 编译器（包括 JVM、JIT 编译器等）出于优化的目的，例如当前有了数据 a，把对 a 的操作放到一起效率会更高，避免读取 b 后又返回来重新读取 a 的时间开销，此时在编译的过程中会进行一定程度的重排。不过重排序并不意味着可以任意排序，它需要需要保证重排序后，不改变单线程内的语义，否则如果能任意排序的话，程序早就逻辑混乱了。 （2）CPU 重排序 CPU 同样会有优化行为，这里的优化和编译器优化类似，都是通过乱序执行的技术来提高整体的执行效率。所以即使之前编译器不发生重排，CPU 也可能进行重排，我们在开发中，一定要考虑到重排序带来的后果。 （3）内存的“重排序” 内存系统内不存在真正的重排序，但是内存会带来看上去和重排序一样的效果，所以这里的“重排序”打了双引号。由于内存有缓存的存在，在 JMM 里表现为主存和本地内存，而主存和本地内存的内容可能不一致，所以这也会导致程序表现出乱序的行为。 举个例子，线程 1 修改了 a 的值，但是修改后没有来得及把新结果写回主存或者线程 2 没来得及读到最新的值，所以线程 2 看不到刚才线程 1 对 a 的修改，此时线程 2 看到的 a 还是等于初始值。但是线程 2 却可能看到线程 1 修改 a 之后的代码执行效果，表面上看起来像是发生了重顺序。 3.Java 中的原子操作有哪些注意事项？什么是原子性和原子操作 在编程中，具备原子性的操作被称为原子操作。原子操作是指一系列的操作，要么全部发生，要么全部不发生，不会出现执行一半就终止的情况。 比如转账行为就是一个原子操作，该过程包含扣除余额、银行系统生成转账记录、对方余额增加等一系列操作。虽然整个过程包含多个操作，但由于这一系列操作被合并成一个原子操作，所以它们要么全部执行成功，要么全部不执行，不会出现执行一半的情况。比如我的余额已经扣除，但是对方的余额却不增加，这种情况是不会出现的，所以说转账行为是具备原子性的。而具有原子性的原子操作，天然具备线程安全的特性。 i++ 这一行代码在 CPU 中执行时，可能会从一行代码变为以下的 3 个指令： 第一个步骤是读取； 第二个步骤是增加； 第三个步骤是保存。 这就说明 i++ 是不具备原子性的，同时也证明了 i++ 不是线程安全的。 Java 中的原子操作有哪些 Java 中的以下几种操作是具备原子性的，属于原子操作： 除了 long 和 double 之外的基本类型（int、byte、boolean、short、char、float）的读/写操作，都天然的具备原子性； 所有引用 reference 的读/写操作； 加了 volatile 后，所有变量的读/写操作（包含 long 和 double）。这也就意味着 long 和 double 加了 volatile 关键字之后，对它们的读写操作同样具备原子性； 在 java.concurrent.Atomic 包中的一部分类的一部分方法是具备原子性的，比如 AtomicInteger 的 incrementAndGet 方法。 long 和 double 的原子性 在前面，我们讲述了 long 和 double 和其他的基本类型不太一样，好像不具备原子性，这是什么原因造成的呢？ 官方文档对于上述问题的描述，如下所示： Non-Atomic Treatment of double and long For the purposes of the Java programming language memory model, a single write to a non-volatile long or double value is treated as two separate writes: one to each 32-bit half. This can result in a situation where a thread sees the first 32 bits of a 64-bit value from one write, and the second 32 bits from another write. Writes and reads of volatile long and double values are always atomic. Writes to and reads of references are always atomic, regardless of whether they are implemented as 32-bit or 64-bit values. Some implementations may find it convenient to divide a single write action on a 64-bit long or double value into two write actions on adjacent 32-bit values. For efficiency’s sake, this behavior is implementation-specific; an implementation of the Java Virtual Machine is free to perform writes to long and double values atomically or in two parts. Implementations of the Java Virtual Machine are encouraged to avoid splitting 64-bit values where possible. Programmers are encouraged to declare shared 64-bit values as volatile or synchronize their programs correctly to avoid possible complications. 从刚才的 JVM 规范中我们可以知道，long 和 double 的值需要占用 64 位的内存空间，而对于 64 位值的写入，可以分为两个 32 位的操作来进行。 这样一来，本来是一个整体的赋值操作，就可能被拆分为低 32 位和高 32 位的两个操作。如果在这两个操作之间发生了其他线程对这个值的读操作，就可能会读到一个错误、不完整的值。 JVM 的开发者可以自由选择是否把 64 位的 long 和 double 的读写操作作为原子操作去实现，并且规范推荐 JVM 将其实现为原子操作。当然，JVM 的开发者也有权利不这么做，这同样是符合规范的。 规范同样规定，如果使用 volatile 修饰了 long 和 double，那么其读写操作就必须具备原子性了。同时，规范鼓励程序员使用 volatile 关键字对这个问题加以控制，由于规范规定了对于 volatile long 和 volatile double 而言，JVM 必须保证其读写操作的原子性，所以加了 volatile 之后，对于程序员而言，就可以确保程序正确。 实际开发中 此时，你可能会有疑问，比如，如果之前对于上述问题不是很了解，在开发过程中没有给 long 和 double 加 volatile，好像也没有出现过问题？而且，在以后的开发过程中，是不是必须给 long 和 double 加 volatile 才是安全的？ 其实在实际开发中，读取到“半个变量”的情况非常罕见，这个情况在目前主流的 Java 虚拟机中不会出现。因为 JVM 规范虽然不强制虚拟机把 long 和 double 的变量写操作实现为原子操作，但它其实是“强烈建议”虚拟机去把该操作作为原子操作来实现的。 而在目前各种平台下的主流虚拟机的实现中，几乎都会把 64 位数据的读写操作作为原子操作来对待，因此我们在编写代码时一般不需要为了避免读到“半个变量”而把 long 和 double 声明为 volatile 的。 原子操作 + 原子操作 != 原子操作 值得注意的是，简单地把原子操作组合在一起，并不能保证整体依然具备原子性。比如连续转账两次的操作行为，显然不能合并当做一个原子操作，虽然每一次转账操作都是具备原子性的，但是将两次转账合为一次的操作，这个组合就不具备原子性了，因为在两次转账之间可能会插入一些其他的操作，例如系统自动扣费等，导致第二次转账失败，而且第二次转账失败并不会影响第一次转账成功。 4.什么是“内存可见性”问题？案例一 123456789public class Visibility &#123; int x = 0; public void write() &#123; x = 1; &#125; public void read() &#123; int y = x; &#125;&#125; 这是一段很简单的代码，类中有两个方法： write 方法，作用是给 x 赋值，代码中，把 x 赋值为 1，由于 x 的初始值是 0，所以执行 write 方法相当于改变了 x 的值； read 方法，作用是把 x 读取出来，读取的时候我们用了一个新的 int 类型变量的 y 来接收 x 的值。 我们假设有两个线程来执行上述代码，第 1 个线程执行的是 write 方法，第 2 个线程执行的是 read 方法。下面我们来分析一下，代码在实际运行过程中的情景是怎么样的，如下图所示： 在图中可以看出，由于 x 的初始值为 0，所以对于左边的第 1 个线程和右边的第 2 个线程而言，它们都可以从主内存中去获取到这个信息，对两个线程来说 x 都是 0。可是此时我们假设第 1 个线程先去执行 write 方法，它就把 x 的值从 0 改为了 1，但是它改动的动作并不是直接发生在主内存中的，而是会发生在第 1 个线程的工作内存中，如下图所示： 那么，假设线程 1 的工作内存还未同步给主内存，此时假设线程 2 开始读取，那么它读到的 x 值不是 1，而是 0，也就是说虽然此时线程 1 已经把 x 的值改动了，但是对于第 2 个线程而言，根本感知不到 x 的这个变化，这就产生了可见性问题。 案例二 在如下所示的代码中，有两个变量 a 和 b， 并且把它们赋初始值为 10 和 20： 1234567891011121314151617181920212223242526272829303132333435363738394041/** * 描述： 演示可见性带来的问题 */public class VisibilityProblem &#123; int a = 10; int b = 20; private void change() &#123; a = 30; b = a; &#125; private void print() &#123; System.out.println(\"b=\" + b + \";a=\" + a); &#125; public static void main(String[] args) &#123; while (true) &#123; VisibilityProblem problem = new VisibilityProblem(); new Thread(new Runnable() &#123; @Override public void run() &#123; try &#123; Thread.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; problem.change(); &#125; &#125;).start(); new Thread(new Runnable() &#123; @Override public void run() &#123; try &#123; Thread.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; problem.print(); &#125; &#125;).start(); &#125; &#125;&#125; 在类中，有两个方法： change 方法，把 a 改成 30，然后把 b 赋值为 a 的值； print 方法，先打印出 b 的值，然后再打印出 a 的值。 接下来我们来看一下 main 函数，在 main 函数中同样非常简单。首先有一个 while 的死循环，在这个循环中，我们新建两个线程，并且让它们先休眠一毫秒，然后再分别去执行 change 方法和 print 方法。休眠一毫秒的目的是让它们执行这两个方法的时间，尽可能的去靠近。 下面我们运行这段代码并分析一下可能出现的情况。 第 1 种情况：是最普通的情况了。假设第 1 个线程，也就是执行 change 的线程先运行，并且运行完毕了，然后第 2 个线程开始运行，那么第 2 个线程自然会打印出 b = 30;a = 30 的结果。 第 2 种情况：与第 1 种情况相反。因为线程先 start，并不代表它真的先执行，所以第 2 种情况是第 2 个线程先打印，然后第 1 个线程再去进行 change，那么此时打印出来的就是 a 和 b 的初始值，打印结果为 b = 20;a = 10。 第 3 种情况：它们几乎同时运行，所以会出现交叉的情况。比如说当第 1 个线程的 change 执行到一半，已经把 a 的值改为 30 了，而 b 的值还未来得及修改，此时第 2 个线程就开始打印了，所以此时打印出来的 b 还是原始值 20，而 a 已经变为了 30， 即打印结果为 b = 20;a = 30。 这些都很好理解，但是有一种情况不是特别容易理解，那就是打印结果为 b = 30;a = 10，我们来想一下，为什么会发生这种情况？ 首先打印出来的是 b = 30，这意味着 b 的值被改变了，也就是说 b = a 这个语句已经执行了； 如果 b = a 要想执行，那么前面 a = 30 也需要执行，此时 b 才能等于 a 的值，也就是 30； 这也就意味着 change 方法已经执行完毕了。 可是在这种情况下再打印 a，结果应该是 a = 30，而不应该打印出 a = 10。因为在刚才 change 执行的过程中，a 的值已经被改成 30 了，不再是初始值的 10。所以，如果出现了打印结果为 b = 30;a = 10 这种情况，就意味着发生了可见性问题：a 的值已经被第 1 个线程修改了，但是其他线程却看不到，由于 a 的最新值却没能及时同步过来，所以才会打印出 a 的旧值。发生上述情况的几率不高。 解决问题 在案例一中，我们可以使用 volatile 来解决问题，我们在原来的代码的基础上给 x 变量加上 volatile 修饰，其他的代码不变。加了 volatile 关键字之后，只要第 1 个线程修改完了 x 的值，那么当第 2 个线程想读取 x 的时候，它一定可以读取到 x 的最新的值，而不可能读取到旧值。案例二同理。 能够保证可见性的措施 除了 volatile 关键字可以让变量保证可见性外，synchronized、Lock、并发集合等一系列工具都可以在一定程度上保证可见性，具体保证可见性的时机和手段。 synchronized 不仅保证了原子性，还保证了可见性 关于 synchronized 这里有一个特别值得说的点，我们之前可能一致认为，使用了 synchronized 之后，它会设立一个临界区，这样在一个线程操作临界区内的数据的时候，另一个线程无法进来同时操作，所以保证了线程安全。 其实这是不全面的，这种说法没有考虑到可见性问题，完整的说法是：synchronized 不仅保证了临界区内最多同时只有一个线程执行操作，同时还保证了在前一个线程释放锁之后，之前所做的所有修改，都能被获得同一个锁的下一个线程所看到，也就是能读取到最新的值。因为如果其他线程看不到之前所做的修改，依然也会发生线程安全问题。 5.主内存和工作内存的关系？CPU 有多级缓存，导致读的数据过期 由于 CPU 的处理速度很快，相比之下，内存的速度就显得很慢，所以为了提高 CPU 的整体运行效率，减少空闲时间，在 CPU 和内存之间会有 cache 层，也就是缓存层的存在。虽然缓存的容量比内存小，但是缓存的速度却比内存的速度要快得多，其中 L1 缓存的速度仅次于寄存器的速度。结构示意图如下所示： 在图中，从下往上分别是内存，L3 缓存、L2 缓存、L1 缓存，寄存器，然后最上层是 CPU 的 4个核心。从内存，到 L3 缓存，再到 L2 和 L1 缓存，它们距离 CPU 的核心越来越近了，越靠近核心，其容量就越小，但是速度也越快。正是由于缓存层的存在，才让我们的 CPU 能发挥出更好的性能。 其实，线程间对于共享变量的可见性问题，并不是直接由多核引起的，而是由我们刚才讲到的这些 L3 缓存、L2 缓存、L1 缓存，也就是多级缓存引起的：每个核心在获取数据时，都会将数据从内存一层层往上读取，同样，后续对于数据的修改也是先写入到自己的 L1 缓存中，然后等待时机再逐层往下同步，直到最终刷回内存。 假设 core 1 修改了变量 a 的值，并写入到了 core 1 的 L1 缓存里，但是还没来得及继续往下同步，由于 core 1 有它自己的的 L1 缓存，core 4 是无法直接读取 core 1 的 L1 缓存的值的，那么此时对于 core 4 而言，变量 a 的值就不是 core 1 修改后的最新的值，core 4 读取到的值可能是一个过期的值，从而引起多线程时可见性问题的发生。 JMM的抽象：主内存和工作内存 Java 作为高级语言，屏蔽了 L1 缓存、L2 缓存、L3 缓存，也就是多层缓存的这些底层细节，用 JMM 定义了一套读写数据的规范。我们不再需要关心 L1 缓存、L2 缓存、L3 缓存等多层缓存的问题，我们只需要关心 JMM 抽象出来的主内存和工作内存的概念。为了更方便你去理解，可参考下图： 每个线程只能够直接接触到工作内存，无法直接操作主内存，而工作内存中所保存的正是主内存的共享变量的副本，主内存和工作内存之间的通信是由 JMM 控制的。 主内存和工作内存的关系 JMM 有以下规定： （1）所有的变量都存储在主内存中，同时每个线程拥有自己独立的工作内存，而工作内存中的变量的内容是主内存中该变量的拷贝； （2）线程不能直接读 / 写主内存中的变量，但可以操作自己工作内存中的变量，然后再同步到主内存中，这样，其他线程就可以看到本次修改； （3） 主内存是由多个线程所共享的，但线程间不共享各自的工作内存，如果线程间需要通信，则必须借助主内存中转来完成。 听到这里，你对上图的理解可能会更深刻一些，从图中可以看出，每个工作内存中的变量都是对主内存变量的一个拷贝，相当于是一个副本。而且图中没有一条线是可以直接连接各个工作内存的，因为工作内存之间的通信，都需要通过主内存来中转。 正是由于所有的共享变量都存在于主内存中，每个线程有自己的工作内存，其中存储的是变量的副本，所以这个副本就有可能是过期的，我们来举个例子：如果一个变量 x 被线程 A 修改了，只要还没同步到主内存中，线程 B 就看不到，所以此时线程 B 读取到的 x 值就是一个过期的值，这就导致了可见性问题。 6.什么是 happens-before 规则？什么是 happens-before 关系 Happens-before 关系是用来描述和可见性相关问题的：如果第一个操作 happens-before 第二个操作（也可以描述为，第一个操作和第二个操作之间满足 happens-before 关系），那么我们就说第一个操作对于第二个操作一定是可见的，也就是第二个操作在执行时就一定能保证看见第一个操作执行的结果。 不具备 happens-before 关系的例子 123456789public class Visibility &#123; int x = 0; public void write() &#123; x = 1; &#125; public void read() &#123; int y = x; &#125;&#125; 代码很简单，类里面有一个 int x 变量 ，初始值为 0，而 write 方法的作用是把 x 的值改写为 1， 而 read 方法的作用则是读取 x 的值。 如果有两个线程，分别执行 write 和 read 方法，那么由于这两个线程之间没有相互配合的机制，所以 write 和 read 方法内的代码不具备 happens-before 关系，其中的变量的可见性无法保证，下面我们用例子说明这个情况。 比如，假设线程 1 已经先执行了 write 方法，修改了共享变量 x 的值，然后线程 2 执行 read 方法去读取 x 的值，此时我们并不能确定线程 2 现在是否能读取到之前线程 1 对 x 所做的修改，线程 2 有可能看到这次修改，所以读到的 x 值是 1，也有可能看不到本次修改，所以读到的 x 值是最初始的 0。既然存在不确定性，那么 write 和 read 方法内的代码就不具备 happens-before 关系。相反，如果第一个操作 happens-before 第二个操作，那么第一个操作对于第二个操作而言一定是可见的。 Happens-before 关系的规则有哪些？ 如果分别有操作 x 和操作 y，用 hb(x, y) 来表示 x happens-before y。 （1）单线程规则： 在一个单独的线程中，按照程序代码的顺序，先执行的操作 happen-before 后执行的操作。也就是说，如果操作 x 和操作 y 是同一个线程内的两个操作，并且在代码里 x 先于 y 出现，那么有 hb(x, y)，正如下图所示： 这一个 happens-before 的规则非常重要，因为如果对于同一个线程内部而言，后面语句都不能保证可以看见前面的语句的执行结果的话，那会造成非常严重的后果，程序的逻辑性就无法保证了。 这里有一个注意点，我们之前讲过重排序，那是不是意味着 happens-before 关系的规则和重排序冲突，为了满足 happens-before 关系，就不能重排序了？ 答案是否定的。其实只要重排序后的结果依然符合 happens-before 关系，也就是能保证可见性的话，那么就不会因此限制重排序的发生。比如，单线程内，语句 1 在语句 2 的前面，所以根据“单线程规则”，语句 1 happens-before 语句 2，但是并不是说语句 1 一定要在语句 2 之前被执行，例如语句 1 修改的是变量 a 的值，而语句 2 的内容和变量 a 无关，那么语句 1 和语句 2 依然有可能被重排序。当然，如果语句 1 修改的是变量 a，而语句 2 正好是去读取变量 a 的值，那么语句 1 就一定会在语句 2 之前执行了。 （2）锁操作规则（synchronized 和 Lock 接口等）： 如果操作 A 是解锁，而操作 B 是对同一个锁的加锁，那么 hb(A, B) 。正如下图所示： 从上图中可以看到，有线程 A 和线程 B 这两个线程。线程 A 在解锁之前的所有操作，对于线程 B 的对同一个锁的加锁之后的所有操作而言，都是可见的。这就是锁操作的 happens-before 关系的规则。 （3）volatile 变量规则：对一个 volatile 变量的写操作 happen-before 后面对该变量的读操作。 这就代表了如果变量被 volatile 修饰，那么每次修改之后，其他线程在读取这个变量的时候一定能读取到该变量最新的值。我们之前介绍过 volatile 关键字，知道它能保证可见性，而这正是由本条规则所规定的。 （4）线程启动规则：Thread 对象的 start 方法 happen-before 此线程 run 方法中的每一个操作。如下图所示： 在图中的例子中，左侧区域是线程 A 启动了一个子线程 B，而右侧区域是子线程 B，那么子线程 B 在执行 run 方法里面的语句的时候，它一定能看到父线程在执行 threadB.start() 前的所有操作的结果。 （5）线程 join 规则： 我们知道 join 可以让线程之间等待，假设线程 A 通过调用 threadB.start() 启动了一个新线程 B，然后调用 threadB.join() ，那么线程 A 将一直等待到线程 B 的 run 方法结束（不考虑中断等特殊情况），然后 join 方法才返回。在 join 方法返回后，线程 A 中的所有后续操作都可以看到线程 B 的 run 方法中执行的所有操作的结果，也就是线程 B 的 run 方法里面的操作 happens-before 线程 A 的 join 之后的语句。如下图所示： （6）中断规则：对线程 interrupt 方法的调用 happens-before 检测该线程的中断事件。 也就是说，如果一个线程被其他线程 interrupt，那么在检测中断时（比如调用 Thread.interrupted 或者 Thread.isInterrupted 方法）一定能看到此次中断的发生，不会发生检测结果不准的情况。 （7）并发工具类的规则： 线程安全的并发容器（如 HashTable）在 get 某个值时一定能看到在此之前发生的 put 等存入操作的结果。也就是说，线程安全的并发容器的存入操作 happens-before 读取操作。 信号量（Semaphore）它会释放许可证，也会获取许可证。这里的释放许可证的操作 happens-before 获取许可证的操作，也就是说，如果在获取许可证之前有释放许可证的操作，那么在获取时一定可以看到。 Future：Future 有一个 get 方法，可以用来获取任务的结果。那么，当 Future 的 get 方法得到结果的时候，一定可以看到之前任务中所有操作的结果，也就是说 Future 任务中的所有操作 happens-before Future 的 get 操作。 线程池：要想利用线程池，就需要往里面提交任务（Runnable 或者 Callable），这里面也有一个 happens-before 关系的规则，那就是提交任务的操作 happens-before 任务的执行。 7.volatile 的作用是什么？与 synchronized 有什么异同？volatile 是什么 volatile是 Java 中的一个关键字，是一种同步机制。当某个变量是共享变量，且这个变量是被 volatile 修饰的，那么在修改了这个变量的值之后，再读取该变量的值时，可以保证获取到的是修改后的最新的值，而不是过期的值。 相比于 synchronized 或者 Lock，volatile 是更轻量的，因为使用 volatile 不会发生上下文切换等开销很大的情况，不会让线程阻塞。 volatile 的作用 第一层的作用是保证可见性。Happens-before 关系中对于 volatile 是这样描述的：对一个 volatile 变量的写操作 happen-before 后面对该变量的读操作。 这就代表了如果变量被 volatile 修饰，那么每次修改之后，接下来在读取这个变量的时候一定能读取到该变量最新的值。 第二层的作用就是禁止重排序。先介绍一下 as-if-serial语义：不管怎么重排序，（单线程）程序的执行结果不会改变。在满足 as-if-serial 语义的前提下，由于编译器或 CPU 的优化，代码的实际执行顺序可能与我们编写的顺序是不同的，这在单线程的情况下是没问题的，但是一旦引入多线程，这种乱序就可能会导致严重的线程安全问题。用了 volatile 关键字就可以在一定程度上禁止这种重排序。 volatile 和 synchronized 的关系 相似性：volatile 可以看作是一个轻量版的 synchronized，比如一个共享变量如果自始至终只被各个线程赋值和读取，而没有其他操作的话，那么就可以用 volatile 来代替 synchronized 或者代替原子变量，足以保证线程安全。实际上，对 volatile 字段的每次读取或写入都类似于“半同步”——读取 volatile 与获取 synchronized 锁有相同的内存语义，而写入 volatile 与释放 synchronized 锁具有相同的语义。 不可代替：但是在更多的情况下，volatile 是不能代替 synchronized 的，volatile 并没有提供原子性和互斥性。 性能方面：volatile 属性的读写操作都是无锁的，正是因为无锁，所以不需要花费时间在获取锁和释放锁上，所以说它是高性能的，比 synchronized 性能更好。","tags":[{"name":"java","slug":"java","permalink":"https://sunshine-zwq.gitee.io/tags/java/"},{"name":"并发编程","slug":"并发编程","permalink":"https://sunshine-zwq.gitee.io/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"},{"name":"面试","slug":"面试","permalink":"https://sunshine-zwq.gitee.io/tags/%E9%9D%A2%E8%AF%95/"}]},{"title":"Java并发编程常见问题-线程池","date":"2020-12-15T05:41:30.000Z","path":"2020/12/15/Java并发编程常见问题-线程池/","text":"1.使用线程池比手动创建线程好在哪里？为什么要使用线程池？ 1234for (int i = 0; i &lt; 10000; i++) &#123; Thread thread = new Thread(new Task()); thread.start();&#125; 如代码所示，我们创建了 10000 个子线程，而 Java 程序中的线程与操作系统中的线程是一一对应的，此时假设线程中的任务需要一定的耗时才能够完成，便会产生很大的系统开销与资源浪费。 创建线程时会产生系统开销，并且每个线程还会占用一定的内存等资源，更重要的是我们创建如此多的线程也会给稳定性带来危害，因为每个系统中，可创建线程的数量是有一个上限的，不可能无限的创建。线程执行完需要被回收，大量的线程又会给垃圾回收带来压力。但我们的任务确实非常多，如果都在主线程串行执行，那效率也太低了，那应该怎么办呢？于是便诞生了线程池来平衡线程与系统资源之间的关系。 如果每个任务都创建一个线程会带来的问题： 第一点，反复创建线程系统开销比较大，每个线程创建和销毁都需要时间，如果任务比较简单，那么就有可能导致创建和销毁线程消耗的资源比线程执行任务本身消耗的资源还要大。 第二点，过多的线程会占用过多的内存等资源，还会带来过多的上下文切换，同时还会导致系统不稳定。 线程池解决问题思路 针对上面的两点问题，线程池有两个解决思路： 首先，针对反复创建线程开销大的问题，线程池用一些固定的线程一直保持工作状态并反复执行任务。 其次，针对过多线程占用太多内存资源的问题，解决思路更直接，线程池会根据需要创建线程，控制线程的总数量，避免占用过多内存资源。 如何使用线程池 1234567891011121314151617181920/** * 描述： 用固定线程数的线程池执行10000个任务 */ public class ThreadPoolDemo &#123; public static void main(String[] args) &#123; ExecutorService service = Executors.newFixedThreadPool(5); for (int i = 0; i &lt; 10000; i++) &#123; service.execute(new Task()); &#125; System.out.println(Thread.currentThread().getName()); &#125; static class Task implements Runnable &#123; public void run() &#123; System.out.println(\"Thread Name: \" + Thread.currentThread().getName()); &#125; &#125; &#125; 执行效果： 123456789101112131415Thread Name: pool-1-thread-1Thread Name: pool-1-thread-2Thread Name: pool-1-thread-3Thread Name: pool-1-thread-4Thread Name: pool-1-thread-5Thread Name: pool-1-thread-5Thread Name: pool-1-thread-5Thread Name: pool-1-thread-5Thread Name: pool-1-thread-5Thread Name: pool-1-thread-2Thread Name: pool-1-thread-1Thread Name: pool-1-thread-5Thread Name: pool-1-thread-3Thread Name: pool-1-thread-5... 如打印结果所示，打印的线程名始终在 Thread Name: pool-1-thread-1~5 之间变化，并没有超过这个范围，也就证明了线程池不会无限制地扩张线程的数量，始终是这5个线程在工作。 执行流程如图所示，首先创建了一个线程池，线程池中有 5 个线程，然后线程池将 10000 个任务分配给这 5 个线程，这 5 个线程反复领取任务并执行，直到所有任务执行完毕，这就是线程池的思想。 使用线程池的好处 第一点，线程池可以解决线程生命周期的系统开销问题，同时还可以加快响应速度。因为线程池中的线程是可以复用的，我们只用少量的线程去执行大量的任务，这就大大减小了线程生命周期的开销。而且线程通常不是等接到任务后再临时创建，而是已经创建好时刻准备执行任务，这样就消除了线程创建所带来的延迟，提升了响应速度，增强了用户体验。 第二点，线程池可以统筹内存和 CPU 的使用，避免资源使用不当。线程池会根据配置和任务数量灵活地控制线程数量，不够的时候就创建，太多的时候就回收，避免线程过多导致内存溢出，或线程太少导致 CPU 资源浪费，达到了一个完美的平衡。 第三点，线程池可以统一管理资源。比如线程池可以统一管理任务队列和线程，可以统一开始或结束任务，比单个线程逐一处理任务要更方便、更易于管理，同时也有利于数据统计，比如我们可以很方便地统计出已经执行过的任务的数量。 2.线程池的各个参数的含义线程池的参数 线程创建的时机 如上图所示，当提交任务后，线程池首先会检查当前线程数，如果此时线程数小于核心线程数，比如最开始线程数量为 0，则新建线程并执行任务，随着任务的不断增加，线程数会逐渐增加并达到核心线程数，此时如果仍有任务被不断提交，就会被放入 workQueue 任务队列中，等待核心线程执行完当前任务后重新从 workQueue 中提取正在等待被执行的任务。 此时，假设我们的任务特别的多，已经达到了 workQueue 的容量上限，这时线程池就会启动后备力量，也就是 maximumPoolSize 最大线程数，线程池会在 corePoolSize 核心线程数的基础上继续创建线程来执行任务，假设任务被不断提交，线程池会持续创建线程直到线程数达到 maximumPoolSize 最大线程数，如果依然有任务被提交，这就超过了线程池的最大处理能力，这个时候线程池就会拒绝这些任务，我们可以看到实际上任务进来之后，线程池会逐一判断 corePoolSize、workQueue、maximumPoolSize，如果依然不能满足需求，则会拒绝任务。 corePoolSize 与 maximumPoolSize corePoolSize 指的是核心线程数，线程池初始化时线程数默认为 0，当有新的任务提交后，会创建新线程执行任务，如果不做特殊设置，此后线程数通常不会再小于 corePoolSize ，因为它们是核心线程，即便未来可能没有可执行的任务也不会被销毁。随着任务量的增加，在任务队列满了之后，线程池会进一步创建新线程，最多可以达到 maximumPoolSize 来应对任务多的场景，如果未来线程有空闲，大于 corePoolSize 的线程会被合理回收。所以正常情况下，线程池中的线程数量会处在 corePoolSize 与 maximumPoolSize 的闭区间内。 “长工”与“临时工” 我们可以把 corePoolSize 与 maximumPoolSize 比喻成长工与临时工，通常古代一个大户人家会有几个固定的长工，负责日常的工作，而大户人家起初肯定也是从零开始雇佣长工的。假如长工数量被老爷设定为 5 人，也就对应了 corePoolSize，不管这 5 个长工是忙碌还是空闲，都会一直在大户人家待着，可到了农忙或春节，长工的人手显然就不够用了，这时就需要雇佣更多的临时工，这些临时工就相当于在 corePoolSize 的基础上继续创建新线程，但临时工也是有上限的，也就对应了 maximumPoolSize，随着农忙或春节结束，老爷考虑到人工成本便会解约掉这些临时工，家里工人数量便会从 maximumPoolSize 降到 corePoolSize，所以老爷家的工人数量会一致保持在 corePoolSize 和 maximumPoolSize 的区间。 总结线程池的几个特点： 线程池希望保持较少的线程数，并且只有在负载变得很大时才增加线程。 线程池只有在任务队列填满时才创建多于 corePoolSize 的线程，如果使用的是无界队列（例如 LinkedBlockingQueue），那么由于队列不会满，所以线程数不会超过 corePoolSize。 通过设置 corePoolSize 和 maximumPoolSize 为相同的值，就可以创建固定大小的线程池。 通过设置 maximumPoolSize 为很高的值，例如 Integer.MAX_VALUE，就可以允许线程池创建任意多的线程。 keepAliveTime+时间单位 第三个参数是 keepAliveTime + 时间单位，当线程池中线程数量多于核心线程数时，而此时又没有任务可做，线程池就会检测线程的 keepAliveTime，如果超过规定的时间，无事可做的线程就会被销毁，以便减少内存的占用和资源消耗。如果后期任务又多了起来，线程池也会根据规则重新创建线程，所以这是一个可伸缩的过程，比较灵活，我们也可以用 setKeepAliveTime 方法动态改变 keepAliveTime 的参数值。 ThreadFactory 第四个参数是 ThreadFactory，ThreadFactory 实际上是一个线程工厂，它的作用是生产线程以便执行任务。我们可以选择使用默认的线程工厂，创建的线程都会在同一个线程组，并拥有一样的优先级，且都不是守护线程，我们也可以选择自己定制线程工厂，以方便给线程自定义命名，不同的线程池内的线程通常会根据具体业务来定制不同的线程名。 workQueue 和 Handler 最后两个参数是 workQueue 和 Handler，它们分别对应阻塞队列和任务拒绝策略。 3.线程池有哪 4 种拒绝策略？拒绝时机 新建线程池时可以指定它的任务拒绝策略，例如： 12newThreadPoolExecutor(5, 10, 5, TimeUnit.SECONDS, new LinkedBlockingQueue&lt;&gt;(), new ThreadPoolExecutor.DiscardOldestPolicy()); 以便在必要的时候按照我们的策略来拒绝任务，那么拒绝任务的时机是什么呢？线程池会在以下两种情况下会拒绝新提交的任务： 第一种情况是当我们调用 shutdown 等方法关闭线程池后，即便此时可能线程池内部依然有没执行完的任务正在执行，但是由于线程池已经关闭，此时如果再向线程池内提交任务，就会遭到拒绝。 第二种情况是线程池没有能力继续处理新提交的任务，也就是工作已经非常饱和的时候。 第二种情况，比如新建一个线程池，使用容量上限为 10 的 ArrayBlockingQueue 作为任务队列，并且指定线程池的核心线程数为 5，最大线程数为 10，假设此时有 20 个耗时任务被提交，在这种情况下，线程池会首先创建核心数量的线程，也就是5个线程来执行任务，然后往队列里去放任务，队列的 10 个容量被放满了之后，会继续创建新线程，直到达到最大线程数 10。此时线程池中一共有 20 个任务，其中 10 个任务正在被 10 个线程执行，还有 10 个任务在任务队列中等待，而且由于线程池的最大线程数量就是 10，所以已经不能再增加更多的线程来帮忙处理任务了，这就意味着此时线程池工作饱和，这个时候再提交新任务时就会被拒绝。 拒绝策略 Java 在 ThreadPoolExecutor 类中为我们提供了 4 种默认的拒绝策略来应对不同的场景，都实现了 RejectedExecutionHandler 接口，如图所示： 第一种拒绝策略是 AbortPolicy，这种拒绝策略在拒绝任务时，会直接抛出一个类型为 RejectedExecutionException 的 RuntimeException，让你感知到任务被拒绝了，于是你便可以根据业务逻辑选择重试或者放弃提交等策略。 第二种拒绝策略是 DiscardPolicy，这种拒绝策略正如它的名字所描述的一样，当新任务被提交后直接被丢弃掉，也不会给你任何的通知，相对而言存在一定的风险，因为我们提交的时候根本不知道这个任务会被丢弃，可能造成数据丢失。 第三种拒绝策略是 DiscardOldestPolicy，如果线程池没被关闭且没有能力执行，则会丢弃任务队列中的头结点，通常是存活时间最长的任务，这种策略与第二种不同之处在于它丢弃的不是最新提交的，而是队列中存活时间最长的，这样就可以腾出空间给新提交的任务，但同理它也存在一定的数据丢失风险。 第四种拒绝策略是 CallerRunsPolicy，相对而言它就比较完善了，当有新任务提交后，如果线程池没被关闭且没有能力执行，则把这个任务交于提交任务的线程执行，也就是谁提交任务，谁就负责执行任务。这样做主要有两点好处。 第一点新提交的任务不会被丢弃，这样也就不会造成业务损失。 第二点好处是，由于谁提交任务谁就要负责执行任务，这样提交任务的线程就得负责执行任务，而执行任务又是比较耗时的，在这段期间，提交任务的线程被占用，也就不会再提交新的任务，减缓了任务提交的速度，相当于是一个负反馈。在此期间，线程池中的线程也可以充分利用这段时间来执行掉一部分任务，腾出一定的空间，相当于是给了线程池一定的缓冲期。 4.有哪 6 种常见的线程池？什么是 Java7 的 ForkJoinPool？6种常见线程池如下： FixedThreadPool CachedThreadPool ScheduledThreadPool SingleThreadExecutor SingleThreadScheduledExecutor ForkJoinPool FixedThreadPool FixedThreadPool的核心线程数和最大线程数是一样的，所以可以把它看作是固定线程数的线程池，它的特点是线程池中的线程数除了初始阶段需要从 0 开始增加外，之后的线程数量就是固定的，就算任务数超过线程数，线程池也不会再创建更多的线程来处理任务，而是会把超出线程处理能力的任务放到任务队列中进行等待。而且就算任务队列满了，到了本该继续增加线程数的时候，由于它的最大线程数和核心线程数是一样的，所以也无法再增加新的线程了。 CachedThreadPool CachedThreadPool可以称作可缓存线程池，它的特点在于线程数是几乎可以无限增加的（实际最大可以达到 Integer.MAX_VALUE，为 2^31-1，这个数非常大，所以基本不可能达到），而当线程闲置时还可以对线程进行回收。也就是说该线程池的线程数量不是固定不变的，当然它也有一个用于存储提交任务的队列，但这个队列是 SynchronousQueue，队列的容量为0，实际不存储任何任务，它只负责对任务进行中转和传递，所以效率比较高。 当我们提交一个任务后，线程池会判断已创建的线程中是否有空闲线程，如果有空闲线程则将任务直接指派给空闲线程，如果没有空闲线程，则新建线程去执行任务，这样就做到了动态地新增线程。当任务执行完之后，假设没有新的任务了，那么大量的闲置线程又会造成内存资源的浪费，这时线程池就会检测线程在 60 秒内有没有可执行任务，如果没有就会被销毁，最终线程数量会减为 0。 ScheduledThreadPool ScheduledThreadPool支持定时或周期性执行任务。比如每隔 10 秒钟执行一次任务，而实现这种功能的方法主要有 3 种，如代码所示： 1234567ScheduledExecutorService service = Executors.newScheduledThreadPool(10); service.schedule(new Task(), 10, TimeUnit.SECONDS); service.scheduleAtFixedRate(new Task(), 10, 10, TimeUnit.SECONDS); service.scheduleWithFixedDelay(new Task(), 10, 10, TimeUnit.SECONDS); 3 种方法的区别： 第一种方法 schedule 比较简单，表示延迟指定时间后执行一次任务，如果代码中设置参数为 10 秒，也就是 10 秒后执行一次任务后就结束。 第二种方法 scheduleAtFixedRate 表示以固定的频率执行任务，它的第二个参数 initialDelay 表示第一次延时时间，第三个参数 period 表示周期，也就是第一次延时后每次延时多长时间执行一次任务。 第三种方法 scheduleWithFixedDelay 与第二种方法类似，也是周期执行任务，区别在于对周期的定义，之前的 scheduleAtFixedRate 是以任务开始的时间为时间起点开始计时，时间到就开始执行第二次任务，而不管任务需要花多久执行；而 scheduleWithFixedDelay 方法以任务结束的时间为下一次循环的时间起点开始计时。 SingleThreadExecutor SingleThreadExecutor会使用唯一的线程去执行任务，原理和 FixedThreadPool 是一样的，只不过这里线程只有一个，如果线程在执行任务的过程中发生异常，线程池也会重新创建一个线程来执行后续的任务。这种线程池由于只有一个线程，所以非常适合用于所有任务都需要按被提交的顺序依次执行的场景，而前几种线程池不一定能够保障任务的执行顺序等于被提交的顺序，因为它们是多线程并行执行的。 SingleThreadScheduledExecutor SingleThreadScheduledExecutor和第三种 ScheduledThreadPool 线程池非常相似，它只是 ScheduledThreadPool 的一个特例，内部只有一个线程，如源码所示： 1new ScheduledThreadPoolExecutor(1) 它只是将 ScheduledThreadPool 的核心线程数设置为了 1。 几种线程池的各参数： ForkJoinPool ForkJoinPool是在 JDK 7 加入的，ForkJoinPool 线程池和之前的线程池有两点非常大的不同之处。第一点是它非常适合执行可以产生子任务的任务。 如图所示，我们有一个 Task，这个 Task 可以产生三个子任务，三个子任务并行执行完毕后将结果汇总给 Result，比如说主任务需要执行非常繁重的计算任务，我们就可以把计算拆分成三个部分，这三个部分是互不影响相互独立的，这样就可以利用 CPU 的多核优势，并行计算，然后将结果进行汇总。这里面主要涉及两个步骤，第一步是拆分也就是 Fork，第二步是汇总也就是 Join，这也是 ForkJoinPool 线程池名字的由来。 举个例子，比如面试中经常考到的菲波那切数列，这个数列的特点就是后一项的结果等于前两项的和，第 0 项是 0，第 1 项是 1，那么第 2 项就是 0+1=1，以此类推。我们在写代码时应该首选效率更高的迭代形式或者更高级的乘方或者矩阵公式法等写法，不过假设我们写成了最初版本的递归形式，伪代码如下所示： 12345678910if (n &lt;= 1) &#123; return n; &#125; else &#123; Fib f1 = new Fib(n - 1); Fib f2 = new Fib(n - 2); f1.solve(); f2.solve(); number = f1.number + f2.number; return number; &#125; 可以看到如果 n&lt;=1 则直接返回 n，如果 n&gt;1 ，先将前一项 f1 的值计算出来，然后往前推两项求出 f2 的值，然后将两值相加得到结果，所以我们看到在求和运算中产生了两个子任务。计算 f(4) 的流程如下图所示： 在计算 f(4) 时需要首先计算出 f(2) 和 f(3)，而同理，计算 f(3) 时又需要计算 f(1) 和 f(2)，以此类推。 这是典型的递归问题，对应到我们的 ForkJoin 模式，如图所示，子任务同样会产生子子任务，最后再逐层汇总，得到最终的结果。 ForkJoinPool 线程池有多种方法可以实现任务的分裂和汇总，其中一种用法如下方代码所示： 1234567891011121314151617181920class Fibonacci extends RecursiveTask&lt;Integer&gt; &#123; int n; public Fibonacci(int n) &#123; this.n = n; &#125; @Override public Integer compute() &#123; if (n &lt;= 1) &#123; return n; &#125; Fibonacci f1 = new Fibonacci(n - 1); f1.fork(); Fibonacci f2 = new Fibonacci(n - 2); f2.fork(); return f1.join() + f2.join(); &#125; &#125; Fibonacci首先继承了 RecursiveTask，RecursiveTask 类是对ForkJoinTask 的一个简单的包装，这时我们重写 compute() 方法，当 n&lt;=1 时直接返回，当 n&gt;1 就创建递归任务，也就是 f1 和 f2，然后我们用 fork() 方法分裂任务并分别执行，最后在 return 的时候，使用 join() 方法把结果汇总，这样就实现了任务的分裂和汇总。 1234567public static void main(String[] args) throws ExecutionException, InterruptedException &#123; ForkJoinPool forkJoinPool = new ForkJoinPool(); for (int i = 0; i &lt; 10; i++) &#123; ForkJoinTask task = forkJoinPool.submit(new Fibonacci(i)); System.out.println(task.get()); &#125; &#125; 上面这段代码将会打印出斐波那契数列的第 0 到 9 项的值： 123456789100112358132134 和线程池的第二点不同之处在于内部结构，之前的线程池所有的线程共用一个队列，但 ForkJoinPool 线程池中每个线程都有自己独立的任务队列，如图所示： ForkJoinPool 线程池内部除了有一个共用的任务队列之外，每个线程还有一个对应的双端队列 deque，这时一旦线程中的任务被 Fork 分裂了，分裂出来的子任务放入线程自己的 deque 里，而不是放入公共的任务队列中。如果此时有三个子任务放入线程 t1 的 deque 队列中，对于线程 t1 而言获取任务的成本就降低了，可以直接在自己的任务队列中获取而不必去公共队列中争抢也不会发生阻塞（除了后面会讲到的 steal 情况外），减少了线程间的竞争和切换，是非常高效的。 再考虑一种情况，此时线程有多个，而线程 t1 的任务特别繁重，分裂了数十个子任务，但是 t0 此时却无事可做，它自己的 deque 队列为空，这时为了提高效率，t0 就会想办法帮助 t1 执行任务，这就是“work-stealing”（工作窃取）的含义。 双端队列 deque 中，线程 t1 获取任务的逻辑是后进先出，也就是LIFO（Last In Frist Out），而线程 t0 在“steal”偷线程 t1 的 deque 中的任务的逻辑是先进先出，也就是FIFO（Fast In Frist Out），如图所示，图中很好的描述了两个线程使用双端队列分别获取任务的情景。你可以看到，使用 “work-stealing” 算法和双端队列很好地平衡了各线程的负载。 最后，我们用一张全景图来描述 ForkJoinPool 线程池的内部结构，你可以看到 ForkJoinPool 线程池和其他线程池很多地方都是一样的，但重点区别在于它每个线程都有一个自己的双端队列来存储分裂出来的子任务。ForkJoinPool 非常适合用于递归的场景，例如树的遍历、最优路径搜索等场景。 5.线程池常用的阻塞队列有哪些？线程池内部结构 线程池的内部结构主要由四部分组成，如图所示： 第一部分是线程池管理器，它主要负责管理线程池的创建、销毁、添加任务等管理操作，它是整个线程池的管家。 第二部分是工作线程，也就是图中的线程 t0~t9，这些线程勤勤恳恳地从任务队列中获取任务并执行。 第三部分是任务队列，作为一种缓冲机制，线程池会把当下没有处理的任务放入任务队列中，由于多线程同时从任务队列中获取任务是并发场景，此时就需要任务队列满足线程安全的要求，所以线程池中任务队列采用 BlockingQueue 来保障线程安全。 第四部分是任务，任务要求实现统一的接口，以便工作线程可以处理和执行。 阻塞队列 不同的线程池会选用不同的阻塞队列，常见的5 种线程池对应了 3 种阻塞队列。 LinkedBlockingQueue 对于 FixedThreadPool 和 SingleThreadExector 而言，它们使用的阻塞队列是容量为Integer.MAX_VALUE 的 LinkedBlockingQueue，可以认为是无界队列。由于 FixedThreadPool线程池的线程数是固定的，所以没有办法增加特别多的线程来处理任务，这时就需要 LinkedBlockingQueue 这样一个没有容量限制的阻塞队列来存放任务。这里需要注意，由于线程池的任务队列永远不会放满，所以线程池只会创建核心线程数量的线程，所以此时的最大线程数对线程池来说没有意义，因为并不会触发生成多于核心线程数的线程。 SynchronousQueue 第二种阻塞队列是 SynchronousQueue，对应的线程池是 CachedThreadPool。线程池 CachedThreadPool 的最大线程数是 Integer 的最大值，可以理解为线程数是可以无限扩展的。CachedThreadPool 和上一种线程池 FixedThreadPool 的情况恰恰相反，FixedThreadPool 的情况是阻塞队列的容量是无限的，而这里 CachedThreadPool 是线程数可以无限扩展，所以 CachedThreadPool 线程池并不需要一个任务队列来存储任务，因为一旦有任务被提交就直接转发给线程或者创建新线程来执行，而不需要另外保存它们。 我们自己创建使用 SynchronousQueue 的线程池时，如果不希望任务被拒绝，那么就需要注意设置最大线程数要尽可能大一些，以免发生任务数大于最大线程数时，没办法把任务放到队列中也没有足够线程来执行任务的情况。 DelayedWorkQueue 第三种阻塞队列是DelayedWorkQueue，它对应的线程池分别是 ScheduledThreadPool 和 SingleThreadScheduledExecutor，这两种线程池的最大特点就是可以延迟执行任务，比如说一定时间后执行任务或是每隔一定的时间执行一次任务。DelayedWorkQueue 的特点是内部元素并不是按照放入的时间排序，而是会按照延迟的时间长短对任务进行排序，内部采用的是“堆”的数据结构。之所以线程池 ScheduledThreadPool 和 SingleThreadScheduledExecutor 选择 DelayedWorkQueue，是因为它们本身正是基于时间执行任务的，而延迟队列正好可以把任务按时间进行排序，方便任务的执行。 6.为什么不应该自动创建线程池？所谓的自动创建线程池就是直接调用 Executors 的各种方法来生成前面学过的常见的线程池，例如 Executors.newCachedThreadPool()。但这样做是有一定风险的。 FixedThreadPool 首先我们来看第一种线程池 FixedThreadPool， 它是线程数量固定的线程池，如源码所示，newFixedThreadPool 内部实际还是调用了 ThreadPoolExecutor 构造函数。 123public static ExecutorService newFixedThreadPool(int nThreads) &#123; return new ThreadPoolExecutor(nThreads, nThreads,0L, TimeUnit.MILLISECONDS,new LinkedBlockingQueue&lt;Runnable&gt;());&#125; 通过往构造函数中传参，创建了一个核心线程数和最大线程数相等的线程池，它们的数量也就是我们传入的参数，这里的重点是使用的队列是容量没有上限的 LinkedBlockingQueue，如果我们对任务的处理速度比较慢，那么随着请求的增多，队列中堆积的任务也会越来越多，最终大量堆积的任务会占用大量内存，并发生 OOM ，也就是OutOfMemoryError，这几乎会影响到整个程序，会造成很严重的后果。 SingleThreadExecutor 第二种线程池是 SingleThreadExecutor，我们来分析下创建它的源码。 123public static ExecutorService newSingleThreadExecutor() &#123; return new FinalizableDelegatedExecutorService (new ThreadPoolExecutor(1, 1,0L, TimeUnit.MILLISECONDS,new LinkedBlockingQueue&lt;Runnable&gt;()));&#125; 可以看出，newSingleThreadExecutor 和 newFixedThreadPool 的原理是一样的，只不过把核心线程数和最大线程数都直接设置成了 1，但是任务队列仍是无界的 LinkedBlockingQueue，所以也会导致同样的问题，也就是当任务堆积时，可能会占用大量的内存并导致 OOM。 CachedThreadPool 第三种线程池是 CachedThreadPool，创建它的源码下所示。 123public static ExecutorService newCachedThreadPool() &#123; return new ThreadPoolExecutor(0, Integer.MAX_VALUE,60L, TimeUnit.SECONDS,new SynchronousQueue&lt;Runnable&gt;());&#125; 这里的 CachedThreadPool 和前面两种线程池不一样的地方在于任务队列使用的是 SynchronousQueue，SynchronousQueue 本身并不存储任务，而是对任务直接进行转发，这本身是没有问题的，但你会发现构造函数的第二个参数被设置成了 Integer.MAX_VALUE，这个参数的含义是最大线程数，所以由于 CachedThreadPool 并不限制线程的数量，当任务数量特别多的时候，就可能会导致创建非常多的线程，最终超过了操作系统的上限而无法创建新线程，或者导致内存不足。 ScheduledThreadPool 和 SingleThreadScheduledExecutor 第四种线程池 ScheduledThreadPool 和第五种线程池 SingleThreadScheduledExecutor 的原理是一样的，创建 ScheduledThreadPool 的源码如下所示。 123public static ScheduledExecutorService newScheduledThreadPool(int corePoolSize) &#123; return new ScheduledThreadPoolExecutor(corePoolSize);&#125; 而这里的 ScheduledThreadPoolExecutor 是 ThreadPoolExecutor 的子类，调用的它的构造方法如下所示。 123public ScheduledThreadPoolExecutor(int corePoolSize) &#123; super(corePoolSize, Integer.MAX_VALUE, 0, NANOSECONDS,new DelayedWorkQueue());&#125; 我们通过源码可以看出，它采用的任务队列是 DelayedWorkQueue，这是一个延迟队列，同时也是一个无界队列，所以和 LinkedBlockingQueue 一样，如果队列中存放过多的任务，就可能导致 OOM。 可以看到，这几种自动创建的线程池都存在风险，相比较而言，我们自己手动创建会更好，因为我们可以更加明确线程池的运行规则，不仅可以选择适合自己的线程数量，更可以在必要的时候拒绝新任务的提交，避免资源耗尽的风险。 7.合适的线程数量是多少？CPU 核心数和线程数的关系？我们调整线程池中的线程数量的最主要的目的是为了充分并合理地使用 CPU 和内存等资源，从而最大限度地提高程序的性能。在实际工作中，我们需要根据任务类型的不同选择对应的策略。 CPU 密集型任务 首先，我们来看 CPU 密集型任务，比如加密、解密、压缩、计算等一系列需要大量耗费 CPU 资源的任务。对于这样的任务最佳的线程数为 CPU 核心数的 1~2 倍，如果设置过多的线程数，实际上并不会起到很好的效果。此时假设我们设置的线程数量是 CPU 核心数的 2 倍以上，因为计算任务非常重，会占用大量的 CPU 资源，所以这时 CPU 的每个核心工作基本都是满负荷的，而我们又设置了过多的线程，每个线程都想去利用 CPU 资源来执行自己的任务，这就会造成不必要的上下文切换，此时线程数的增多并没有让性能提升，反而由于线程数量过多会导致性能下降。 针对这种情况，我们最好还要同时考虑在同一台机器上还有哪些其他会占用过多 CPU 资源的程序在运行，然后对资源使用做整体的平衡。 耗时 IO 型任务 第二种任务是耗时 IO 型，比如数据库、文件的读写，网络通信等任务，这种任务的特点是并不会特别消耗 CPU 资源，但是 IO 操作很耗时，总体会占用比较多的时间。对于这种任务最大线程数一般会大于 CPU 核心数很多倍，因为 IO 读写速度相比于 CPU 的速度而言是比较慢的，如果我们设置过少的线程数，就可能导致 CPU 资源的浪费。而如果我们设置更多的线程数，那么当一部分线程正在等待 IO 的时候，它们此时并不需要 CPU 来计算，那么另外的线程便可以利用 CPU 去执行其他的任务，互不影响，这样的话在任务队列中等待的任务就会减少，可以更好地利用资源。 《Java并发编程实战》的作者 Brain Goetz 推荐的计算方法： 1线程数 &#x3D; CPU 核心数 *（1+平均等待时间&#x2F;平均工作时间） 通过这个公式，我们可以计算出一个合理的线程数量，如果任务的平均等待时间长，线程数就随之增加，而如果平均工作时间长，也就是对于我们上面的 CPU 密集型任务，线程数就随之减少。 太少的线程数会使得程序整体性能降低，而过多的线程也会消耗内存等其他资源，所以如果想要更准确的话，可以进行压测，监控 JVM 的线程情况以及 CPU 的负载情况，根据实际情况衡量应该创建的线程数，合理并充分利用资源。 结论 线程的平均工作时间所占比例越高，就需要越少的线程； 线程的平均等待时间所占比例越高，就需要越多的线程； 针对不同的程序，进行对应的实际测试就可以得到最合适的选择。 8.如何根据实际需要，定制自己的线程池？核心线程数 合理的线程数量和任务类型，以及 CPU 核心数都有关系，基本结论是线程的平均工作时间所占比例越高，就需要越少的线程；线程的平均等待时间所占比例越高，就需要越多的线程。而对于最大线程数而言，如果我们执行的任务类型不是固定的，比如可能一段时间是 CPU 密集型，另一段时间是 IO 密集型，或是同时有两种任务相互混搭。那么在这种情况下，我们可以把最大线程数设置成核心线程数的几倍，以便应对任务突发情况。当然更好的办法是用不同的线程池执行不同类型的任务，让任务按照类型区分开，而不是混杂在一起。 阻塞队列 对于阻塞队列这个参数而言，我们可以选择之前介绍过的 LinkedBlockingQueue 或者 SynchronousQueue 或者 DelayedWorkQueue，不过还有一种常用的阻塞队列叫 ArrayBlockingQueue，它也经常被用于线程池中，这种阻塞队列内部是用数组实现的，在新建对象的时候要求传入容量值，且后期不能扩容，所以 ArrayBlockingQueue 的最大的特点就是容量是有限的。这样一来，如果任务队列放满了任务，而且线程数也已经达到了最大值，线程池根据规则就会拒绝新提交的任务，这样一来就可能会产生一定的数据丢失。 但相比于无限增加任务或者线程数导致内存不足，进而导致程序崩溃，数据丢失还是要更好一些的，如果我们使用了 ArrayBlockingQueue 这种阻塞队列，再加上我们限制了最大线程数量，就可以非常有效地防止资源耗尽的情况发生。此时的队列容量大小和 maxPoolSize 是一个 trade-off，如果我们使用容量更大的队列和更小的最大线程数，就可以减少上下文切换带来的开销，但也可能因此降低整体的吞吐量；如果我们的任务是 IO 密集型，则可以选择稍小容量的队列和更大的最大线程数，这样整体的效率就会更高，不过也会带来更多的上下文切换。 线程工厂 对于线程工厂 threadFactory 这个参数，我们可以使用默认的 defaultThreadFactory，也可以传入自定义的有额外能力的线程工厂，因为我们可能有多个线程池，而不同的线程池之间有必要通过不同的名字来进行区分，所以可以传入能根据业务信息进行命名的线程工厂，以便后续可以根据线程名区分不同的业务进而快速定位问题代码。比如可以通过com.google.common.util.concurrent.ThreadFactoryBuilder 来实现，如代码所示。 12ThreadFactoryBuilder builder = new ThreadFactoryBuilder();ThreadFactory rpcFactory = builder.setNameFormat(\"rpc-pool-%d\").build(); 我们生成了名字为 rpcFactory 的 ThreadFactory，它的 nameFormat 为 “rpc-pool-%d” ，那么它生成的线程的名字是有固定格式的，它生成的线程的名字分别为”rpc-pool-1”，”rpc-pool-2” ，以此类推。 拒绝策略 最后一个参数是拒绝策略，我们可以根据业务需要四种拒绝策略之一来使用：AbortPolicy，DiscardPolicy，DiscardOldestPolicy 或者 CallerRunsPolicy。除此之外，我们还可以通过实现 RejectedExecutionHandler 接口来实现自己的拒绝策略，在接口中我们需要实现 rejectedExecution 方法，在 rejectedExecution 方法中，执行例如打印日志、暂存任务、重新执行等自定义的拒绝策略，以便满足业务需求。如代码所示。 123456private static class CustomRejectionHandler implements RejectedExecutionHandler &#123; @Override public void rejectedExecution(Runnable r, ThreadPoolExecutor executor) &#123; //打印日志、暂存任务、重新执行等拒绝策略 &#125; &#125; 总结 所以定制自己的线程池和我们的业务是强相关的，首先我们需要掌握每个参数的含义，以及常见的选项，然后根据实际需要，比如说并发量、内存大小、是否接受任务被拒绝等一系列因素去定制一个非常适合自己业务的线程池，这样既不会导致内存不足，同时又可以用合适数量的线程来保障任务执行的效率，并在拒绝任务时有所记录方便日后进行追溯。 9.如何正确关闭线程池？shutdown 和 shutdownNow 的区别？5 种在 ThreadPoolExecutor 中涉及关闭线程池的方法： void shutdown; boolean isShutdown; boolean isTerminated; boolean awaitTermination(long timeout, TimeUnit unit) throws InterruptedException; List shutdownNow; shutdown() 第一种方法叫作 shutdown()，它可以安全地关闭一个线程池，调用 shutdown() 方法之后线程池并不是立刻就被关闭，因为这时线程池中可能还有很多任务正在被执行，或是任务队列中有大量正在等待被执行的任务，调用 shutdown() 方法后线程池会在执行完正在执行的任务和队列中等待的任务后才彻底关闭。但这并不代表 shutdown() 操作是没有任何效果的，调用 shutdown() 方法后如果还有新的任务被提交，线程池则会根据拒绝策略直接拒绝后续新提交的任务。 isShutdown() 第二个方法叫作 isShutdown()，它可以返回 true 或者 false 来判断线程池是否已经开始了关闭工作，也就是是否执行了 shutdown 或者 shutdownNow 方法。这里需要注意，如果调用 isShutdown() 方法的返回的结果为 true 并不代表线程池此时已经彻底关闭了，这仅仅代表线程池开始了关闭的流程，也就是说，此时可能线程池中依然有线程在执行任务，队列里也可能有等待被执行的任务。 isTerminated() 第三种方法叫作 isTerminated()，这个方法可以检测线程池是否真正“终结”了，这不仅代表线程池已关闭，同时代表线程池中的所有任务都已经都执行完毕了。 awaitTermination() 第四个方法叫作 awaitTermination()，它本身并不是用来关闭线程池的，而是主要用来判断线程池状态的。比如我们给 awaitTermination 方法传入的参数是 10 秒，那么它就会陷入 10 秒钟的等待，直到发生以下三种情况之一： 等待期间（包括进入等待状态之前）线程池已关闭并且所有已提交的任务（包括正在执行的和队列中等待的）都执行完毕，相当于线程池已经“终结”了，方法便会返回 true； 等待超时时间到后，第一种线程池“终结”的情况始终未发生，方法返回 false； 等待期间线程被中断，方法会抛出 InterruptedException 异常。 也就是说，调用 awaitTermination 方法后当前线程会尝试等待一段指定的时间，如果在等待时间内，线程池已关闭并且内部的任务都执行完毕了，也就是说线程池真正“终结”了，那么方法就返回 true，否则超时返回 fasle。 我们则可以根据 awaitTermination() 返回的布尔值来判断下一步应该执行的操作。 shutdownNow() 最后一个方法是 shutdownNow()，也是 5 种方法里功能最强大的，它与第一种 shutdown 方法不同之处在于名字中多了一个单词 Now，也就是表示立刻关闭的意思。在执行 shutdownNow 方法之后，首先会给所有线程池中的线程发送 interrupt 中断信号，尝试中断这些任务的执行，然后会将任务队列中正在等待的所有任务转移到一个 List 中并返回，我们可以根据返回的任务 List 来进行一些补救的操作，例如记录在案并在后期重试。shutdownNow() 的源码如下所示。 12345678910111213141516public List&lt;Runnable&gt; shutdownNow() &#123; List&lt;Runnable&gt; tasks; final ReentrantLock mainLock = this.mainLock; mainLock.lock(); try &#123; checkShutdownAccess(); advanceRunState(STOP); interruptWorkers(); tasks = drainQueue(); &#125; finally &#123; mainLock.unlock(); &#125; tryTerminate(); return tasks; &#125; 可以看到源码中有一行 interruptWorkers() 代码，这行代码会让每一个已经启动的线程都中断，这样线程就可以在执行任务期间检测到中断信号并进行相应的处理，提前结束任务。这里需要注意的是，由于 Java 中不推荐强行停止线程的机制的限制，即便我们调用了 shutdownNow 方法，如果被中断的线程对于中断信号不理不睬，那么依然有可能导致任务不会停止。可见我们在开发中落地最佳实践是很重要的，我们自己编写的线程应当具有响应中断信号的能力，应当利用中断信号来协同工作。 10.线程池实现“线程复用”的原理？线程复用原理 线程池可以把线程和任务进行解耦，线程归线程，任务归任务，摆脱了之前通过 Thread 创建线程时的一个线程必须对应一个任务的限制。在线程池中，同一个线程可以从 BlockingQueue 中不断提取新任务来执行，其核心原理在于线程池对 Thread 进行了封装，并不是每次执行任务都会调用 Thread.start() 来创建新线程，而是让每个线程去执行一个“循环任务”，在这个“循环任务”中，不停地检查是否还有任务等待被执行，如果有则直接去执行这个任务，也就是调用任务的 run 方法，把 run 方法当作和普通方法一样的地位去调用，相当于把每个任务的 run() 方法串联了起来，所以线程数量并不增加。 线程复用源码解析 线程复用的逻辑实现主要在 Worker 类中的 run 方法里执行的 runWorker 方法中，简化后的 runWorker 方法代码如下所示： 12345678910final void runWorker(Worker w) &#123; Runnable task = w.firstTask; while (task != null || (task = getTask()) != null) &#123; try &#123; task.run(); &#125; finally &#123; task = null; &#125; &#125;&#125; 可以看出，实现线程复用的逻辑主要在一个不停循环的 while 循环体中。 通过取 Worker 的 firstTask 或者通过 getTask 方法从 workQueue 中获取待执行的任务。 直接调用 task 的 run 方法来执行具体的任务（而不是新建线程）。 在这里，我们找到了最终的实现，通过取 Worker 的 firstTask 或者 getTask方法从 workQueue 中取出了新任务，并直接调用 Runnable 的 run 方法来执行任务，也就是如之前所说的，每个线程都始终在一个大循环中，反复获取任务，然后执行任务，从而实现了线程的复用。","tags":[{"name":"java","slug":"java","permalink":"https://sunshine-zwq.gitee.io/tags/java/"},{"name":"并发编程","slug":"并发编程","permalink":"https://sunshine-zwq.gitee.io/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"},{"name":"面试","slug":"面试","permalink":"https://sunshine-zwq.gitee.io/tags/%E9%9D%A2%E8%AF%95/"}]},{"title":"Java并发编程常见问题-线程安全","date":"2020-12-14T08:28:27.000Z","path":"2020/12/14/Java并发编程常见问题-线程安全/","text":"1.一共有哪 3 类线程安全问题？什么是线程安全 《Java Concurrency In Practice》的作者 Brian Goetz 对线程安全是这样理解的，当多个线程访问一个对象时，如果不用考虑这些线程在运行时环境下的调度和交替执行问题，也不需要进行额外的同步，而调用这个对象的行为都可以获得正确的结果，那这个对象便是线程安全的。 事实上，Brian Goetz 想表达的意思是，如果某个对象是线程安全的，那么对于使用者而言，在使用时就不需要考虑方法间的协调问题，比如不需要考虑不能同时写入或读写不能并行的问题，也不需要考虑任何额外的同步问题，比如不需要额外自己加 synchronized 锁，那么它才是线程安全的，可以看出对线程安全的定义还是非常苛刻的。 一共有 3 种典型的线程安全问题： 运行结果错误； 发布和初始化导致线程安全问题； 活跃性问题。 运行结果错误 数字自增导致的运行结果错误示例： 123456789101112131415161718192021public class WrongResult &#123; volatile static int i; public static void main(String[] args) throws InterruptedException &#123; Runnable r = new Runnable() &#123; @Override public void run() &#123; for (int j = 0; j &lt; 10000; j++) &#123; i++; &#125; &#125; &#125;; Thread thread1 = new Thread(r); thread1.start(); Thread thread2 = new Thread(r); thread2.start(); thread1.join(); thread2.join(); System.out.println(i); &#125;&#125; 理论上得到的结果应该是 20000，但实际结果却远小于理论结果，比如可能是12996，也可能是13323，每次的结果都还不一样。 原因： i++ 操作，表面上看只是一行代码，但实际上它并不是一个原子操作，它的执行步骤主要分为三步（读取、修改、保存），而且在每步操作之间都有可能被打断。 发布和初始化导致线程安全问题 我们创建对象并进行发布和初始化供其他类或对象使用是常见的操作，但如果我们操作的时间或地点不对，就可能导致线程安全问题。如代码所示： 123456789101112131415161718192021222324252627public class WrongInit &#123; private Map&lt;Integer, String&gt; students; public WrongInit() &#123; new Thread(new Runnable() &#123; @Override public void run() &#123; students = new HashMap&lt;&gt;(); students.put(1, \"王小美\"); students.put(2, \"钱二宝\"); students.put(3, \"周三\"); students.put(4, \"赵四\"); &#125; &#125;).start(); &#125; public Map&lt;Integer, String&gt; getStudents() &#123; return students; &#125; public static void main(String[] args) throws InterruptedException &#123; WrongInit multiThreadsError6 = new WrongInit(); System.out.println(multiThreadsError6.getStudents().get(1)); &#125;&#125; 只有当线程运行完 run() 方法中的全部赋值操作后，4 名同学的全部信息才算是初始化完毕，可是我们看在主函数 mian() 中，初始化 WrongInit 类之后并没有进行任何休息就直接打印 1 号同学的信息，试想这个时候程序会出现什么情况？实际上会发生空指针异常： 1Exception in thread &quot;main&quot; java.lang.NullPointerException at lesson6.WrongInit.main(WrongInit.java:32) 活跃性问题 活跃性问题，最典型的有三种，分别为死锁、活锁和饥饿。 死锁 最常见的活跃性问题是死锁，死锁是指两个线程之间相互等待对方资源，但同时又互不相让，都想自己先执行，如代码所示： 12345678910111213141516171819202122232425262728293031323334353637383940414243public class MayDeadLock &#123; Object o1 = new Object(); Object o2 = new Object(); public void thread1() throws InterruptedException &#123; synchronized (o1) &#123; Thread.sleep(500); synchronized (o2) &#123; System.out.println(\"线程1成功拿到两把锁\"); &#125; &#125; &#125; public void thread2() throws InterruptedException &#123; synchronized (o2) &#123; Thread.sleep(500); synchronized (o1) &#123; System.out.println(\"线程2成功拿到两把锁\"); &#125; &#125; &#125; public static void main(String[] args) &#123; MayDeadLock mayDeadLock = new MayDeadLock(); new Thread(new Runnable() &#123; @Override public void run() &#123; try &#123; mayDeadLock.thread1(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;).start(); new Thread(new Runnable() &#123; @Override public void run() &#123; try &#123; mayDeadLock.thread2(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;).start(); &#125;&#125; 活锁 第二种活跃性问题是活锁，活锁与死锁非常相似，也是程序一直等不到结果，但对比于死锁，活锁是活的，什么意思呢？因为正在运行的线程并没有阻塞，它始终在运行中，却一直得不到结果。 举一个例子，假设有一个消息队列，队列里放着各种各样需要被处理的消息，而某个消息由于自身被写错了导致不能被正确处理，执行时会报错，可是队列的重试机制会重新把它放在队列头进行优先重试处理，但这个消息本身无论被执行多少次，都无法被正确处理，每次报错后又会被放到队列头进行重试，周而复始，最终导致线程一直处于忙碌状态，但程序始终得不到结果，便发生了活锁问题。 饥饿 第三个典型的活跃性问题是饥饿，饥饿是指线程需要某些资源时始终得不到，尤其是CPU 资源，就会导致线程一直不能运行而产生的问题。在 Java 中有线程优先级的概念，Java 中优先级分为 1 到 10，1 最低，10 最高。如果我们把某个线程的优先级设置为 1，这是最低的优先级，在这种情况下，这个线程就有可能始终分配不到 CPU 资源，而导致长时间无法运行。或者是某个线程始终持有某个文件的锁，而其他线程想要修改文件就必须先获取锁，这样想要修改文件的线程就会陷入饥饿，长时间不能运行。 2.哪些场景需要额外注意线程安全问题？主要有四种场景：访问共享变量或资源、依赖时序的操作、不同数据之间存在绑定关系、对方没有声明自己是线程安全的。 访问共享变量或资源 第一种场景是访问共享变量或共享资源的时候，典型的场景有访问共享对象的属性，访问 static 静态变量，访问共享的缓存，等等。因为这些信息不仅会被一个线程访问到，还有可能被多个线程同时访问，那么就有可能在并发读写的情况下发生线程安全问题。比如没有控制好并发处理的多线程同时 i++ 的例子。 依赖时序的操作 第二个需要我们注意的场景是依赖时序的操作，如果我们操作的正确性是依赖时序的，而在多线程的情况下又不能保障执行的顺序和我们预想的一致，这个时候就会发生线程安全问题，如下面的代码所示： 123if (map.containsKey(key)) &#123; map.remove(obj)&#125; 代码中首先检查 map 中有没有 key 对应的元素，如果有则继续执行 remove 操作。此时，这个组合操作就是危险的，因为它是先检查后操作，而执行过程中可能会被打断。如果此时有两个线程同时进入 if() 语句，然后它们都检查到存在 key 对应的元素，于是都希望执行下面的 remove 操作，随后一个线程率先把 obj 给删除了，而另外一个线程它刚已经检查过存在 key 对应的元素，if 条件成立，所以它也会继续执行删除 obj 的操作，但实际上，集合中的 obj 已经被前面的线程删除了，这种情况下就可能导致线程安全问题。 这种情况下，我们就需要对它进行加锁等保护措施来保障操作的原子性。 不同数据之间存在绑定关系 第三种需要我们注意的线程安全场景是不同数据之间存在相互绑定关系的情况。有时候，我们的不同数据之间是成组出现的，存在着相互对应或绑定的关系，最典型的就是 IP 和端口号。有时候我们更换了 IP，往往需要同时更换端口号，如果没有把这两个操作绑定在一起，就有可能出现单独更换了 IP 或端口号的情况，而此时信息如果已经对外发布，信息获取方就有可能获取一个错误的 IP 与端口绑定情况，这时就发生了线程安全问题。在这种情况下，我们也同样需要保障操作的原子性。 对方没有声明自己是线程安全的 第四种值得注意的场景是在我们使用其他类时，如果对方没有声明自己是线程安全的，那么这种情况下对其他类进行多线程的并发操作，就有可能会发生线程安全问题。举个例子，比如说我们定义了 ArrayList，它本身并不是线程安全的，如果此时多个线程同时对 ArrayList 进行并发读/写，那么就有可能会产生线程安全问题，造成数据出错，而这个责任并不在 ArrayList，因为它本身并不是并发安全的 3.为什么多线程会带来性能问题？主要有两个方面，一方面是线程调度，另一个方面是线程协作。 调度开销 (1).上下文切换 首先，我们看一下线程调度，在实际开发中，线程数往往是大于 CPU 核心数的，比如 CPU 核心数可能是 8 核、16 核，等等，但线程数可能达到成百上千个。这种情况下，操作系统就会按照一定的调度算法，给每个线程分配时间片，让每个线程都有机会得到运行。而在进行调度时就会引起上下文切换，上下文切换会挂起当前正在执行的线程并保存当前的状态，然后寻找下一处即将恢复执行的代码，唤醒下一个线程，以此类推，反复执行。但上下文切换带来的开销是比较大的，假设我们的任务内容非常短，比如只进行简单的计算，那么就有可能发生我们上下文切换带来的性能开销比执行线程本身内容带来的开销还要大的情况。 (2).缓存失效 不仅上下文切换会带来性能问题，缓存失效也有可能带来性能问题。由于程序有很大概率会再次访问刚才访问过的数据，所以为了加速整个程序的运行，会使用缓存，这样我们在使用相同数据时就可以很快地获取数据。可一旦进行了线程调度，切换到其他线程，CPU就会去执行不同的代码，原有的缓存就很可能失效了，需要重新缓存新的数据，这也会造成一定的开销，所以线程调度器为了避免频繁地发生上下文切换，通常会给被调度到的线程设置最小的执行时间，也就是只有执行完这段时间之后，才可能进行下一次的调度，由此减少上下文切换的次数。 那么什么情况会导致密集的上下文切换呢？如果程序频繁地竞争锁，或者由于 IO 读写等原因导致频繁阻塞，那么这个程序就可能需要更多的上下文切换，这也就导致了更大的开销，我们应该尽量避免这种情况的发生。 协作开销 除了线程调度之外，线程协作同样也有可能带来性能问题。因为线程之间如果有共享数据，为了避免数据错乱，为了保证线程安全，就有可能禁止编译器和 CPU 对其进行重排序等优化，也可能出于同步的目的，反复把线程工作内存的数据 flush 到主存中，然后再从主内存 refresh 到其他线程的工作内存中，等等。这些问题在单线程中并不存在，但在多线程中为了确保数据的正确性，就不得不采取上述方法，因为线程安全的优先级要比性能优先级更高，这也间接降低了我们的性能。","tags":[{"name":"java","slug":"java","permalink":"https://sunshine-zwq.gitee.io/tags/java/"},{"name":"并发编程","slug":"并发编程","permalink":"https://sunshine-zwq.gitee.io/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"},{"name":"面试","slug":"面试","permalink":"https://sunshine-zwq.gitee.io/tags/%E9%9D%A2%E8%AF%95/"}]},{"title":"Java并发编程常见问题-线程基础升华","date":"2020-12-14T08:16:37.000Z","path":"2020/12/14/Java并发编程常见问题-线程基础升华/","text":"1.为何说只有 1 种实现线程的方法？为什么说本质上只有一种实现线程的方式？ 最常见的创建线程方式：(1).继承Thread类，(2).实现Runnable接口；除此之外，常规的创建线程方式还有：(3).通过线程池创建，(4).通过有返回值的Callable创建。其他创建方式还有：定时器Timer、匿名内部类或 lambda 表达式方式等等。 深入解析线程池中的源码，看看线程池是怎么实现线程的： 12345678910111213141516171819202122static class DefaultThreadFactory implements ThreadFactory &#123; DefaultThreadFactory() &#123; SecurityManager s = System.getSecurityManager(); group = (s != null) ? s.getThreadGroup() : Thread.currentThread().getThreadGroup(); namePrefix = \"pool-\" + poolNumber.getAndIncrement() + \"-thread-\"; &#125; public Thread newThread(Runnable r) &#123; Thread t = new Thread(group, r, namePrefix + threadNumber.getAndIncrement(),0); if (t.isDaemon()) t.setDaemon(false); if (t.getPriority() != Thread.NORM_PRIORITY) t.setPriority(Thread.NORM_PRIORITY); return t; &#125;&#125; 对于线程池而言，本质上是通过线程工厂创建线程的，默认采用 DefaultThreadFactory ，它会给线程池创建的线程设置一些默认值，比如：线程的名字、是否是守护线程，以及线程的优先级等。但是无论怎么设置这些属性，最终它还是通过 new Thread() 创建线程的。 Callable创建线程示例： 12345678910class CallableTask implements Callable&lt;Integer&gt; &#123; @Override public Integer call() throws Exception &#123; return new Random().nextInt(); &#125;&#125;//创建线程池ExecutorService service = Executors.newFixedThreadPool(10);//提交任务，并用 Future提交返回结果Future&lt;Integer&gt; future = service.submit(new CallableTask()); 无论是 Callable 还是 FutureTask，它们首先和 Runnable 一样，都是一个任务，是需要被执行的，而不是说它们本身就是线程。它们可以放到线程池中执行，如代码所示， submit() 方法把任务放到线程池中，并由线程池创建线程，不管用什么方法，最终都是靠线程来执行的。 定时器Timer内部源码截取： 123class TimerThread extends Thread &#123;//具体实现&#125; 深入分析定时器的源码会发现，本质上它还是会有一个继承自 Thread 类的 TimerThread。 综上所述，上面提及的创建线程方式，打开封装后，会发现它们最终都是基于 Runnable 接口或继承 Thread 类实现的。接下来，我们进行更深层次的探讨，为什么说这两种方式本质上是一种呢？ 123456@Overridepublic void run() &#123; if (target != null) &#123; target.run(); &#125;&#125; 首先，启动线程需要调用 start() 方法，而 start() 方法最终还会调用 run() 方法，我们先来看看第一种方式中 run() 方法究竟是怎么实现的，可以看出 run() 方法的代码非常短小精悍，第 1 行代码 if (target != null) ，判断 target 是否等于 null，如果不等于 null，就执行第 2 行代码 target.run()，而 target 实际上就是一个 Runnable，即使用 Runnable 接口实现线程时传给Thread类的对象。 然后，我们来看第二种方式，也就是继承 Thread 方式，实际上，继承 Thread 类之后，会把上述的 run() 方法重写，重写后 run() 方法里直接就是所需要执行的任务，但它最终还是需要调用 thread.start() 方法来启动线程，而 start() 方法最终也会调用这个已经被重写的 run() 方法来执行它的任务，这时我们就可以彻底明白了，事实上创建线程只有一种方式，就是构造一个 Thread 类，这是创建线程的唯一方式。 为什么说本质上只有一种实现线程的方式？这个问题可以这样描述： 本质上，实现线程只有一种方式，而要想实现线程执行的内容，却有两种方式，也就是可以通过 实现 Runnable 接口的方式，或是继承 Thread 类重写 run() 方法的方式，把我们想要执行的代码传入，让线程去执行，在此基础上，如果我们还想有更多实现线程的方式，比如线程池和 Timer 定时器，只需要在此基础上进行封装即可。 实现 Runnable 接口究竟比继承 Thread 类实现线程好在哪里？ 首先，我们从代码的架构考虑，实际上，Runnable 里只有一个 run() 方法，它定义了需要执行的内容，在这种情况下，实现了 Runnable 与 Thread 类的解耦，Thread 类负责线程启动和属性设置等内容，权责分明。 在某些情况下可以提高性能，使用继承 Thread 类方式，每次执行一次任务，都需要新建一个独立的线程，执行完任务后线程走到生命周期的尽头被销毁，如果还想执行这个任务，就必须再新建一个继承了 Thread 类的类，如果此时执行的内容比较少，比如只是在 run() 方法里简单打印一行文字，那么它所带来的开销并不大，相比于整个线程从开始创建到执行完毕被销毁，这一系列的操作比 run() 方法打印文字本身带来的开销要大得多，相当于捡了芝麻丢了西瓜，得不偿失。如果我们使用实现 Runnable 接口的方式，就可以把任务直接传入线程池，使用一些固定的线程来完成任务，不需要每次新建销毁线程，大大降低了性能开销。 Java 语言不支持双继承，如果我们的类一旦继承了 Thread 类，那么它后续就没有办法再继承其他的类，这样一来，如果未来这个类需要继承其他类实现一些功能上的拓展，它就没有办法做到了，相当于限制了代码未来的可拓展性。 综上所述，我们应该优先选择通过实现 Runnable 接口的方式来创建线程。 2.如何正确停止线程？为什么 volatile 标记位的停止方法是错误的？为什么不强制停止？而是通知、协作 对于 Java 而言，最正确的停止线程的方式是使用 interrupt。但 interrupt 仅仅起到通知被停止线程的作用。而对于被停止的线程而言，它拥有完全的自主权，它既可以选择立即停止，也可以选择一段时间后停止，也可以选择压根不停止。那么为什么 Java 不提供强制停止线程的能力呢？ 事实上，Java 希望程序间能够相互通知、相互协作地管理线程，因为如果不了解对方正在做的工作，贸然强制停止线程就可能会造成一些安全的问题，为了避免造成问题就需要给对方一定的时间来整理收尾工作。比如：线程正在写入一个文件，这时收到终止信号，它就需要根据自身业务判断，是选择立即停止，还是将整个文件写入成功后停止，而如果选择立即停止就可能造成数据不完整，不管是中断命令发起者，还是接收者都不希望数据出现问题。 如何用 interrupt 停止线程 123while (!Thread.currentThread().isInterrupted() &amp;&amp; more work to do) &#123; do more work&#125; 我们一旦调用某个线程的 interrupt() 之后，这个线程的中断标记位就会被设置成 true。每个线程都有这样的标记位，当线程执行时，应该定期检查这个标记位，如果标记位被设置成 true，就说明有程序想终止该线程。回到源码，可以看到在 while 循环体判断语句中，首先通过 Thread.currentThread().isInterrupt() 判断线程是否被断，随后检查是否还有工作要做。&amp;&amp; 逻辑表示只有当两个判断条件同时满足的情况下，才会去执行下面的工作。 具体实例： 1234567891011121314151617public class StopThread implements Runnable &#123; @Override public void run() &#123; int count = 0; while (!Thread.currentThread().isInterrupted() &amp;&amp; count &lt; 1000) &#123; System.out.println(\"count = \" + count++); &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; Thread thread = new Thread(new StopThread()); thread.start(); Thread.sleep(5); thread.interrupt(); &#125;&#125; sleep 期间能否感受到中断 1234567891011121314151617181920public class StopDuringSleep &#123; public static void main(String[] args) throws InterruptedException &#123; Runnable runnable = () -&gt; &#123; int num = 0; try &#123; while (!Thread.currentThread().isInterrupted() &amp;&amp; num &lt;= 1000) &#123; System.out.println(num); num++; Thread.sleep(1000000); &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;; Thread thread = new Thread(runnable); thread.start(); Thread.sleep(5); thread.interrupt(); &#125;&#125; 主线程休眠 5 毫秒后，通知子线程中断，此时子线程仍在执行 sleep 语句，处于休眠中。那么就需要考虑一点，在休眠中的线程是否能够感受到中断通知呢？是否需要等到休眠结束后才能中断线程呢？如果是这样，就会带来严重的问题，因为响应中断太不及时了。正因为如此，Java 设计者在设计之初就考虑到了这一点。 如果 sleep、wait 等可以让线程进入阻塞的方法使线程休眠了，而处于休眠中的线程被中断，那么线程是可以感受到中断信号的，并且会抛出一个 InterruptedException 异常，同时清除中断信号，将中断标记位设置成 false。这样一来就不用担心长时间休眠中线程感受不到中断了，因为即便线程还在休眠，仍然能够响应中断通知，并抛出异常。 错误的停止方法 首先，我们来看几种停止线程的错误方法。比如 stop()，suspend() 和 resume()，这些方法已经被 Java 直接标记为 @Deprecated。如果再调用这些方法，IDE 会友好地提示，我们不应该再使用它们了。但为什么它们不能使用了呢？是因为 stop() 会直接把线程停止，这样就没有给线程足够的时间来处理想要在停止前保存数据的逻辑，任务戛然而止，会导致出现数据完整性等问题。 而对于 suspend() 和 resume() 而言，它们的问题在于如果线程调用 suspend()，它并不会释放锁，就开始进入休眠，但此时有可能仍持有锁，这样就容易导致死锁问题，因为这把锁在线程被 resume() 之前，是不会被释放的。 为什么用 volatile 标记位的停止方法是错误的？ volatile 修饰标记位适用的场景（可以正常停止线程执行）： 12345678910111213141516171819202122232425262728public class VolatileCanStop implements Runnable &#123; private volatile boolean canceled = false; @Override public void run() &#123; int num = 0; try &#123; while (!canceled &amp;&amp; num &lt;= 1000000) &#123; if (num % 10 == 0) &#123; System.out.println(num + \"是10的倍数。\"); &#125; num++; Thread.sleep(1); &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; public static void main(String[] args) throws InterruptedException &#123; VolatileCanStop r = new VolatileCanStop(); Thread thread = new Thread(r); thread.start(); Thread.sleep(3000); r.canceled = true; &#125;&#125; volatile 修饰标记位不适用的场景： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657public class TestProducerAndConsumer &#123; public static void main(String[] args) throws InterruptedException &#123; ArrayBlockingQueue storage = new ArrayBlockingQueue(8); Producer producer = new Producer(storage); Thread producerThread = new Thread(producer); producerThread.start(); Thread.sleep(500); Consumer consumer = new Consumer(storage); while (consumer.needMoreNums()) &#123; System.out.println(consumer.storage.take() + \"被消费了\"); Thread.sleep(100); &#125; System.out.println(\"消费者不需要更多数据了。\"); //一旦消费不需要更多数据了，我们应该让生产者也停下来，但是实际情况却停不下来 producer.canceled = true; System.out.println(producer.canceled); &#125;&#125;class Producer implements Runnable &#123; public volatile boolean canceled = false; BlockingQueue storage; public Producer(BlockingQueue storage) &#123; this.storage = storage; &#125; @Override public void run() &#123; int num = 0; try &#123; while (num &lt;= 100000 &amp;&amp; !canceled) &#123; if (num % 50 == 0) &#123; storage.put(num); System.out.println(num + \"是50的倍数,被放到仓库中了。\"+storage.size()); &#125; num++; &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; finally &#123; System.out.println(\"生产者结束运行\"); &#125; &#125;&#125;class Consumer &#123; BlockingQueue storage; public Consumer(BlockingQueue storage) &#123; this.storage = storage; &#125; public boolean needMoreNums() &#123; if (Math.random() &gt; 0.97) &#123; return false; &#125; return true; &#125;&#125; 运行结果（打印停止之后，java进程并没有自动关闭，说明还在运行）： 123456789101112131415161718192021220是50的倍数,被放到仓库中了。50是50的倍数,被放到仓库中了。100是50的倍数,被放到仓库中了。150是50的倍数,被放到仓库中了。200是50的倍数,被放到仓库中了。250是50的倍数,被放到仓库中了。300是50的倍数,被放到仓库中了。350是50的倍数,被放到仓库中了。0被消费了400是50的倍数,被放到仓库中了。50被消费了450是50的倍数,被放到仓库中了。100被消费了500是50的倍数,被放到仓库中了。150被消费了550是50的倍数,被放到仓库中了。200被消费了600是50的倍数,被放到仓库中了。250被消费了650是50的倍数,被放到仓库中了。消费者不需要更多数据了。true 程序首先创建了生产者/消费者共用的仓库 BlockingQueue storage，仓库容量是 8，并且建立生产者并将生产者放入线程后启动线程，启动后进行 500 毫秒的休眠，休眠时间保障生产者有足够的时间把仓库塞满，而仓库达到容量后就不会再继续往里塞，这时生产者会阻塞，500 毫秒后消费者也被创建出来，并判断是否需要使用更多的数字，然后每次消费后休眠 100 毫秒，这样的业务逻辑是有可能出现在实际生产中的。 当消费者不再需要数据，就会将 canceled 的标记位设置为 true，理论上此时生产者会跳出 while 循环，并打印输出“生产者运行结束”。 然而结果却不是我们想象的那样，尽管已经把 canceled 设置成 true，但生产者仍然没有停止，这是因为在这种情况下，生产者在执行 storage.put(num) 时发生阻塞，在它被唤醒之前是没有办法进入下一次循环判断 canceled 的值的，所以在这种情况下用 volatile 是没有办法让生产者停下来的，相反如果用 interrupt 语句来中断，即使生产者处于阻塞状态，仍然能够感受到中断信号，并做响应处理。 3.线程是如何在 6 种状态之间转换的？Java 中线程的生命周期中一共有 6 种状态： New（新创建） Runnable（可运行） Blocked（被阻塞） Waiting（等待） Timed Waiting（计时等待） Terminated（被终止） 如果想要确定线程当前的状态，可以通过 getState() 方法，并且线程在任何时刻只可能处于 1 种状态。 New 新创建 New 表示线程被创建但尚未启动的状态：当我们用 new Thread() 新建一个线程时，如果线程没有开始运行 start() 方法，所以也没有开始执行 run() 方法里面的代码，那么此时它的状态就是 New。而一旦线程调用了 start()，它的状态就会从 New 变成 Runnable，也就是状态转换图中中间的这个大方框里的内容。 Runnable 可运行 Java 中的 Runable 状态对应操作系统线程状态中的两种状态，分别是 Running 和 Ready，也就是说，Java 中处于 Runnable 状态的线程有可能正在执行，也有可能没有正在执行，正在等待被分配 CPU 资源。 所以，如果一个正在运行的线程是 Runnable 状态，当它运行到任务的一半时，执行该线程的 CPU 被调度去做其他事情，导致该线程暂时不运行，它的状态依然不变，还是 Runnable，因为它有可能随时被调度回来继续执行任务。 阻塞状态 在 Java 中阻塞状态通常不仅仅是 Blocked，实际上它包括三种状态，分别是 Blocked(被阻塞）、Waiting(等待）、Timed Waiting(计时等待）。 Blocked 被阻塞 从 Runnable 状态进入 Blocked 状态只有一种可能，就是进入 synchronized 保护的代码时没有抢到 monitor锁，无论是进入 synchronized 代码块，还是 synchronized 方法，都是一样。 当处于 Blocked 的线程抢到 monitor 锁，就会从 Blocked 状态回到Runnable 状态。 Waiting 等待 线程进入 Waiting 状态有三种可能性： 没有设置 Timeout 参数的 Object.wait() 方法。 没有设置 Timeout 参数的 Thread.join() 方法。 LockSupport.park() 方法。 刚才强调过，Blocked 仅仅针对 synchronized monitor 锁，可是在 Java 中还有很多其他的锁，比如ReentrantLock，如果线程在获取这种锁时没有抢到该锁就会进入 Waiting 状态，因为本质上它执行了 LockSupport.park() 方法，所以会进入 Waiting 状态。同样，Object.wait() 和 Thread.join() 也会让线程进入 Waiting 状态。 Blocked 与 Waiting 的区别是 Blocked 在等待其他线程释放 monitor 锁，而 Waiting 则是在等待某个条件，比如 join 的线程执行完毕，或者是 notify()/notifyAll() 。 Timed Waiting 限期等待 在 Waiting 上面是 Timed Waiting 状态，这两个状态是非常相似的，区别仅在于有没有时间限制，Timed Waiting 会等待超时，由系统自动唤醒，或者在超时前被唤醒信号唤醒。 以下情况会让线程进入 Timed Waiting 状态： 设置了时间参数的 Thread.sleep(long millis) 方法； 设置了时间参数的 Object.wait(long timeout) 方法； 设置了时间参数的 Thread.join(long millis) 方法； 设置了时间参数的 LockSupport.parkNanos(long nanos) 方法和 LockSupport.parkUntil(long deadline) 方法。 从 Waiting 状态流转到其他状态则比较特殊，因为首先 Waiting 是不限时的，也就是说无论过了多长时间它都不会主动恢复。 只有当执行了 LockSupport.unpark()，或者 join 的线程运行结束，或者被中断时才可以进入 Runnable 状态。 如果其他线程调用 notify() 或 notifyAll()来唤醒它，它会直接进入 Blocked 状态，这是为什么呢？因为唤醒 Waiting 线程的线程如果调用 notify() 或 notifyAll()，要求必须首先持有该 monitor 锁，所以处于 Waiting 状态的线程被唤醒时拿不到该锁，就会进入 Blocked 状态，直到执行了 notify()/notifyAll() 的唤醒它的线程执行完毕并释放 monitor 锁，才可能轮到它去抢夺这把锁，如果它能抢到，就会从 Blocked 状态回到 Runnable 状态。 同样在 Timed Waiting 中执行 notify() 和 notifyAll() 也是一样的道理，它们会先进入 Blocked 状态，然后抢夺锁成功后，再回到 Runnable 状态。 当然对于 Timed Waiting 而言，如果它的超时时间到了且能直接获取到锁/join的线程运行结束/被中断/调用了LockSupport.unpark()，会直接恢复到 Runnable 状态，而无需经历 Blocked 状态。 Terminated 终止 进入Terminated 终止状态这个状态有两种可能： run() 方法执行完毕，线程正常退出。 出现一个没有捕获的异常，终止了 run() 方法，最终导致意外终止。 注意点 线程的状态是需要按照箭头方向来走的，比如线程从 New 状态是不可以直接进入 Blocked 状态的，它需要先经历 Runnable 状态。 线程生命周期不可逆：一旦进入 Runnable 状态就不能回到 New 状态；一旦被终止就不可能再有任何状态的变化。所以一个线程只能有一次 New 和 Terminated 状态，只有处于中间状态才可以相互转换。 4.wait/notify/notifyAll 方法的使用注意事项为什么 wait 必须在 synchronized 保护的同步代码中使用？ wait 方法的源码注释： “wait method should always be used in a loop: 12345synchronized (obj) &#123; while (condition does not hold) obj.wait(); ... // Perform action appropriate to condition&#125; This method should only be called by a thread that is the owner of this object’s monitor.” 英文部分的意思是说，在使用 wait 方法时，必须把 wait 方法写在 synchronized 保护的 while 代码块中，并始终判断执行条件是否满足，如果满足就往下继续执行，如果不满足就执行 wait 方法，而在执行 wait 方法之前，必须先持有对象的 monitor 锁，也就是通常所说的 synchronized 锁。那么设计成这样有什么好处呢？ 我们逆向思考这个问题，如果不要求 wait 方法放在 synchronized 保护的同步代码中使用，而是可以随意调用，那么就有可能写出这样的代码。 12345678910111213class BlockingQueue &#123; Queue&lt;String&gt; buffer = new LinkedList&lt;String&gt;(); public void give(String data) &#123; buffer.add(data); notify(); // Since someone may be waiting in take &#125; public String take() throws InterruptedException &#123; while (buffer.isEmpty()) &#123; wait(); &#125; return buffer.remove(); &#125;&#125; 但是这段代码并没有受 synchronized 保护，于是便有可能发生以下场景： 首先，消费者线程调用 take 方法并判断 buffer.isEmpty 方法是否返回 true，若为 true 代表buffer是空的，则线程希望进入等待，但是在线程调用 wait 方法之前，就被调度器暂停了，所以此时还没来得及执行 wait 方法。 此时生产者开始运行，执行了整个 give 方法，它往 buffer 中添加了数据，并执行了 notify 方法，但 notify 并没有任何效果，因为消费者线程的 wait 方法没来得及执行，所以没有线程在等待被唤醒。 此时，刚才被调度器暂停的消费者线程回来继续执行 wait 方法并进入了等待。 虽然刚才消费者判断了 buffer.isEmpty 条件，但真正执行 wait 方法时，之前的 buffer.isEmpty 的结果已经过期了，不再符合最新的场景了，因为这里的“判断-执行”不是一个原子操作，它在中间被打断了，是线程不安全的。 假设这时没有更多的生产者进行生产，消费者便有可能陷入无穷无尽的等待，因为它错过了刚才 give 方法内的 notify 的唤醒。 代码改写成源码注释所要求的被 synchronized 保护的同步代码块的形式，代码如下： 123456789101112131415public void give(String data) &#123; synchronized (this) &#123; buffer.add(data); notify(); &#125;&#125; public String take() throws InterruptedException &#123; synchronized (this) &#123; while (buffer.isEmpty()) &#123; wait(); &#125; return buffer.remove(); &#125;&#125; 另外，wait 方法会释放 monitor 锁，这也要求我们必须首先进入到 synchronized 内持有这把锁。 这里还存在一个“虚假唤醒”（spurious wakeup）的问题，线程可能在既没有被notify/notifyAll，也没有被中断或者超时的情况下被唤醒，这种唤醒是我们不希望看到的。虽然在实际生产中，虚假唤醒发生的概率很小，但是程序依然需要保证在发生虚假唤醒的时候的正确性，所以就需要采用while循环的结构。 12while (condition does not hold) obj.wait(); 这样即便被虚假唤醒了，也会再次检查while里面的条件，如果不满足条件，就会继续wait，也就消除了虚假唤醒的风险。 为什么 wait/notify/notifyAll 被定义在 Object 类中，而 sleep 定义在 Thread 类中？ 主要有两点原因： 因为 Java 中每个对象都有一把称之为 monitor 监视器的锁，由于每个对象都可以上锁，这就要求在对象头中有一个用来保存锁信息的位置。这个锁是对象级别的，而非线程级别的，wait/notify/notifyAll 也都是锁级别的操作，它们的锁属于对象，所以把它们定义在 Object 类中是最合适，因为 Object 类是所有对象的父类。 因为如果把 wait/notify/notifyAll 方法定义在 Thread 类中，会带来很大的局限性，比如一个线程可能持有多把锁，以便实现相互配合的复杂逻辑，假设此时 wait 方法定义在 Thread 类中，如何实现让一个线程持有多把锁呢？又如何明确线程等待的是哪把锁呢？既然我们是让当前线程去等待某个对象的锁，自然应该通过操作对象来实现，而不是操作线程。 wait/notify 和 sleep 方法的异同？ 相同点： 它们都可以让线程阻塞。 它们都可以响应 interrupt 中断：在等待的过程中如果收到中断信号，都可以进行响应，并抛出 InterruptedException 异常。 不同点： wait 方法必须在 synchronized 保护的代码中使用，而 sleep 方法并没有这个要求。 在同步代码中执行 sleep 方法时，并不会释放 monitor 锁，但执行 wait 方法时会主动释放 monitor 锁。 sleep 方法中会要求必须定义一个时间，时间到期后会主动恢复，而对于没有参数的 wait 方法而言，意味着永久等待，直到被中断或被唤醒才能恢复，它并不会主动恢复。 wait/notify 是 Object 类的方法，而 sleep 是 Thread 类的方法。 5.有哪几种实现生产者消费者模式的方法？生产者消费者模式 生产者消费者模式是程序设计中非常常见的一种设计模式，被广泛运用在解耦、消息队列等场景。在现实世界中，我们把生产商品的一方称为生产者，把消费商品的一方称为消费者，有时生产者的生产速度特别快，但消费者的消费速度跟不上，俗称“产能过剩”，又或是多个生产者对应多个消费者时，大家可能会手忙脚乱。如何才能让大家更好地配合呢？这时在生产者和消费者之间就需要一个中介来进行调度，于是便诞生了生产者消费者模式。 (1).BlockingQueue 实现 1234567891011121314151617181920public static void main(String[] args) &#123; BlockingQueue&lt;Object&gt; queue = new ArrayBlockingQueue&lt;&gt;(10); Runnable producer = () -&gt; &#123; while (true) &#123; queue.put(new Object()); &#125; &#125;; new Thread(producer).start(); new Thread(producer).start(); Runnable consumer = () -&gt; &#123; while (true) &#123; queue.take(); &#125; &#125;; new Thread(consumer).start(); new Thread(consumer).start(); &#125; 如代码所示，首先，创建了一个 ArrayBlockingQueue 类型的 BlockingQueue，命名为 queue 并将它的容量设置为 10；其次，创建一个简单的生产者，while(true) 循环体中的queue.put() 负责往队列添加数据；然后，创建两个生产者线程并启动；同样消费者也非常简单，while(true) 循环体中的 queue.take() 负责消费数据，同时创建两个消费者线程并启动。为了代码简洁并突出设计思想，代码里省略了 try/catch 检测，我们不纠结一些语法细节。以上便是利用 BlockingQueue 实现生产者消费者模式的代码。虽然代码非常简单，但实际上 ArrayBlockingQueue 已经在背后完成了很多工作，比如队列满了就去阻塞生产者线程，队列有空就去唤醒生产者线程等。 (2).Condition 实现 12345678910111213141516171819202122232425262728293031323334353637383940public class MyBlockingQueueForCondition &#123; private Queue queue; private int max = 16; private ReentrantLock lock = new ReentrantLock(); private Condition notEmpty = lock.newCondition(); private Condition notFull = lock.newCondition(); public MyBlockingQueueForCondition(int size) &#123; this.max = size; queue = new LinkedList(); &#125; public void put(Object o) throws InterruptedException &#123; lock.lock(); try &#123; while (queue.size() == max) &#123; notFull.await(); &#125; queue.add(o); notEmpty.signalAll(); &#125; finally &#123; lock.unlock(); &#125; &#125; public Object take() throws InterruptedException &#123; lock.lock(); try &#123; while (queue.size() == 0) &#123; notEmpty.await(); &#125; Object item = queue.remove(); notFull.signalAll(); return item; &#125; finally &#123; lock.unlock(); &#125; &#125;&#125; 因为生产者消费者模式通常是面对多线程的场景，需要一定的同步措施保障线程安全，所以在 put 方法中先将Lock 锁上，然后，在 while 的条件里检测 queue 是不是已经满了，如果已经满了，则调用 notFull 的 await()阻塞生产者线程并释放 Lock，如果没有满，则往队列放入数据并利用 notEmpty.signalAll() 通知正在等待的所有消费者并唤醒它们。最后在 finally 中利用 lock.unlock() 方法解锁，把 unlock 方法放在 finally 中是一个基本原则，否则可能会产生无法释放锁的情况。 这里需要注意，我们在 take() 方法中使用 while( queue.size() == 0 ) 检查队列状态，而不能用 if( queue.size() == 0 )。为什么呢？大家思考这样一种情况，因为生产者消费者往往是多线程的，我们假设有两个消费者，第一个消费者线程获取数据时，发现队列为空，便进入等待状态；因为第一个线程在等待时会释放 Lock 锁，所以第二个消费者可以进入并执行 if( queue.size() == 0 )，也发现队列为空，于是第二个线程也进入等待；而此时，如果生产者生产了一个数据，便会唤醒两个消费者线程，而两个线程中只有一个线程可以拿到锁，并执行 queue.remove 操作，另外一个线程因为没有拿到锁而卡在被唤醒的地方，而第一个线程执行完操作后会在 finally 中通过 unlock 解锁，而此时第二个线程便可以拿到被第一个线程释放的锁，继续执行操作，也会去调用 queue.remove 操作，然而这个时候队列已经为空了，所以会抛出 NoSuchElementException 异常，这不符合我们的逻辑。而如果用while 做检查，当第一个消费者被唤醒得到锁并移除数据之后，第二个线程在执行 remove 前仍会进行 while 检查，发现此时依然满足 queue.size() == 0 的条件，就会继续执行 await 方法，避免了获取的数据为 null 或抛出异常的情况。 (3).wait/notify 实现 1234567891011121314151617181920212223242526class MyBlockingQueue &#123; private int maxSize; private LinkedList&lt;Object&gt; storage; public MyBlockingQueue(int size) &#123; this.maxSize = size; storage = new LinkedList&lt;&gt;(); &#125; public synchronized void put() throws InterruptedException &#123; while (storage.size() == maxSize) &#123; wait(); &#125; storage.add(new Object()); notifyAll(); &#125; public synchronized void take() throws InterruptedException &#123; while (storage.size() == 0) &#123; wait(); &#125; System.out.println(storage.remove()); notifyAll(); &#125;&#125;","tags":[{"name":"java","slug":"java","permalink":"https://sunshine-zwq.gitee.io/tags/java/"},{"name":"并发编程","slug":"并发编程","permalink":"https://sunshine-zwq.gitee.io/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"},{"name":"面试","slug":"面试","permalink":"https://sunshine-zwq.gitee.io/tags/%E9%9D%A2%E8%AF%95/"}]},{"title":"Java JUC","date":"2020-12-13T03:14:37.000Z","path":"2020/12/13/Java JUC/","text":"简介 在 Java 5.0 提供了 java.util.concurrent （简称JUC ）包，在此包中增加了在并发编程中很常用的实用工具类，用于定义类似于线程的自定义子系统，包括线程池、异步 IO 和轻量级任务框架。提供可调的、灵活的线程池。还提供了设计用于多线程上下文中的 Collection 实现等。 volatile关键字-内存可见性内存可见性： 内存可见性（Memory Visibility）是指当某个线程正在使用对象状态而另一个线程在同时修改该状态，需要确保当一个线程修改了对象状态后，其他线程能够看到发生的状态变化。 可见性错误是指当读操作与写操作在不同的线程中执行时，我们无法确保执行读操作的线程能适时地看到其他线程写入的值，有时甚至是根本不可能的事情。 我们可以通过同步来保证对象被安全地发布。除此之外我们也可以使用一种更加轻量级的 volatile 变量。 volatile 关键字 Java 提供了一种稍弱的同步机制，即 volatile 变量，用来确保将变量的更新操作通知到其他线程。可以将 volatile 看做一个轻量级的锁，但是又与锁有些不同： 对于多线程，不是一种互斥关系 不能保证变量状态的“原子性操作” 内存不可见代码示例： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546package com.zwq;/** * volatile关键字 * @author zhuwq * @create 2020-11-29 15:25 */public class TestVolatile &#123; public static void main(String[] args) &#123; ThreadDemo td = new ThreadDemo(); new Thread(td).start(); while (true)&#123; if(td.isFlag())&#123; System.out.println(\"------------------\"); break; &#125; &#125; &#125;&#125;class ThreadDemo implements Runnable&#123; private boolean flag = false; @Override public void run() &#123; try &#123; Thread.sleep(200); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; flag = true; System.out.println(\"flag=\" + isFlag()); &#125; public boolean isFlag() &#123; return flag; &#125; public void setFlag(boolean flag) &#123; this.flag = flag; &#125;&#125; 运行结果： 1flag&#x3D;true 运行结果说明，while(true)循环里的 td.isFlag() 值一直都是false，其他线程修改了flag，但并没有同步。 线程读取在主内存的成员变量（即共享变量）的过程： 线程的工作内存会去读取主内存的成员变量并保存副本 线程在工作内存中修改副本 将修改后的副本的值推送给主空间并改写主空间该成员变量的值 主空间成员变量修改后的值将不会主动推送给其他线程, 这就造成了线程的工作内存的共享变量的不同步 示意图： 解决办法： synchroized可以同步值 volatile关键字 会使得主内存的共享变量每经过一次改变都会推送给其他的线程, 其他线程会修改其副本 解决办法1示例代码： 123456789101112public static void main(String[] args) &#123; ThreadDemo td = new ThreadDemo(); new Thread(td).start(); while (true)&#123; synchronized (td)&#123; if(td.isFlag())&#123; System.out.println(\"------------------\"); break; &#125; &#125; &#125; &#125; 运行结果： 12flag&#x3D;true------------------ 解决办法2示例代码： 1private volatile boolean flag = false; 运行结果： 12flag&#x3D;true------------------ 内存不可见的本质：线程之间有互相独立的缓存，即当多个线程对共享数据进行操作时，其操作彼此不可见。 可以直接理解： 使用volatile之后该共享该变量线程不在工作内存缓存其副本，所有线程对该变量的操作全是在主内存中完成，即不在存在操作的不可见，所有线程的操作的变量是位于主内存的变量。 原子变量 CAS算法i++并发问题示例代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243package com.zwq;/** * 一、i++的原子性问题：i++的操作实际上分为3个步骤“读-改-写” * int i = 10; * i = i++;// 10 * * int temp = i; * i = i + 1; * i = temp; * @author zhuwq * @create 2020-11-30 22:33 */public class TestAtomicDemo &#123; public static void main(String[] args) &#123; AtomicDemo ad = new AtomicDemo(); for(int i = 0; i &lt; 10; i++)&#123; new Thread(ad).start(); &#125; &#125;&#125;class AtomicDemo implements Runnable&#123; private int serialNumber = 0; @Override public void run() &#123; try &#123; Thread.sleep(200); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(getSerialNumber()); &#125; public int getSerialNumber()&#123; return serialNumber++; &#125;&#125; 并发出现问题（偶发）的运行结果： 123456789100312476558 i++的多线程操作的问题：会产生重复数据，即在一个线程的工作内存对i的副本进行自增，但是在推送给主内存更新i之前这时其他线程读取了未更新的i值。本质：一组操作的原子性。 如果用volatile去修饰变量，依然解决不了这个并发问题： 1private volatile int serialNumber = 0; volatile的不能保证i++操作同步的原因：i++有读-改-写3步操作，需要保证这3个操作的原子性，volatile只能保证副本之间的可见性，即volatile保证读-改-写的操作的共享变量是对主内存的变量i进行操作，不能保存多个操作的原子性，即在进行读-改-写这组3步操作时，其他线程也能进如这组操作，在写阶段即返回赋值前，其他线程会读取到未修改之前的i，这样多个线程会出现重复数据。 CAS算法： CAS (Compare-And-Swap) 是一种硬件对并发的支持，针对多处理器操作而设计的处理器中的一种特殊指令，用于管理对共享数据的并发访问。 CAS 是一种无锁的非阻塞算法的实现。 CAS 包含了 3 个操作数： 需要读写的内存值 V 进行比较的值 A 拟写入的新值 B 当且仅当 V 的值等于 A 时，CAS 通过原子方式用新值 B 来更新 V 的值，否则不会执行任何操作。 原子变量： 类的小工具包，支持在单个变量上解除锁的线程安全编程。事实上，此包中的类可将 volatile 值、字段和数组元素的概念扩展到那些也提供原子条件更新操作的类。 类 AtomicBoolean、AtomicInteger、AtomicLong 和 AtomicReference 的实例各自提供对相应类型单个变量的访问和更新。每个类也为该类型提供适当的实用工具方法。 AtomicIntegerArray、AtomicLongArray 和 AtomicReferenceArray 类进一步扩展了原子操作，对这些类型的数组提供了支持。这些类在为其数组元素提供 volatile 访问语义方面也引人注目，这对于普通数组来说是不受支持的。 核心方法：boolean compareAndSet(expectedValue, updateValue) java.util.concurrent.atomic 包下提供了一些原子操作的常用类: AtomicBoolean 、AtomicInteger 、AtomicLong 、 AtomicReference AtomicIntegerArray 、AtomicLongArray AtomicMarkableReference AtomicReferenceArray AtomicStampedReference 利用atomic解决上面i++原子操作的问题，示例代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657package com.zwq;import java.util.concurrent.atomic.AtomicInteger;/** * 一、i++的原子性问题：i++的操作实际上分为3个步骤“读-改-写” * int i = 10; * i = i++;// 10 * * int temp = i; * i = i + 1; * i = temp; * * 二、原子变量：jdk1.5后java.util.concurrent.atomic包下提供了常用的原子变量： * 1.volatile保证内存可见性 * 2.CAS(Compare-And-Swap)算法保证数据的原子性 * CAS算法是硬件对于并发操作共享数据的支持 * CAS 包含了三个操作数： * 内存值 V * 预估值 A * 更新值 B * 当且仅当 V==A 时，V = B，否则，将不做任何操作 * @author zhuwq * @create 2020-11-30 22:33 */public class TestAtomicDemo &#123; public static void main(String[] args) &#123; AtomicDemo ad = new AtomicDemo(); for(int i = 0; i &lt; 10; i++)&#123; new Thread(ad).start(); &#125; &#125;&#125;class AtomicDemo implements Runnable&#123;// private volatile int serialNumber = 0; private AtomicInteger serialNumber = new AtomicInteger(); @Override public void run() &#123; try &#123; Thread.sleep(200); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(getSerialNumber()); &#125; public int getSerialNumber()&#123;// return serialNumber++; return serialNumber.getAndIncrement(); &#125;&#125; 模拟CAS算法： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849package com.zwq;/** * 模拟CAS算法 * @author zhuwq * @create 2020-11-30 23:56 */public class TestCompareAndSwap &#123; public static void main(String[] args) &#123; final CompareAndSwap cas = new CompareAndSwap(); for(int i = 0; i &lt; 10; i++)&#123; new Thread(new Runnable() &#123; @Override public void run() &#123; int expectedValue = cas.get(); boolean b = cas.compareAndSet(expectedValue, (int)(Math.random() * 101)); System.out.println(b); &#125; &#125;).start(); &#125; &#125;&#125;class CompareAndSwap&#123; private int value; // 获取内存值 public synchronized int get()&#123; return value; &#125; // 比较 public synchronized int compareAndSwap(int expectedValue, int newValue)&#123; int oldValue = value; if(oldValue == expectedValue)&#123; this.value = newValue; &#125; return oldValue; &#125; // 设置 public synchronized boolean compareAndSet(int expectedValue, int newValue)&#123; return expectedValue == compareAndSwap(expectedValue, newValue); &#125;&#125; ConcurrentHashMap锁分段机制 Java 5.0 在 java.util.concurrent 包中提供了多种并发容器类来改进同步容器的性能。 ConcurrentHashMap 同步容器类是Java 5 增加的一个线程安全的哈希表。对与多线程的操作，介于 HashMap 与 Hashtable 之间。内部采用“锁分段”机制替代 Hashtable 的独占锁。进而提高性能。 此包还提供了设计用于多线程上下文中的 Collection 实现：ConcurrentHashMap、ConcurrentSkipListMap、ConcurrentSkipListSet、CopyOnWriteArrayList 和 CopyOnWriteArraySet。当期望许多线程访问一个给定 collection 时，ConcurrentHashMap 通常优于同步的 HashMap，ConcurrentSkipListMap 通常优于同步的 TreeMap。当期望的读数和遍历远远大于列表的更新数时，CopyOnWriteArrayList 优于同步的 ArrayList。 效率低下的HashTable容器 HashTable容器使用synchronized来保证线程安全，但在线程竞争激烈的情况下HashTable的效率非常低下。因为当一个线程访问HashTable的同步方法时，其他线程访问HashTable的同步方法时，可能会进入阻塞或轮询状态。如线程1使用put进行添加元素，线程2不但不能使用put方法添加元素，并且也不能使用get方法来获取元素，所以竞争越激烈效率越低。 ConcurrentHashMap的锁分段技术 HashTable容器在竞争激烈的并发环境下表现出效率低下的原因，是因为所有访问HashTable的线程都必须竞争同一把锁，那假如容器里有多把锁，每一把锁用于锁容器其中一部分数据，那么当多线程访问容器里不同数据段的数据时，线程间就不会存在锁竞争，从而可以有效的提高并发访问效率，这就是ConcurrentHashMap所使用的锁分段技术，首先将数据分成一段一段的存储，然后给每一段数据配一把锁，当一个线程占用锁访问其中一个段数据的时候，其他段的数据也能被其他线程访问。 ConcurrentHashMap的结构 我们通过ConcurrentHashMap的类图来分析ConcurrentHashMap的结构。 ConcurrentHashMap是由Segment数组结构和HashEntry数组结构组成。Segment是一种可重入锁ReentrantLock，在ConcurrentHashMap里扮演锁的角色，HashEntry则用于存储键值对数据。一个ConcurrentHashMap里包含一个Segment数组，Segment的结构和HashMap类似，是一种数组和链表结构，一个Segment里包含一个HashEntry数组，每个HashEntry是一个链表结构的元素， 每个Segment守护着一个HashEntry数组里的元素，当对HashEntry数组的数据进行修改时，必须首先获得它对应的Segment锁。 并发修改异常： 123456789101112131415161718192021222324252627282930313233343536373839404142package com.zwq;import java.util.ArrayList;import java.util.Collections;import java.util.Iterator;import java.util.List;/** * CopyOnWriteArrayList/CopyOnWriteArraySet：“写入并复制” * @author zhuwq * @create 2020-12-05 13:58 */public class TestCopyOnWriteArrayList &#123; public static void main(String[] args) &#123; HelloThread ht = new HelloThread(); for (int i = 0; i &lt; 10; i++) &#123; new Thread(ht).start(); &#125; &#125;&#125;class HelloThread implements Runnable&#123; private static List&lt;String&gt; list = Collections.synchronizedList(new ArrayList&lt;String&gt;()); static&#123; list.add(\"AA\"); list.add(\"BB\"); list.add(\"CC\"); &#125; @Override public void run() &#123; Iterator&lt;String&gt; it = list.iterator(); while (it.hasNext())&#123; System.out.println(it.next()); list.add(\"DD\"); &#125; &#125;&#125; 程序运行会抛出java.util.ConcurrentModificationException异常，即并发修改异常。 用CopyOnWriteArrayList可以解决问题： 123456789101112131415161718192021222324252627282930313233343536373839404142package com.zwq;import java.util.Iterator;import java.util.concurrent.CopyOnWriteArrayList;/** * CopyOnWriteArrayList/CopyOnWriteArraySet：“写入并复制” * 注意：添加操作多时，效率低，因为每次添加时都会进行复制，开销非常大。并发迭代多时可以选择。 * @author zhuwq * @create 2020-12-05 13:58 */public class TestCopyOnWriteArrayList &#123; public static void main(String[] args) &#123; HelloThread ht = new HelloThread(); for (int i = 0; i &lt; 10; i++) &#123; new Thread(ht).start(); &#125; &#125;&#125;class HelloThread implements Runnable&#123;// private static List&lt;String&gt; list = Collections.synchronizedList(new ArrayList&lt;String&gt;()); private static CopyOnWriteArrayList&lt;String&gt; list = new CopyOnWriteArrayList&lt;&gt;(); static&#123; list.add(\"AA\"); list.add(\"BB\"); list.add(\"CC\"); &#125; @Override public void run() &#123; Iterator&lt;String&gt; it = list.iterator(); while (it.hasNext())&#123; System.out.println(it.next()); list.add(\"DD\"); &#125; &#125;&#125; CountDownLatch闭锁 CountDownLatch是一个同步辅助类，在完成一组正在其他线程中执行的操作之前，它允许一个或多个线程一直等待。 闭锁可以延迟线程的进度直到其到达终止状态，闭锁可以用来确保某些活动直到其他活动都完成才继续执行： 确保某个计算在其需要的所有资源都被初始化之后才继续执行; 确保某个服务在其依赖的所有其他服务都已经启动之后才启动; 等待直到某个操作所有参与者都准备就绪再继续执行。 示例代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657package com.zwq;import java.util.concurrent.CountDownLatch;/** * TestCountDownLatch：闭锁，在完成某些运算时，只有其他所有线程的运算全部完成，当前运算才继续执行 * @author zhuwq * @create 2020-12-05 14:21 */public class TestCountDownLatch &#123; public static void main(String[] args) &#123; final CountDownLatch latch = new CountDownLatch(5); LatchDemo ld = new LatchDemo(latch); long start = System.currentTimeMillis(); for (int i = 0; i &lt; 5; i++) &#123; new Thread(ld).start(); &#125; try &#123; latch.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; long end = System.currentTimeMillis(); System.out.println(\"耗费时间为：\" + (end - start)); &#125;&#125;class LatchDemo implements Runnable&#123; private CountDownLatch latch; public LatchDemo(CountDownLatch latch)&#123; this.latch = latch; &#125; @Override public void run() &#123; synchronized (this)&#123; try&#123; for (int i = 0; i &lt; 50000; i++) &#123; if(i % 2 == 0)&#123; System.out.println(i); &#125; &#125; &#125;finally &#123; latch.countDown(); &#125; &#125; &#125;&#125; 实现Callable接口 Java 5.0 在 java.util.concurrent 提供了一个新的创建执行线程的方式：Callable 接口 Callable 接口类似于 Runnable，两者都是为那些其实例可能被另一个线程执行的类设计的。但是 Runnable 不会返回结果，并且无法抛出经过检查的异常。 Callable 需要依赖FutureTask ，FutureTask 也可以用作闭锁。 示例代码： 1234567891011121314151617181920212223242526272829303132333435363738394041package com.zwq;import java.util.concurrent.Callable;import java.util.concurrent.ExecutionException;import java.util.concurrent.FutureTask;/** * 一、创建执行线程的方式三：实现Callable接口。相较于实现Runnable接口的方式，方法可以有返回值，并且可以抛出异常。 * 二、执行Callable方式，需要FutureTask实现类的支持，用于接收运行结果。FutureTask是Future接口的实现类 * @author zhuwq * @create 2020-12-05 14:49 */public class TestCallable &#123; public static void main(String[] args) &#123; CallableDemo cd = new CallableDemo(); FutureTask&lt;Integer&gt; result = new FutureTask&lt;&gt;(cd); new Thread(result).start(); // 接收线程运算后的结果 try &#123; System.out.println(result.get());// FutureTask可用于闭锁 &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; catch (ExecutionException e) &#123; e.printStackTrace(); &#125; &#125;&#125;class CallableDemo implements Callable&lt;Integer&gt;&#123; @Override public Integer call() throws Exception &#123; int sum = 0; for (int i = 1; i &lt;= 100; i++) &#123; sum += i; &#125; return sum; &#125;&#125; Lock同步锁显式锁 Lock 在 Java 5.0 之前，协调共享对象的访问时可以使用的机制只有 synchronized 和 volatile 。Java 5.0 后增加了一些新的机制，但并不是一种替代内置锁的方法，而是当内置锁不适用时，作为一种可选择的高级功能。 ReentrantLock 实现了 Lock 接口，并提供了与synchronized 相同的互斥性和内存可见性。但相较于synchronized 提供了更高的处理锁的灵活性。 示例代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556package com.zwq;import java.util.concurrent.locks.Lock;import java.util.concurrent.locks.ReentrantLock;/** * 一、用于解决多线程安全问题的方式： * synchronized：隐式锁 * 1.同步代码块 * 2.同步方法 * * jdk1.5后： * 3.同步锁Lock * 注意：这是一个显式锁，需要通过lock()方法上锁，必须通过unlock()方法进行释放锁 * * @author zhuwq * @create 2020-12-05 15:13 */public class TestLock &#123; public static void main(String[] args) &#123; Ticket ticket = new Ticket(); new Thread(ticket, \"1号窗口\").start(); new Thread(ticket, \"2号窗口\").start(); new Thread(ticket, \"3号窗口\").start(); &#125;&#125;class Ticket implements Runnable&#123; private int tick = 100; private Lock lock = new ReentrantLock(); @Override public void run() &#123; while (true)&#123; lock.lock();// 上锁 try&#123; if(tick &gt; 0)&#123; try &#123; Thread.sleep(50); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName() + \" 完成售票，余票为：\" + --tick); &#125; &#125;finally &#123; lock.unlock(); &#125; &#125; &#125;&#125; 生产者消费案例-虚假唤醒实现生产者消费者案例的基础代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788package com.zwq;/** * 生产者与消费者案例 * @author zhuwq * @create 2020-12-12 16:11 */public class TestProductorAndConsumer &#123; public static void main(String[] args) &#123; Clerk clerk = new Clerk(); Productor pro = new Productor(clerk); Consumer cus = new Consumer(clerk); new Thread(pro, \"生产者1\").start(); new Thread(cus, \"消费者1\").start(); &#125;&#125;// 店员class Clerk&#123; private int product = 0; // 进货 public synchronized void get()&#123; if(product &gt;= 10)&#123; System.out.println(\"产品已满！\"); try &#123; this.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;else&#123; System.out.println(Thread.currentThread().getName() + \"：\" + ++product); this.notifyAll(); &#125; &#125; // 卖货 public synchronized void sale()&#123; if(product &lt;= 0)&#123; System.out.println(\"缺货！\"); try &#123; this.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;else&#123; System.out.println(Thread.currentThread().getName() + \"：\" + --product); this.notifyAll(); &#125; &#125;&#125;// 生产者class Productor implements Runnable&#123; private Clerk clerk; public Productor(Clerk clerk)&#123; this.clerk = clerk; &#125; @Override public void run() &#123; for (int i = 0; i &lt; 20; i++) &#123; clerk.get(); &#125; &#125;&#125;// 消费者class Consumer implements Runnable&#123; private Clerk clerk; public Consumer(Clerk clerk)&#123; this.clerk = clerk; &#125; @Override public void run() &#123; for (int i = 0; i &lt; 20; i++) &#123; clerk.sale(); &#125; &#125;&#125; 在这个代码基础上，做一点小改动：(1).生产者的线程任务每次循环休眠0.2秒，(2).将进货限制的上限改为1，(3).循环次数改成3，方便观察问题： 1234567891011121314151617181920212223242526272829303132333435363738394041424344// 店员class Clerk&#123; // 进货 public synchronized void get()&#123; if(product &gt;= 1)&#123; System.out.println(\"产品已满！\"); try &#123; this.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125;else&#123; System.out.println(Thread.currentThread().getName() + \"：\" + ++product); this.notifyAll(); &#125; &#125;&#125;// 生产者class Productor implements Runnable&#123; @Override public void run() &#123; for (int i = 0; i &lt; 3; i++) &#123; try &#123; Thread.sleep(200); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; clerk.get(); &#125; &#125;&#125;// 消费者class Consumer implements Runnable&#123; @Override public void run() &#123; for (int i = 0; i &lt; 3; i++) &#123; clerk.sale(); &#125; &#125;&#125; 运行结果如下，并且java进程一直还在没有自动关闭： 123456缺货！生产者1：1消费者1：0缺货！生产者1：1产品已满！ 问题原因分析如下： 123456缺货！// 由于生产者会睡眠0.2秒，所以是消费者会先抢到锁执行，但是由于product是0，触发了wait被阻塞，消费者的第一次循环被挂起生产者1：1// 过了睡眠的0.2秒，生产者执行get()，由于product是0，执行生产，此时product为1，并触发notifyAll消费者1：0// 由于被notifyAll触发，第一次循环的wait被唤醒，并且马上进入第二次循环，执行消费，此时product为0缺货！// 由于生产者有0.2秒的睡眠，消费者很快进入第三次循环，此时product是0，再次触发wait被阻塞生产者1：1// 过了睡眠的0.2秒，生产者执行get()，由于product是0，执行生产，此时product为1，并触发notifyAll；此时处于第三次循环的消费者wait被唤醒，没有其他操作，循环结束，消费者线程结束产品已满！// 生产者进入第三次循环，由于此时product为1，产品已满，触发wait，但是已经没有别的线程触发notify或者notifyAll，所以一直处于wait阻塞，java进程永远不会关闭 解决这个问题，只需要把get()和sale()的else都去掉： 12345678910111213141516171819202122232425262728293031323334// 店员class Clerk&#123; private int product = 0; // 进货 public synchronized void get()&#123; if(product &gt;= 1)&#123; System.out.println(\"产品已满！\"); try &#123; this.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; System.out.println(Thread.currentThread().getName() + \"：\" + ++product); this.notifyAll(); &#125; // 卖货 public synchronized void sale()&#123; if(product &lt;= 0)&#123; System.out.println(\"缺货！\"); try &#123; this.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; System.out.println(Thread.currentThread().getName() + \"：\" + --product); this.notifyAll(); &#125;&#125; 修改之后运行结果如下，java进程也正常结束了： 123456789缺货！生产者1：1消费者1：0缺货！生产者1：1消费者1：0缺货！生产者1：1消费者1：0 程序再修改一下，分别增加一个生产者和消费者： 1234567891011121314public class TestProductorAndConsumer &#123; public static void main(String[] args) &#123; Clerk clerk = new Clerk(); Productor pro = new Productor(clerk); Consumer cus = new Consumer(clerk); new Thread(pro, \"生产者1\").start(); new Thread(cus, \"消费者1\").start(); new Thread(pro, \"生产者2\").start(); new Thread(cus, \"消费者2\").start(); &#125;&#125; 运行结果如下，product出现了负数： 123456789101112131415161718缺货！缺货！生产者2：1消费者2：0缺货！消费者1：-1缺货！生产者1：0消费者1：-1缺货！消费者2：-2缺货！消费者1：-3消费者2：-4生产者2：-3生产者1：-2生产者2：-1生产者1：0 显然这里出现了线程安全问题，简单分析如下： 当2个消费者同时调用sale()时，由于目前product为0，则这2个消费者线程都wait阻塞了，过了0.2秒之后，生产了1个，product为1，然后notifyAll，这个时候就把之前阻塞的2个消费者线程都唤醒了，消费了2个，这时product已经出现负数-1，这个就是虚假唤醒问题。原因是因为使用的if判断，但是被唤醒之后条件已经发生变化，必须要重新判断条件！要解决虚假唤醒问题，wait应该总是使用在循环中。 将get()和sale()的if改为while： 12345678910111213141516171819202122232425262728293031323334// 店员class Clerk&#123; private int product = 0; // 进货 public synchronized void get()&#123; while(product &gt;= 1)&#123;// 为了避免虚假唤醒问题，wait应该总是在循环中使用 System.out.println(\"产品已满！\"); try &#123; this.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; System.out.println(Thread.currentThread().getName() + \"：\" + ++product); this.notifyAll(); &#125; // 卖货 public synchronized void sale()&#123; while(product &lt;= 0)&#123; System.out.println(\"缺货！\"); try &#123; this.wait(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; System.out.println(Thread.currentThread().getName() + \"：\" + --product); this.notifyAll(); &#125;&#125; 至此，虚假唤醒问题得以解决。 Condition控制线程通信 Condition 接口描述了可能会与锁有关联的条件变量。这些变量在用法上与使用 Object.wait 访问的隐式监视器类似，但提供了更强大的功能。需要特别指出的是，单个 Lock 可能与多个 Condition 对象关联。为了避免兼容性问题，Condition 方法的名称与对应的 Object 版本中的不同。 在 Condition 对象中，与 wait、notify 和 notifyAll 方法对应的分别是await、signal 和 signalAll。 Condition 实例实质上被绑定到一个锁上。要为特定 Lock 实例获得Condition 实例，请使用其 newCondition() 方法。 用Condition实现生产者消费者案例： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110package com.zwq;import java.util.concurrent.locks.Condition;import java.util.concurrent.locks.Lock;import java.util.concurrent.locks.ReentrantLock;/** * 生产者与消费者案例 * @author zhuwq * @create 2020-12-12 16:11 */public class TestProductorAndConsumerForLock &#123; public static void main(String[] args) &#123; Clerk clerk = new Clerk(); Productor pro = new Productor(clerk); Consumer cus = new Consumer(clerk); new Thread(pro, \"生产者1\").start(); new Thread(cus, \"消费者1\").start(); new Thread(pro, \"生产者2\").start(); new Thread(cus, \"消费者2\").start(); &#125;&#125;// 店员class Clerk&#123; private int product = 0; private Lock lock = new ReentrantLock(); private Condition condition = lock.newCondition(); // 进货 public void get()&#123; lock.lock(); try&#123; while(product &gt;= 1)&#123;// 为了避免虚假唤醒问题，wait应该总是在循环中使用 System.out.println(\"产品已满！\"); try &#123; condition.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; System.out.println(Thread.currentThread().getName() + \"：\" + ++product); condition.signalAll(); &#125;finally &#123; lock.unlock(); &#125; &#125; // 卖货 public void sale()&#123; lock.lock(); try&#123; while(product &lt;= 0)&#123; System.out.println(\"缺货！\"); try &#123; condition.await(); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; System.out.println(Thread.currentThread().getName() + \"：\" + --product); condition.signalAll(); &#125;finally &#123; lock.unlock(); &#125; &#125;&#125;// 生产者class Productor implements Runnable&#123; private Clerk clerk; public Productor(Clerk clerk)&#123; this.clerk = clerk; &#125; @Override public void run() &#123; for (int i = 0; i &lt; 3; i++) &#123; try &#123; Thread.sleep(200); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; clerk.get(); &#125; &#125;&#125;// 消费者class Consumer implements Runnable&#123; private Clerk clerk; public Consumer(Clerk clerk)&#123; this.clerk = clerk; &#125; @Override public void run() &#123; for (int i = 0; i &lt; 3; i++) &#123; clerk.sale(); &#125; &#125;&#125; 线程按序交替编写一个程序，开启 3 个线程，这三个线程的 ID 分别为A、B、C，每个线程将自己的 ID 在屏幕上打印 10 遍，要求输出的结果必须按顺序显示。如：ABCABCABC…… 依次递归 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125package com.zwq;import java.util.concurrent.locks.Condition;import java.util.concurrent.locks.Lock;import java.util.concurrent.locks.ReentrantLock;/** * 编写一个程序，开启 3 个线程，这三个线程的 ID 分别为A、B、C，每个线程将自己的 ID 在屏幕上打印 10 遍，要求输出的结果必须按顺序显示。 * 如：ABCABCABC…… 依次递归 * @author zhuwq * @create 2020-12-12 22:33 */public class TestABCAlternate &#123; public static void main(String[] args) &#123; final AlternateDemo ad = new AlternateDemo(); new Thread(new Runnable() &#123; @Override public void run() &#123; for (int i = 0; i &lt; 5; i++) &#123; ad.loopA(i); &#125; &#125; &#125;, \"A\").start(); new Thread(new Runnable() &#123; @Override public void run() &#123; for (int i = 0; i &lt; 5; i++) &#123; ad.loopB(i); &#125; &#125; &#125;, \"B\").start(); new Thread(new Runnable() &#123; @Override public void run() &#123; for (int i = 0; i &lt; 5; i++) &#123; ad.loopC(i); &#125; &#125; &#125;, \"C\").start(); &#125;&#125;class AlternateDemo&#123; private volatile int number = 1;// 当前正在执行线程的标记 private Lock lock = new ReentrantLock(); private Condition condition1 = lock.newCondition(); private Condition condition2 = lock.newCondition(); private Condition condition3 = lock.newCondition(); /** * @param totalLoop 循环第几轮 */ public void loopA(int totalLoop)&#123; lock.lock(); try&#123; // 1.判断 if(number != 1)&#123; condition1.await(); &#125; // 2.打印 System.out.println(Thread.currentThread().getName() + \"\\t\" + totalLoop); // 3.唤醒 number = 2; condition2.signal(); &#125;catch (Exception e)&#123; e.printStackTrace(); &#125;finally &#123; lock.unlock(); &#125; &#125; public void loopB(int totalLoop)&#123; lock.lock(); try&#123; // 1.判断 if(number != 2)&#123; condition2.await(); &#125; // 2.打印 System.out.println(Thread.currentThread().getName() + \"\\t\" + totalLoop); // 3.唤醒 number = 3; condition3.signal(); &#125;catch (Exception e)&#123; e.printStackTrace(); &#125;finally &#123; lock.unlock(); &#125; &#125; public void loopC(int totalLoop)&#123; lock.lock(); try&#123; // 1.判断 if(number != 3)&#123; condition3.await(); &#125; // 2.打印 System.out.println(Thread.currentThread().getName() + \"\\t\" + totalLoop); // 3.唤醒 number = 1; condition1.signal(); &#125;catch (Exception e)&#123; e.printStackTrace(); &#125;finally &#123; lock.unlock(); &#125; &#125;&#125; ReadWriteLock 读写锁 ReadWriteLock 维护了一对相关的锁，一个用于只读操作，另一个用于写入操作。只要没有 writer，读取锁可以由多个 reader 线程同时保持。写入锁是独占的。 ReadWriteLock 读取操作通常不会改变共享资源，但执行写入操作时，必须独占方式来获取锁。对于读取操作占多数的数据结构。 ReadWriteLock 能提供比独占锁更高的并发性。而对于只读的数据结构，其中包含的不变性可以完全不需要考虑加锁操作。 示例代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465package com.zwq;import java.util.concurrent.locks.ReadWriteLock;import java.util.concurrent.locks.ReentrantReadWriteLock;/** * 1. ReadWriteLock 读写锁 * 写写/读写 需要互斥 * 读读 不需要互斥 * * @author zhuwq * @create 2020-12-12 23:04 */public class TestReadWriteLock &#123; public static void main(String[] args) &#123; final ReadWriteLockDemo rw = new ReadWriteLockDemo(); new Thread(new Runnable() &#123; @Override public void run() &#123; rw.set((int)(Math.random() * 101)); &#125; &#125;, \"Write:\").start(); for (int i = 0; i &lt; 10; i++) &#123; new Thread(new Runnable() &#123; @Override public void run() &#123; rw.get(); &#125; &#125;).start(); &#125; &#125;&#125;class ReadWriteLockDemo&#123; private int number = 0; private ReadWriteLock lock = new ReentrantReadWriteLock(); // 读 public void get()&#123; lock.readLock().lock();// 上锁 try&#123; System.out.println(Thread.currentThread().getName() + \"：\" + number); &#125;finally &#123; lock.readLock().unlock();// 释放锁 &#125; &#125; // 写 public void set(int number)&#123; lock.writeLock().lock();// 上锁 try&#123; System.out.println(Thread.currentThread().getName()); this.number = number; &#125;finally &#123; lock.writeLock().unlock();// 释放锁 &#125; &#125;&#125; 线程池 第四种获取线程的方法：线程池，一个 ExecutorService，它使用可能的几个池线程之一执行每个提交的任务，通常使用 Executors 工厂方法配置。 线程池可以解决两个不同问题：由于减少了每个任务调用的开销，它们通常可以在执行大量异步任务时提供增强的性能，并且还可以提供绑定和管理资源（包括执行任务集时使用的线程）的方法。每个 ThreadPoolExecutor 还维护着一些基本的统计数据，如完成的任务数。 为了便于跨大量上下文使用，此类提供了很多可调整的参数和扩展钩子 (hook)。但是，强烈建议程序员使用较为方便的 Executors 工厂方法，它们均为大多数使用场景预定义了设置 ： Executors.newCachedThreadPool()（无界线程池，可以进行自动线程回收） Executors.newFixedThreadPool(int)（固定大小线程池） Executors.newSingleThreadExecutor()（单个后台线程） 线程池相关class关系图： 示例代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374package com.zwq;import java.util.ArrayList;import java.util.List;import java.util.concurrent.*;/** * 一、线程池：提供了一个线程队列，队列中保存着所有等待状态的线程。避免了创建与销毁额外开销，提高了响应的速度。 * * 二、线程池的体系结构： * java.util.concurrent.Executor：负责线程的使用和调度的根接口 * |--ExecutorService 子接口：线程池的主要接口 * |--ThreadPoolExecutor 线程池的实现类 * |--ScheduledExecutorService 子接口：负责线程的调度 * |--ScheduledThreadPoolExecutor：继承ThreadPoolExecutor，实现了ScheduledExecutorService * * 三、工具类：Executors * Executors.newFixedThreadPool(int)：创建固定大小的线程池 * Executors.newCachedThreadPool()：缓存线程池，线程池的数量不固定，可以根据需求自动更改数量 * Executors.newSingleThreadExecutor()：创建单个线程池，线程池中只有一个线程 * * Executors.newScheduledThreadPool()：创建固定大小的线程池，可以延时或定时地执行任务 * * @author zhuwq * @create 2020-12-12 23:26 */public class TestThreadPool &#123; public static void main(String[] args) throws ExecutionException, InterruptedException &#123; // 创建线程池 ExecutorService pool = Executors.newFixedThreadPool(5); ThreadPoolDemo tpd = new ThreadPoolDemo(); // 为线程池中的线程分配任务 /*for (int i = 0; i &lt; 10; i++) &#123; pool.submit(tpd); &#125;*/ List&lt;Future&lt;Integer&gt;&gt; list = new ArrayList&lt;&gt;(); for (int i = 0; i &lt; 10; i++) &#123; Future&lt;Integer&gt; future = pool.submit(new Callable&lt;Integer&gt;() &#123; @Override public Integer call() throws Exception &#123; int sum = 0; for (int i = 1; i &lt;= 100; i++) &#123; sum += i; &#125; return sum; &#125; &#125;); list.add(future); &#125; for (Future&lt;Integer&gt; future : list) &#123; System.out.println(future.get()); &#125; // 关闭线程池 pool.shutdown(); &#125;&#125;class ThreadPoolDemo implements Runnable&#123; private int i = 0; @Override public void run() &#123; while (i &lt;= 100)&#123; System.out.println(Thread.currentThread().getName() + \"：\" + i++); &#125; &#125;&#125; 线程调度ScheduledExecutorService：一个 ExecutorService，可安排在给定的延迟后运行或定期执行的命令。 示例代码： 12345678910111213141516171819202122232425262728293031package com.zwq;import java.util.Random;import java.util.concurrent.*;/** * @author zhuwq * @create 2020-12-13 0:32 */public class TestScheduledThreadPool &#123; public static void main(String[] args) throws ExecutionException, InterruptedException &#123; ScheduledExecutorService pool = Executors.newScheduledThreadPool(5); for (int i = 0; i &lt; 10; i++) &#123; ScheduledFuture&lt;Integer&gt; result = pool.schedule(new Callable&lt;Integer&gt;() &#123; @Override public Integer call() throws Exception &#123; int num = new Random().nextInt(100);// 生成随机数 System.out.println(Thread.currentThread().getName() + \"：\" + num); return num; &#125; &#125;, 1, TimeUnit.SECONDS); System.out.println(result.get()); &#125; pool.shutdown(); &#125;&#125; ForkJoinPool 分支/合并框架 工作窃取Fork/Join 框架 就是在必要的情况下，将一个大任务，进行拆分(fork)成若干个小任务（拆到不可再拆时），再将一个个的小任务运算的结果进行 join 汇总。 Fork/Join 框架与线程池的区别 采用 “工作窃取”模式（work-stealing）：当执行新的任务时它可以将其拆分分成更小的任务执行，并将小任务加到线程队列中，然后再从一个随机线程的队列中偷一个并把它放在自己的队列中。 相对于一般的线程池实现，fork/join框架的优势体现在对其中包含的任务的处理方式上。在一般的线程池中，如果一个线程正在执行的任务由于某些原因无法继续运行，那么该线程会处于等待状态。而在fork/join框架实现中，如果某个子问题由于等待另外一个子问题的完成而无法继续运行。那么处理该子问题的线程会主动寻找其他尚未运行的子问题来执行，这种方式减少了线程的等待时间，提高了性能。 示例代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758package com.zwq;import org.junit.Test;import java.util.concurrent.ForkJoinPool;import java.util.concurrent.ForkJoinTask;import java.util.concurrent.RecursiveTask;/** * @author zhuwq * @create 2020-12-13 10:41 */public class TestForkJoinPool &#123; public static void main(String[] args) &#123; ForkJoinPool pool = new ForkJoinPool(); ForkJoinTask task = new ForkJoinSumCalculate(0L, 100000000L); Long sum = (Long) pool.invoke(task); System.out.println(sum); &#125;&#125;class ForkJoinSumCalculate extends RecursiveTask&lt;Long&gt;&#123; private long start; private long end; private static final long THRESHOLD = 10000L;// 临界值 public ForkJoinSumCalculate(long start, long end)&#123; this.start = start; this.end = end; &#125; @Override protected Long compute() &#123; long length = end - start; if(length &lt;= THRESHOLD)&#123; long sum = 0L; for (long i = start; i &lt;= end; i++) &#123; sum += i; &#125; return sum; &#125;else&#123; long middle = (start + end) / 2; ForkJoinSumCalculate left = new ForkJoinSumCalculate(start, middle); left.fork();// 进行拆分，同时压入线程队列 ForkJoinSumCalculate right = new ForkJoinSumCalculate(middle + 1, end); right.fork(); return left.join() + right.join(); &#125; &#125;&#125;","tags":[{"name":"java","slug":"java","permalink":"https://sunshine-zwq.gitee.io/tags/java/"},{"name":"并发编程","slug":"并发编程","permalink":"https://sunshine-zwq.gitee.io/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"}]},{"title":"[转载]github、gitee同时配置ssh-key，并解决冲突","date":"2020-12-12T06:50:47.000Z","path":"2020/12/12/[转载]github、gitee同时配置ssh-key，并解决冲突/","text":"原文链接https://blog.csdn.net/daralisdan/article/details/100174369 正文一、首先进入用户目录（默认在c盘）打开 .ssh文件夹，在该文件夹下，右击鼠标，git -bash 进入git命令行 二、生成github、gitee的key，依次执行以下命令（输入自己的邮箱） 分别配置两个命令，在.ssh文件夹会生成创建各自的配置文件 12$ ssh-keygen -t rsa -C \"xxxxxxx@qq.com\" -f \"github_id_rsa\"$ ssh-keygen -t rsa -C \"xxxxxxx@qq.com\" -f \"gitee_id_rsa 完成后，.ssh文件夹生成以下文件 三、把public key添加到github和gitee的SSH公钥（即带有pub后缀的文本内容） 四、创建config文件解决ssh冲突在git命令行输入vi config 1$ vi config 回车添加如下配置： 1234567891011# githubHost github.comHostName github.comPreferredAuthentications publickeyIdentityFile ~&#x2F;.ssh&#x2F;github_id_rsa# giteeHost gitee.comHostName gitee.comPreferredAuthentications publickeyIdentityFile ~&#x2F;.ssh&#x2F;gitee_id_rsa 配置完成后，使用 :wq 保存退出编辑器 五、测试 1$ ssh -T git@github.com 成功则显示： 1Hi xxx! You've successfully authenticated, but GitHub does not provide shell access. 1$ ssh -T git@gitee.com 成功则显示： 1Hi xxx! You've successfully authenticated, but GITEE.COM does not provide shell access.","tags":[{"name":"git","slug":"git","permalink":"https://sunshine-zwq.gitee.io/tags/git/"},{"name":"gitee","slug":"gitee","permalink":"https://sunshine-zwq.gitee.io/tags/gitee/"},{"name":"github","slug":"github","permalink":"https://sunshine-zwq.gitee.io/tags/github/"}]},{"title":"Java并发编程：相关参考链接整理","date":"2020-12-12T05:37:59.000Z","path":"2020/12/12/Java并发编程：相关参考链接整理/","text":"面试相关Java并发编程面试题 Top 50 整理版","tags":[{"name":"java","slug":"java","permalink":"https://sunshine-zwq.gitee.io/tags/java/"},{"name":"并发编程","slug":"并发编程","permalink":"https://sunshine-zwq.gitee.io/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"}]},{"title":"双重校验锁实现的单例，已经使用了synchronized，为什么还需要volatile？","date":"2020-12-05T05:00:00.000Z","path":"2020/12/05/双重校验锁实现的单例，已经使用了synchronized，为什么还需要volatile？/","text":"问题双重校验锁实现的单例，已经使用了synchronized，为什么还需要volatile？ 1234567891011121314public class Singleton &#123; private volatile static Singleton singleton; private Singleton ()&#123;&#125; public static Singleton getSingleton() &#123; if (singleton == null) &#123; synchronized (Singleton.class) &#123; if (singleton == null) &#123; singleton = new Singleton(); &#125; &#125; &#125; return singleton; &#125; &#125; 原因解析synchronized 能保证临界区的原子性、有序性和可见性。volatile 也能保证所修饰对象的可见性，并且还能禁止重排序。 那么问题就来了：既然 volatile 的功能 synchronized基本都具备，那为啥还需要 volatile 修饰单例对象呢？ 答：new 操作不是原子操作，在 JVM 层面会导致重排序。synchronized关于有序性的准确解释：synchronized只能保证有序性却不能禁止重排序。 1234567891011121314151617181920public class Singleton &#123; private volatile static Singleton singleton; private Singleton ()&#123;&#125; public static Singleton getSingleton() &#123; if (singleton == null) &#123; // #1 synchronized (Singleton.class) &#123; if (singleton == null) &#123; singleton = new Singleton(); // #2 &#125; &#125; &#125; return singleton; &#125; &#125; // 当两个线程A和B同时进入方法时，加入A抢夺到锁，则A继续执行，当A执行到new操作时，由于new操作不是原子操作，且synchronized也不能禁止重排序，// 我们首先将new操作原子化：a-开辟内存空间；b-初始化对象；c-将引用赋值给变量// 正常的执行顺序应该是a-b-c，不禁止重排序的情况下可能是：a-c-b// 当线程A执行a-c，即将执行b的时候，由于cpu时间片结束，则有可能会让步给线程B，// 线程B进行第一次判断，singleton由于已经有了内存指向，并不为空，此时，对象还没有执行初始化，但已经判断为true，并且返回了。// 此时，就产生了严重的错误，因此需要 volatile 来禁止重排序。 既然synchronized无法禁止指令重排，那synchronized可以保证有序性怎么理解？ 答：这个有序性是相对语义来看的，线程与线程间，每一个 synchronized 块可以看成是一个原子操作，它保证每个时刻只有一个线程执行同步代码，相当于单线程，而单线程的指令重排是没有问题的。这就满足了as-if-serial语义的一个关键前提，那就是单线程，因为有as-if-serial语义保证，单线程的有序性就天然存在了。 参考链接https://www.cnblogs.com/melonman/p/13067678.html https://blog.csdn.net/chinaleesunnyboy/article/details/107530702 https://blog.csdn.net/qq_45401061/article/details/104415653","tags":[{"name":"java","slug":"java","permalink":"https://sunshine-zwq.gitee.io/tags/java/"},{"name":"并发编程","slug":"并发编程","permalink":"https://sunshine-zwq.gitee.io/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"},{"name":"面试","slug":"面试","permalink":"https://sunshine-zwq.gitee.io/tags/%E9%9D%A2%E8%AF%95/"}]},{"title":"[转载]Java并发编程：volatile的使用及其原理","date":"2020-12-04T16:01:00.000Z","path":"2020/12/05/[转载]Java并发编程：volatile的使用及其原理/","text":"原文链接https://www.cnblogs.com/paddix/p/5428507.html作者：liuxiaopeng博客地址：http://www.cnblogs.com/paddix/ 一、volatile的作用在《Java并发编程：核心理论》一文中，我们已经提到过可见性、有序性及原子性问题，通常情况下我们可以通过Synchronized关键字来解决这些个问题，不过如果对Synchronized原理有了解的话，应该知道Synchronized是一个比较重量级的操作，对系统的性能有比较大的影响，所以，如果有其他解决方案，我们通常都避免使用Synchronized来解决问题。而volatile关键字就是Java中提供的另一种解决可见性和有序性问题的方案。对于原子性，需要强调一点，也是大家容易误解的一点：对volatile变量的单次读/写操作可以保证原子性的，如long和double类型变量，但是并不能保证i++这种操作的原子性，因为本质上i++是读、写两次操作。 二、volatile的使用关于volatile的使用，我们可以通过几个例子来说明其使用方式和场景。 1、防止重排序我们从一个最经典的例子来分析重排序问题。大家应该都很熟悉单例模式的实现，而在并发环境下的单例实现方式，我们通常可以采用双重检查加锁（DCL）的方式来实现。其源码如下： 123456789101112131415161718192021package com.paddx.test.concurrent;public class Singleton &#123; public static volatile Singleton singleton; /** * 构造函数私有，禁止外部实例化 */ private Singleton() &#123;&#125;; public static Singleton getInstance() &#123; if (singleton == null) &#123; synchronized (singleton) &#123; if (singleton == null) &#123; singleton = new Singleton(); &#125; &#125; &#125; return singleton; &#125;&#125; 现在我们分析一下为什么要在变量singleton之间加上volatile关键字。要理解这个问题，先要了解对象的构造过程，实例化一个对象其实可以分为三个步骤： （1）分配内存空间。 （2）初始化对象。 （3）将内存空间的地址赋值给对应的引用。 但是由于操作系统可以对指令进行重排序，所以上面的过程也可能会变成如下过程： （1）分配内存空间。 （2）将内存空间的地址赋值给对应的引用。 （3）初始化对象 如果是这个流程，多线程环境下就可能将一个未初始化的对象引用暴露出来，从而导致不可预料的结果。因此，为了防止这个过程的重排序，我们需要将变量设置为volatile类型的变量。 2、实现可见性可见性问题主要指一个线程修改了共享变量值，而另一个线程却看不到。引起可见性问题的主要原因是每个线程拥有自己的一个高速缓存区——线程工作内存。volatile关键字能有效的解决这个问题，我们看下下面的例子，就可以知道其作用： 123456789101112131415161718192021222324252627282930313233343536373839404142434445package com.paddx.test.concurrent;public class VolatileTest &#123; int a = 1; int b = 2; public void change()&#123; a = 3; b = a; &#125; public void print()&#123; System.out.println(\"b=\"+b+\";a=\"+a); &#125; public static void main(String[] args) &#123; while (true)&#123; final VolatileTest test = new VolatileTest(); new Thread(new Runnable() &#123; @Override public void run() &#123; try &#123; Thread.sleep(10); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; test.change(); &#125; &#125;).start(); new Thread(new Runnable() &#123; @Override public void run() &#123; try &#123; Thread.sleep(10); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; test.print(); &#125; &#125;).start(); &#125; &#125;&#125; 直观上说，这段代码的结果只可能有两种：b=3;a=3 或 b=2;a=1。不过运行上面的代码（可能时间上要长一点），你会发现除了上两种结果之外，还出现了第三种结果： 1234567891011......b&#x3D;2;a&#x3D;1b&#x3D;2;a&#x3D;1b&#x3D;3;a&#x3D;3b&#x3D;3;a&#x3D;3b&#x3D;3;a&#x3D;1b&#x3D;3;a&#x3D;3b&#x3D;2;a&#x3D;1b&#x3D;3;a&#x3D;3b&#x3D;3;a&#x3D;3...... 为什么会出现b=3;a=1这种结果呢？正常情况下，如果先执行change方法，再执行print方法，输出结果应该为b=3;a=3。相反，如果先执行的print方法，再执行change方法，结果应该是 b=2;a=1。那b=3;a=1的结果是怎么出来的？原因就是第一个线程将值a=3修改后，但是对第二个线程是不可见的，所以才出现这一结果。如果将a和b都改成volatile类型的变量再执行，则再也不会出现b=3;a=1的结果了。 3、保证原子性关于原子性的问题，上面已经解释过。volatile只能保证对单次读/写的原子性。这个问题可以看下JLS中的描述： 123456789101117.7 Non-Atomic Treatment of double and longFor the purposes of the Java programming language memory model, a single write to a non-volatile long or double value is treated as two separate writes: one to each 32-bit half. This can result in a situation where a thread sees the first 32 bits of a 64-bit value from one write, and the second 32 bits from another write.Writes and reads of volatile long and double values are always atomic.Writes to and reads of references are always atomic, regardless of whether they are implemented as 32-bit or 64-bit values.Some implementations may find it convenient to divide a single write action on a 64-bit long or double value into two write actions on adjacent 32-bit values. For efficiency&#39;s sake, this behavior is implementation-specific; an implementation of the Java Virtual Machine is free to perform writes to long and double values atomically or in two parts.Implementations of the Java Virtual Machine are encouraged to avoid splitting 64-bit values where possible. Programmers are encouraged to declare shared 64-bit values as volatile or synchronize their programs correctly to avoid possible complications. 这段话的内容跟我前面的描述内容大致类似。因为long和double两种数据类型的操作可分为高32位和低32位两部分，因此普通的long或double类型读/写可能不是原子的。因此，鼓励大家将共享的long和double变量设置为volatile类型，这样能保证任何情况下对long和double的单次读/写操作都具有原子性。 关于volatile变量对原子性保证，有一个问题容易被误解。现在我们就通过下列程序来演示一下这个问题： 123456789101112131415161718192021222324252627282930package com.paddx.test.concurrent;public class VolatileTest01 &#123; volatile int i; public void addI()&#123; i++; &#125; public static void main(String[] args) throws InterruptedException &#123; final VolatileTest01 test01 = new VolatileTest01(); for (int n = 0; n &lt; 1000; n++) &#123; new Thread(new Runnable() &#123; @Override public void run() &#123; try &#123; Thread.sleep(10); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; test01.addI(); &#125; &#125;).start(); &#125; Thread.sleep(10000);//等待10秒，保证上面程序执行完成 System.out.println(test01.i); &#125;&#125; 大家可能会误认为对变量i加上关键字volatile后，这段程序就是线程安全的。大家可以尝试运行上面的程序。下面是我本地运行的结果： 可能每个人运行的结果不相同。不过应该能看出，volatile是无法保证原子性的（否则结果应该是1000）。原因也很简单，i++其实是一个复合操作，包括三步骤： （1）读取i的值。 （2）对i加1。 （3）将i的值写回内存。 volatile是无法保证这三个操作是具有原子性的，我们可以通过AtomicInteger或者Synchronized来保证+1操作的原子性。 注：上面几段代码中多处执行了Thread.sleep()方法，目的是为了增加并发问题的产生几率，无其他作用。 三、volatile的原理通过上面的例子，我们基本应该知道了volatile是什么以及怎么使用。现在我们再来看看volatile的底层是怎么实现的。 1、可见性实现在前文中已经提及过，线程本身并不直接与主内存进行数据的交互，而是通过线程的工作内存来完成相应的操作。这也是导致线程间数据不可见的本质原因。因此要实现volatile变量的可见性，直接从这方面入手即可。对volatile变量的写操作与普通变量的主要区别有两点： （1）修改volatile变量时会强制将修改后的值刷新的主内存中。 （2）修改volatile变量后会导致其他线程工作内存中对应的变量值失效。因此，再读取该变量值的时候就需要重新从读取主内存中的值。 通过这两个操作，就可以解决volatile变量的可见性问题。 2、有序性实现在解释这个问题前，我们先来了解一下Java中的happen-before规则，JSR 133中对Happen-before的定义如下： 1Two actions can be ordered by a happens-before relationship.If one action happens before another, then the first is visible to and ordered before the second. 通俗一点说就是如果a happen-before b，则a所做的任何操作对b是可见的。（这一点大家务必记住，因为happen-before这个词容易被误解为是时间的前后）。我们再来看看JSR 133中定义了哪些happen-before规则： 123456• Each action in a thread happens before every subsequent action in that thread.• An unlock on a monitor happens before every subsequent lock on that monitor.• A write to a volatile field happens before every subsequent read of that volatile.• A call to start() on a thread happens before any actions in the started thread.• All actions in a thread happen before any other thread successfully returns from a join() on that thread.• If an action a happens before an action b, and b happens before an action c, then a happens before c. 翻译过来为： 同一个线程中的，前面的操作 happen-before 后续的操作。（即单线程内按代码顺序执行。但是，在不影响在单线程环境执行结果的前提下，编译器和处理器可以进行重排序，这是合法的。换句话说，这一是规则无法保证编译重排和指令重排）。 监视器上的解锁操作 happen-before 其后续的加锁操作。（Synchronized 规则） 对volatile变量的写操作 happen-before 后续的读操作。（volatile 规则） 线程的start() 方法 happen-before 该线程所有的后续操作。（线程启动规则） 线程所有的操作 happen-before 其他线程在该线程上调用 join 返回成功后的操作。 如果 a happen-before b，b happen-before c，则a happen-before c（传递性）。 这里我们主要看下第三条：volatile变量的保证有序性的规则。《Java并发编程：核心理论》一文中提到过重排序分为编译器重排序和处理器重排序。为了实现volatile内存语义，JMM会对volatile变量限制这两种类型的重排序。下面是JMM针对volatile变量所规定的重排序规则表： 3、内存屏障为了实现volatile可见性和happen-befor的语义。JVM底层是通过一个叫做“内存屏障”的东西来完成。内存屏障，也叫做内存栅栏，是一组处理器指令，用于实现对内存操作的顺序限制。下面是完成上述规则所要求的内存屏障： （1）LoadLoad 屏障执行顺序：Load1—&gt;Loadload—&gt;Load2确保Load2及后续Load指令加载数据之前能访问到Load1加载的数据。 （2）StoreStore 屏障执行顺序：Store1—&gt;StoreStore—&gt;Store2确保Store2以及后续Store指令执行前，Store1操作的数据对其它处理器可见。 （3）LoadStore 屏障执行顺序： Load1—&gt;LoadStore—&gt;Store2确保Store2和后续Store指令执行前，可以访问到Load1加载的数据。 （4）StoreLoad 屏障执行顺序: Store1—&gt; StoreLoad—&gt;Load2确保Load2和后续的Load指令读取之前，Store1的数据对其他处理器是可见的。 最后我可以通过一个实例来说明一下JVM中是如何插入内存屏障的： 1234567891011121314151617181920212223242526272829package com.paddx.test.concurrent;public class MemoryBarrier &#123; int a, b; volatile int v, u; void f() &#123; int i, j; i = a; j = b; i = v; //LoadLoad j = u; //LoadStore a = i; b = j; //StoreStore v = i; //StoreStore u = j; //StoreLoad i = u; //LoadLoad //LoadStore j = b; a = i; &#125;&#125; 四、总结总体上来说volatile的理解还是比较困难的，如果不是特别理解，也不用急，完全理解需要一个过程，在后续的文章中也还会多次看到volatile的使用场景。这里暂且对volatile的基础知识和原来有一个基本的了解。总体来说，volatile是并发编程中的一种优化，在某些场景下可以代替Synchronized。但是，volatile不能完全取代Synchronized的位置，只有在一些特殊的场景下，才能适用volatile。总的来说，必须同时满足下面两个条件才能保证在并发环境的线程安全： （1）对变量的写操作不依赖于当前值。 （2）该变量没有包含在具有其他变量的不变式中。","tags":[{"name":"java","slug":"java","permalink":"https://sunshine-zwq.gitee.io/tags/java/"},{"name":"并发编程","slug":"并发编程","permalink":"https://sunshine-zwq.gitee.io/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"}]},{"title":"[转载]Java并发编程：线程间的协作(wait、notify、sleep、yield、join)","date":"2020-12-04T16:00:00.000Z","path":"2020/12/05/[转载]Java并发编程：线程间的协作(wait、notify、sleep、yield、join)/","text":"原文链接https://www.cnblogs.com/paddix/p/5381958.html作者：liuxiaopeng博客地址：http://www.cnblogs.com/paddix/ 一、线程的状态Java中线程中状态可分为五种：New（新建状态），Runnable（就绪状态），Running（运行状态），Blocked（阻塞状态），Dead（死亡状态）。 New：新建状态，当线程创建完成时为新建状态，即new Thread(…)，还没有调用start方法时，线程处于新建状态。 Runnable：就绪状态，当调用线程的的start方法后，线程进入就绪状态，等待CPU资源。处于就绪状态的线程由Java运行时系统的线程调度程序(thread scheduler)来调度。 Running：运行状态，就绪状态的线程获取到CPU执行权以后进入运行状态，开始执行run方法。 Blocked：阻塞状态，线程没有执行完，由于某种原因（如，I/O操作等）让出CPU执行权，自身进入阻塞状态。 Dead：死亡状态，线程执行完成或者执行过程中出现异常，线程就会进入死亡状态。 这五种状态之间的转换关系如下图所示： 有了对这五种状态的基本了解，现在我们来看看Java中是如何实现这几种状态的转换的。 二、wait/notify/notifyAll方法的使用1、wait方法 void wait() Causes the current thread to wait until another thread invokes the notify() method or the notifyAll() method for this object. void wait(long timeout) Causes the current thread to wait until either another thread invokes the notify() method or the notifyAll() method for this object, or a specified amount of time has elapsed. void wait(long timeout, int nanos) Causes the current thread to wait until another thread invokes the notify() method or the notifyAll() method for this object, or some other thread interrupts the current thread, or a certain amount of real time has elapsed. JDK中一共提供了这三个版本的方法， （1）wait()方法的作用是将当前运行的线程挂起（即让其进入阻塞状态），直到notify或notifyAll方法来唤醒线程. （2）wait(long timeout)，该方法与wait()方法类似，唯一的区别就是在指定时间内，如果没有notify或notifAll方法的唤醒，也会自动唤醒。 （3）至于wait(long timeout,long nanos)，本意在于更精确的控制调度时间，不过从目前版本来看，该方法貌似没有完整的实现该功能，其源码(JDK1.8)如下： 12345678910111213141516public final void wait(long timeout, int nanos) throws InterruptedException &#123; if (timeout &lt; 0) &#123; throw new IllegalArgumentException(\"timeout value is negative\"); &#125; if (nanos &lt; 0 || nanos &gt; 999999) &#123; throw new IllegalArgumentException( \"nanosecond timeout value out of range\"); &#125; if (nanos &gt;= 500000 || (nanos != 0 &amp;&amp; timeout == 0)) &#123; timeout++; &#125; wait(timeout); &#125; 从源码来看，JDK8中对纳秒的处理，只做了四舍五入，所以还是按照毫秒来处理的，可能在未来的某个时间点会用到纳秒级别的精度。虽然JDK提供了这三个版本，其实最后都是调用wait(long timeout)方法来实现的，wait()方法与wait(0)等效，而wait(long timeout,int nanos)从上面的源码可以看到也是通过wait(long timeout)来完成的。 下面我们通过一个简单的例子来演示wait()方法的使用： 123456789101112131415161718192021222324package com.paddx.test.concurrent;public class WaitTest &#123; public void testWait()&#123; System.out.println(\"Start-----\"); try &#123; wait(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(\"End-------\"); &#125; public static void main(String[] args) &#123; final WaitTest test = new WaitTest(); new Thread(new Runnable() &#123; @Override public void run() &#123; test.testWait(); &#125; &#125;).start(); &#125;&#125; 这段代码的意图很简单，就是程序执行以后，让其暂停一秒，然后再执行。运行上述代码，查看结果： 123456Start-----Exception in thread &quot;Thread-0&quot; java.lang.IllegalMonitorStateException at java.lang.Object.wait(Native Method) at com.paddx.test.concurrent.WaitTest.testWait(WaitTest.java:8) at com.paddx.test.concurrent.WaitTest$1.run(WaitTest.java:20) at java.lang.Thread.run(Thread.java:745) 这段程序并没有按我们的预期输出相应结果，而是抛出了一个异常。大家可能会觉得奇怪为什么会抛出异常？而抛出的IllegalMonitorStateException异常又是什么？我们可以看一下JDK中对IllegalMonitorStateException的描述： 1Thrown to indicate that a thread has attempted to wait on an object&#39;s monitor or to notify other threads waiting on an object&#39;s monitor without owning the specified monitor. 这句话的意思大概就是：线程试图等待对象的监视器或者试图通知其他正在等待对象监视器的线程，但本身没有对应的监视器的所有权。其实这个问题在《Java并发编程：Synchronized及其实现原理》一文中有提到过，wait方法是一个本地方法，其底层是通过一个叫做监视器锁的对象来完成的。所以上面之所以会抛出异常，是因为在调用wait方式时没有获取到monitor对象的所有权，那如何获取monitor对象所有权？Java中只能通过Synchronized关键字来完成，修改上述代码，增加Synchronized关键字： 123456789101112131415161718192021222324package com.paddx.test.concurrent;public class WaitTest &#123; public synchronized void testWait()&#123;//增加Synchronized关键字 System.out.println(\"Start-----\"); try &#123; wait(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(\"End-------\"); &#125; public static void main(String[] args) &#123; final WaitTest test = new WaitTest(); new Thread(new Runnable() &#123; @Override public void run() &#123; test.testWait(); &#125; &#125;).start(); &#125;&#125; 现在再运行上述代码，就能看到预期的效果了： 12Start-----End------- 所以，通过这个例子，大家应该很清楚，wait方法的使用必须在同步的范围内，否则就会抛出IllegalMonitorStateException异常，wait方法的作用就是阻塞当前线程等待notify/notifyAll方法的唤醒，或等待超时后自动唤醒。 2、notify/notifyAll方法 void notify() Wakes up a single thread that is waiting on this object’s monitor. void notifyAll() Wakes up all threads that are waiting on this object’s monitor. 有了对wait方法原理的理解，notify方法和notifyAll方法就很容易理解了。既然wait方式是通过对象的monitor对象来实现的，所以只要在同一对象上去调用notify/notifyAll方法，就可以唤醒对应对象monitor上等待的线程了。notify和notifyAll的区别在于前者只能唤醒monitor上的一个线程，对其他线程没有影响，而notifyAll则唤醒所有的线程，看下面的例子很容易理解这两者的差别： 1234567891011121314151617181920212223242526272829303132333435package com.paddx.test.concurrent;public class NotifyTest &#123; public synchronized void testWait()&#123; System.out.println(Thread.currentThread().getName() +\" Start-----\"); try &#123; wait(0); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName() +\" End-------\"); &#125; public static void main(String[] args) throws InterruptedException &#123; final NotifyTest test = new NotifyTest(); for(int i=0;i&lt;5;i++) &#123; new Thread(new Runnable() &#123; @Override public void run() &#123; test.testWait(); &#125; &#125;).start(); &#125; synchronized (test) &#123; test.notify(); &#125; Thread.sleep(3000); System.out.println(\"-----------分割线-------------\"); synchronized (test) &#123; test.notifyAll(); &#125; &#125;&#125; 输出结果如下： 1234567891011Thread-0 Start-----Thread-1 Start-----Thread-2 Start-----Thread-3 Start-----Thread-4 Start-----Thread-0 End------------------分割线-------------Thread-4 End-------Thread-3 End-------Thread-2 End-------Thread-1 End------- 从结果可以看出：调用notify方法时只有线程Thread-0被唤醒，但是调用notifyAll时，所有的线程都被唤醒了。 最后，有两点需要注意： （1）调用wait方法后，线程是会释放对monitor对象的所有权的。 （2）一个通过wait方法阻塞的线程，必须同时满足以下两个条件才能被真正执行： 线程需要被唤醒（超时唤醒或调用notify/notifyll）。 线程唤醒后需要竞争到锁（monitor）。 ​ 三、sleep/yield/join方法解析上面我们已经清楚了wait和notify方法的使用和原理，现在我们再来看另外一组线程间协作的方法。这组方法跟上面方法的最明显区别是：这几个方法都位于Thread类中，而上面三个方法都位于Object类中。至于为什么，大家可以先思考一下。现在我们逐个分析sleep/yield/join方法： 1、sleepsleep方法的作用是让当前线程暂停指定的时间（毫秒），sleep方法是最简单的方法，在上述的例子中也用到过，比较容易理解。唯一需要注意的是其与wait方法的区别。最简单的区别是，wait方法依赖于同步，而sleep方法可以直接调用。而更深层次的区别在于sleep方法只是暂时让出CPU的执行权，并不释放锁。而wait方法则需要释放锁。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758package com.paddx.test.concurrent;public class SleepTest &#123; public synchronized void sleepMethod()&#123; System.out.println(\"Sleep start-----\"); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(\"Sleep end-----\"); &#125; public synchronized void waitMethod()&#123; System.out.println(\"Wait start-----\"); synchronized (this)&#123; try &#123; wait(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; System.out.println(\"Wait end-----\"); &#125; public static void main(String[] args) &#123; final SleepTest test1 = new SleepTest(); for(int i = 0;i&lt;3;i++)&#123; new Thread(new Runnable() &#123; @Override public void run() &#123; test1.sleepMethod(); &#125; &#125;).start(); &#125; try &#123; Thread.sleep(10000);//暂停十秒，等上面程序执行完成 &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(\"-----分割线-----\"); final SleepTest test2 = new SleepTest(); for(int i = 0;i&lt;3;i++)&#123; new Thread(new Runnable() &#123; @Override public void run() &#123; test2.waitMethod(); &#125; &#125;).start(); &#125; &#125;&#125; 执行结果： 12345678910111213Sleep start-----Sleep end-----Sleep start-----Sleep end-----Sleep start-----Sleep end----------分割线-----Wait start-----Wait start-----Wait start-----Wait end-----Wait end-----Wait end----- 这个结果的区别很明显，通过sleep方法实现的暂停，程序是顺序进入同步块的，只有当上一个线程执行完成的时候，下一个线程才能进入同步方法，sleep暂停期间一直持有monitor对象锁，其他线程是不能进入的。而wait方法则不同，当调用wait方法后，当前线程会释放持有的monitor对象锁，因此，其他线程还可以进入到同步方法，线程被唤醒后，需要竞争锁，获取到锁之后再继续执行。 2、yield方法yield方法的作用是暂停当前线程，以便其他线程有机会执行，不过不能指定暂停的时间，并且也不能保证当前线程马上停止。yield方法只是将Running状态转变为Runnable状态。我们还是通过一个例子来演示其使用： 1234567891011121314151617181920212223242526package com.paddx.test.concurrent;public class YieldTest implements Runnable &#123; @Override public void run() &#123; try &#123; Thread.sleep(100); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; for(int i=0;i&lt;5;i++)&#123; System.out.println(Thread.currentThread().getName() + \": \" + i); Thread.yield(); &#125; &#125; public static void main(String[] args) &#123; YieldTest runn = new YieldTest(); Thread t1 = new Thread(runn,\"FirstThread\"); Thread t2 = new Thread(runn,\"SecondThread\"); t1.start(); t2.start(); &#125;&#125; 运行结果如下： 12345678910FirstThread: 0SecondThread: 0FirstThread: 1SecondThread: 1FirstThread: 2SecondThread: 2FirstThread: 3SecondThread: 3FirstThread: 4SecondThread: 4 这个例子就是通过yield方法来实现两个线程的交替执行。不过请注意：这种交替并不一定能得到保证，源码中也对这个问题进行说明： 1234567891011121314151617&#x2F;** * A hint to the scheduler that the current thread is willing to yield * its current use of a processor. The scheduler is free to ignore this * hint. * * &lt;p&gt; Yield is a heuristic attempt to improve relative progression * between threads that would otherwise over-utilise a CPU. Its use * should be combined with detailed profiling and benchmarking to * ensure that it actually has the desired effect. * * &lt;p&gt; It is rarely appropriate to use this method. It may be useful * for debugging or testing purposes, where it may help to reproduce * bugs due to race conditions. It may also be useful when designing * concurrency control constructs such as the ones in the * &#123;@link java.util.concurrent.locks&#125; package.*&#x2F; 这段话主要说明了三个问题： 调度器可能会忽略该方法。 使用的时候要仔细分析和测试，确保能达到预期的效果。 很少有场景要用到该方法，主要使用的地方是调试和测试。 ​ 3、join方法 void join() Waits for this thread to die. void join(long millis) Waits at most millis milliseconds for this thread to die. void join(long millis, int nanos) Waits at most millis milliseconds plus nanos nanoseconds for this thread to die. join方法的作用是父线程等待子线程执行完成后再执行，换句话说就是将异步执行的线程合并为同步的线程。JDK中提供三个版本的join方法，其实现与wait方法类似，join()方法实际上执行的join(0)，而join(long millis, int nanos)也与wait(long millis, int nanos)的实现方式一致，暂时对纳秒的支持也是不完整的。我们可以看下join方法的源码，这样更容易理解： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647public final void join() throws InterruptedException &#123; join(0); &#125; public final synchronized void join(long millis) throws InterruptedException &#123; long base = System.currentTimeMillis(); long now = 0; if (millis &lt; 0) &#123; throw new IllegalArgumentException(\"timeout value is negative\"); &#125; if (millis == 0) &#123; while (isAlive()) &#123; wait(0); &#125; &#125; else &#123; while (isAlive()) &#123; long delay = millis - now; if (delay &lt;= 0) &#123; break; &#125; wait(delay); now = System.currentTimeMillis() - base; &#125; &#125; &#125;public final synchronized void join(long millis, int nanos) throws InterruptedException &#123; if (millis &lt; 0) &#123; throw new IllegalArgumentException(\"timeout value is negative\"); &#125; if (nanos &lt; 0 || nanos &gt; 999999) &#123; throw new IllegalArgumentException( \"nanosecond timeout value out of range\"); &#125; if (nanos &gt;= 500000 || (nanos != 0 &amp;&amp; millis == 0)) &#123; millis++; &#125; join(millis); &#125; 大家重点关注一下join(long millis)方法的实现，可以看出join方法就是通过wait方法来将线程的阻塞，如果join的线程还在执行，则将当前线程阻塞起来，直到join的线程执行完成，当前线程才能执行。不过有一点需要注意，这里的join只调用了wait方法，却没有对应的notify方法，原因是Thread的start方法中做了相应的处理，所以当join的线程执行完成以后，会自动唤醒主线程继续往下执行。下面我们通过一个例子来演示join方法的作用： （1）不使用join方法： 123456789101112131415161718192021222324package com.paddx.test.concurrent;public class JoinTest implements Runnable&#123; @Override public void run() &#123; try &#123; System.out.println(Thread.currentThread().getName() + \" start-----\"); Thread.sleep(1000); System.out.println(Thread.currentThread().getName() + \" end------\"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; public static void main(String[] args) &#123; for (int i=0;i&lt;5;i++) &#123; Thread test = new Thread(new JoinTest()); test.start(); &#125; System.out.println(\"Finished~~~\"); &#125;&#125; 执行结果如下： 1234567891011Thread-0 start-----Thread-1 start-----Thread-2 start-----Thread-3 start-----Finished~~~Thread-4 start-----Thread-2 end------Thread-4 end------Thread-1 end------Thread-0 end------Thread-3 end------ （2）使用join方法： 1234567891011121314151617181920212223242526272829package com.paddx.test.concurrent;public class JoinTest implements Runnable&#123; @Override public void run() &#123; try &#123; System.out.println(Thread.currentThread().getName() + \" start-----\"); Thread.sleep(1000); System.out.println(Thread.currentThread().getName() + \" end------\"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; public static void main(String[] args) &#123; for (int i=0;i&lt;5;i++) &#123; Thread test = new Thread(new JoinTest()); test.start(); try &#123; test.join(); //调用join方法 &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; System.out.println(\"Finished~~~\"); &#125;&#125; 执行结果如下： 1234567891011Thread-0 start-----Thread-0 end------Thread-1 start-----Thread-1 end------Thread-2 start-----Thread-2 end------Thread-3 start-----Thread-3 end------Thread-4 start-----Thread-4 end------Finished~~~ 对比两段代码的执行结果很容易发现，在没有使用join方法之间，线程是并发执行的，而使用join方法后，所有线程是顺序执行的。 四、总结本文主要详细讲解了wait/notify/notifyAll和sleep/yield/join方法。最后回答一下上面提出的问题：wait/notify/notifyAll方法的作用是实现线程间的协作，那为什么这三个方法不是位于Thread类中，而是位于Object类中？位于Object中，也就相当于所有类都包含这三个方法（因为Java中所有的类都继承自Object类）。要回答这个问题，还是得回过来看wait方法的实现原理，大家需要明白的是，wait等待的到底是什么东西？如果对上面内容理解的比较好的话，我相信大家应该很容易知道wait等待其实是对象monitor，由于Java中的每一个对象都有一个内置的monitor对象，自然所有的类都理应有wait/notify方法。","tags":[{"name":"java","slug":"java","permalink":"https://sunshine-zwq.gitee.io/tags/java/"},{"name":"并发编程","slug":"并发编程","permalink":"https://sunshine-zwq.gitee.io/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"}]},{"title":"[转载]Java并发编程：Synchronized及其实现原理","date":"2020-12-01T16:01:00.000Z","path":"2020/12/02/[转载]Java并发编程：Synchronized及其实现原理/","text":"原文链接https://www.cnblogs.com/paddix/p/5367116.html作者：liuxiaopeng博客地址：http://www.cnblogs.com/paddix/ 一、Synchronized的基本使用Synchronized是Java中解决并发问题的一种最常用的方法，也是最简单的一种方法。Synchronized的作用主要有三个：（1）确保线程互斥的访问同步代码（2）保证共享变量的修改能够及时可见（3）有效解决重排序问题。从语法上讲，Synchronized总共有三种用法： （1）修饰普通方法 （2）修饰静态方法 （3）修饰代码块 接下来我就通过几个例子程序来说明一下这三种使用方式（为了便于比较，三段代码除了Synchronized的使用方式不同以外，其他基本保持一致）。 1、没有同步的情况： 代码段一： 12345678910111213141516171819202122232425262728293031323334353637383940414243package com.paddx.test.concurrent;public class SynchronizedTest &#123; public void method1()&#123; System.out.println(\"Method 1 start\"); try &#123; System.out.println(\"Method 1 execute\"); Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(\"Method 1 end\"); &#125; public void method2()&#123; System.out.println(\"Method 2 start\"); try &#123; System.out.println(\"Method 2 execute\"); Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(\"Method 2 end\"); &#125; public static void main(String[] args) &#123; final SynchronizedTest test = new SynchronizedTest(); new Thread(new Runnable() &#123; @Override public void run() &#123; test.method1(); &#125; &#125;).start(); new Thread(new Runnable() &#123; @Override public void run() &#123; test.method2(); &#125; &#125;).start(); &#125;&#125; 执行结果如下，线程1和线程2同时进入执行状态，线程2执行速度比线程1快，所以线程2先执行完成，这个过程中线程1和线程2是同时执行的。 123456Method 1 startMethod 1 executeMethod 2 startMethod 2 executeMethod 2 endMethod 1 end 2、对普通方法同步： 代码段二： 12345678910111213141516171819202122232425262728293031323334353637383940414243package com.paddx.test.concurrent;public class SynchronizedTest &#123; public synchronized void method1()&#123; System.out.println(\"Method 1 start\"); try &#123; System.out.println(\"Method 1 execute\"); Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(\"Method 1 end\"); &#125; public synchronized void method2()&#123; System.out.println(\"Method 2 start\"); try &#123; System.out.println(\"Method 2 execute\"); Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(\"Method 2 end\"); &#125; public static void main(String[] args) &#123; final SynchronizedTest test = new SynchronizedTest(); new Thread(new Runnable() &#123; @Override public void run() &#123; test.method1(); &#125; &#125;).start(); new Thread(new Runnable() &#123; @Override public void run() &#123; test.method2(); &#125; &#125;).start(); &#125;&#125; 执行结果如下，跟代码段一比较，可以很明显的看出，线程2需要等待线程1的method1执行完成才能开始执行method2方法。 123456Method 1 startMethod 1 executeMethod 1 endMethod 2 startMethod 2 executeMethod 2 end 3、静态方法（类）同步 代码段三： 1234567891011121314151617181920212223242526272829303132333435363738394041424344package com.paddx.test.concurrent; public class SynchronizedTest &#123; public static synchronized void method1()&#123; System.out.println(\"Method 1 start\"); try &#123; System.out.println(\"Method 1 execute\"); Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(\"Method 1 end\"); &#125; public static synchronized void method2()&#123; System.out.println(\"Method 2 start\"); try &#123; System.out.println(\"Method 2 execute\"); Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(\"Method 2 end\"); &#125; public static void main(String[] args) &#123; final SynchronizedTest test = new SynchronizedTest(); final SynchronizedTest test2 = new SynchronizedTest(); new Thread(new Runnable() &#123; @Override public void run() &#123; test.method1(); &#125; &#125;).start(); new Thread(new Runnable() &#123; @Override public void run() &#123; test2.method2(); &#125; &#125;).start(); &#125; &#125; 执行结果如下，对静态方法的同步本质上是对类的同步（静态方法本质上是属于类的方法，而不是对象上的方法），所以即使test和test2属于不同的对象，但是它们都属于SynchronizedTest类的实例，所以也只能顺序的执行method1和method2，不能并发执行。 123456Method 1 startMethod 1 executeMethod 1 endMethod 2 startMethod 2 executeMethod 2 end 4、代码块同步 代码段四： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647package com.paddx.test.concurrent;public class SynchronizedTest &#123; public void method1()&#123; System.out.println(\"Method 1 start\"); try &#123; synchronized (this) &#123; System.out.println(\"Method 1 execute\"); Thread.sleep(3000); &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(\"Method 1 end\"); &#125; public void method2()&#123; System.out.println(\"Method 2 start\"); try &#123; synchronized (this) &#123; System.out.println(\"Method 2 execute\"); Thread.sleep(1000); &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(\"Method 2 end\"); &#125; public static void main(String[] args) &#123; final SynchronizedTest test = new SynchronizedTest(); new Thread(new Runnable() &#123; @Override public void run() &#123; test.method1(); &#125; &#125;).start(); new Thread(new Runnable() &#123; @Override public void run() &#123; test.method2(); &#125; &#125;).start(); &#125;&#125; 执行结果如下，虽然线程1和线程2都进入了对应的方法开始执行，但是线程2在进入同步块之前，需要等待线程1中同步块执行完成。 123456Method 1 startMethod 1 executeMethod 2 startMethod 1 endMethod 2 executeMethod 2 end 二、Synchronized原理如果对上面的执行结果还有疑问，也先不用急，我们先来了解Synchronized的原理，再回头上面的问题就一目了然了。我们先通过反编译下面的代码来看看Synchronized是如何实现对代码块进行同步的： 123456789package com.paddx.test.concurrent;public class SynchronizedDemo &#123; public void method() &#123; synchronized (this) &#123; System.out.println(\"Method 1 start\"); &#125; &#125;&#125; 反编译结果： 关于这两条指令的作用，我们直接参考JVM规范中描述： monitorenter ： 1234Each object is associated with a monitor. A monitor is locked if and only if it has an owner. The thread that executes monitorenter attempts to gain ownership of the monitor associated with objectref, as follows:• If the entry count of the monitor associated with objectref is zero, the thread enters the monitor and sets its entry count to one. The thread is then the owner of the monitor.• If the thread already owns the monitor associated with objectref, it reenters the monitor, incrementing its entry count.• If another thread already owns the monitor associated with objectref, the thread blocks until the monitor&#39;s entry count is zero, then tries again to gain ownership. 这段话的大概意思为： 每个对象有一个监视器锁（monitor）。当monitor被占用时就会处于锁定状态，线程执行monitorenter指令时尝试获取monitor的所有权，过程如下： 1、如果monitor的进入数为0，则该线程进入monitor，然后将进入数设置为1，该线程即为monitor的所有者。 2、如果线程已经占有该monitor，只是重新进入，则进入monitor的进入数加1. 3、如果其他线程已经占用了monitor，则该线程进入阻塞状态，直到monitor的进入数为0，再重新尝试获取monitor的所有权。 monitorexit： 12The thread that executes monitorexit must be the owner of the monitor associated with the instance referenced by objectref.The thread decrements the entry count of the monitor associated with objectref. If as a result the value of the entry count is zero, the thread exits the monitor and is no longer its owner. Other threads that are blocking to enter the monitor are allowed to attempt to do so. 这段话的大概意思为： 执行monitorexit的线程必须是objectref所对应的monitor的所有者。 指令执行时，monitor的进入数减1，如果减1后进入数为0，那线程退出monitor，不再是这个monitor的所有者。其他被这个monitor阻塞的线程可以尝试去获取这个 monitor 的所有权。 通过这两段描述，我们应该能很清楚的看出Synchronized的实现原理，Synchronized的语义底层是通过一个monitor的对象来完成，其实wait/notify等方法也依赖于monitor对象，这就是为什么只有在同步的块或者方法中才能调用wait/notify等方法，否则会抛出java.lang.IllegalMonitorStateException的异常的原因。 我们再来看一下同步方法的反编译结果： 源代码： 1234567package com.paddx.test.concurrent;public class SynchronizedMethod &#123; public synchronized void method() &#123; System.out.println(&quot;Hello World!&quot;); &#125;&#125; 反编译结果： 从反编译的结果来看，方法的同步并没有通过指令monitorenter和monitorexit来完成（理论上其实也可以通过这两条指令来实现），不过相对于普通方法，其常量池中多了ACC_SYNCHRONIZED标示符。JVM就是根据该标示符来实现方法的同步的：当方法调用时，调用指令将会检查方法的 ACC_SYNCHRONIZED 访问标志是否被设置，如果设置了，执行线程将先获取monitor，获取成功之后才能执行方法体，方法执行完后再释放monitor。在方法执行期间，其他任何线程都无法再获得同一个monitor对象。其实本质上没有区别，只是方法的同步是一种隐式的方式来实现，无需通过字节码来完成。 三、运行结果解释有了对Synchronized原理的认识，再来看上面的程序就可以迎刃而解了。 1、代码段2结果： 虽然method1和method2是不同的方法，但是这两个方法都进行了同步，并且是通过同一个对象去调用的，所以调用之前都需要先去竞争同一个对象上的锁（monitor），也就只能互斥的获取到锁，因此，method1和method2只能顺序的执行。 2、代码段3结果： 虽然test和test2属于不同对象，但是test和test2属于同一个类的不同实例，由于method1和method2都属于静态同步方法，所以调用的时候需要获取同一个类上monitor（每个类只对应一个class对象），所以也只能顺序的执行。 3、代码段4结果： 对于代码块的同步实质上需要获取Synchronized关键字后面括号中对象的monitor，由于这段代码中括号的内容都是this，而method1和method2又是通过同一的对象去调用的，所以进入同步块之前需要去竞争同一个对象上的锁，因此只能顺序执行同步块。 四、总结Synchronized是Java并发编程中最常用的用于保证线程安全的方式，其使用相对也比较简单。但是如果能够深入了解其原理，对监视器锁等底层知识有所了解，一方面可以帮助我们正确的使用Synchronized关键字，另一方面也能够帮助我们更好的理解并发编程机制，有助我们在不同的情况下选择更优的并发策略来完成任务。对平时遇到的各种并发问题，也能够从容的应对。","tags":[{"name":"java","slug":"java","permalink":"https://sunshine-zwq.gitee.io/tags/java/"},{"name":"并发编程","slug":"并发编程","permalink":"https://sunshine-zwq.gitee.io/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"}]},{"title":"[转载]Java并发编程：核心理论","date":"2020-12-01T16:00:00.000Z","path":"2020/12/02/[转载]Java并发编程：核心理论/","text":"并发编程是Java程序员最重要的技能之一，也是最难掌握的一种技能。它要求编程者对计算机最底层的运作原理有深刻的理解，同时要求编程者逻辑清晰、思维缜密，这样才能写出高效、安全、可靠的多线程并发程序。本系列会从线程间协调的方式（wait、notify、notifyAll）、Synchronized及Volatile的本质入手，详细解释JDK为我们提供的每种并发工具和底层实现机制。在此基础上，我们会进一步分析java.util.concurrent包的工具类，包括其使用方式、实现源码及其背后的原理。本文是该系列的第一篇文章，是这系列中最核心的理论部分，之后的文章都会以此为基础来分析和解释。 原文链接https://www.cnblogs.com/paddix/p/5374810.html作者：liuxiaopeng博客地址：http://www.cnblogs.com/paddix/ 一、共享性数据共享性是线程安全的主要原因之一。如果所有的数据只是在线程内有效，那就不存在线程安全性问题，这也是我们在编程的时候经常不需要考虑线程安全的主要原因之一。但是，在多线程编程中，数据共享是不可避免的。最典型的场景是数据库中的数据，为了保证数据的一致性，我们通常需要共享同一个数据库中数据，即使是在主从的情况下，访问的也同一份数据，主从只是为了访问的效率和数据安全，而对同一份数据做的副本。我们现在，通过一个简单的示例来演示多线程下共享数据导致的问题： 代码段一： 1234567891011121314151617181920212223242526272829303132333435363738package com.paddx.test.concurrent; public class ShareData &#123; public static int count = 0; public static void main(String[] args) &#123; final ShareData data = new ShareData(); for (int i = 0; i &lt; 10; i++) &#123; new Thread(new Runnable() &#123; @Override public void run() &#123; try &#123; //进入的时候暂停1毫秒，增加并发问题出现的几率 Thread.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; for (int j = 0; j &lt; 100; j++) &#123; data.addCount(); &#125; System.out.print(count + \" \"); &#125; &#125;).start(); &#125; try &#123; //主程序暂停3秒，以保证上面的程序执行完成 Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(\"count=\" + count); &#125; public void addCount() &#123; count++; &#125;&#125; 上述代码的目的是对count进行加一操作，执行1000次，不过这里是通过10个线程来实现的，每个线程执行100次，正常情况下，应该输出1000。不过，如果你运行上面的程序，你会发现结果却不是这样。下面是某次的执行结果（每次运行的结果不一定相同，有时候也可能获取到正确的结果）： 可以看出，对共享变量操作，在多线程环境下很容易出现各种意想不到的的结果。 二、互斥性资源互斥是指同时只允许一个访问者对其进行访问，具有唯一性和排它性。我们通常允许多个线程同时对数据进行读操作，但同一时间内只允许一个线程对数据进行写操作。所以我们通常将锁分为共享锁和排它锁，也叫做读锁和写锁。如果资源不具有互斥性，即使是共享资源，我们也不需要担心线程安全。例如，对于不可变的数据共享，所有线程都只能对其进行读操作，所以不用考虑线程安全问题。但是对共享数据的写操作，一般就需要保证互斥性，上述例子中就是因为没有保证互斥性才导致数据的修改产生问题。 Java中提供多种机制来保证互斥性，最简单的方式是使用Synchronized。现在我们在上面程序中加上Synchronized再执行： 代码段二： 1234567891011121314151617181920212223242526272829303132333435363738394041package com.paddx.test.concurrent; public class ShareData &#123; public static int count = 0; public static void main(String[] args) &#123; final ShareData data = new ShareData(); for (int i = 0; i &lt; 10; i++) &#123; new Thread(new Runnable() &#123; @Override public void run() &#123; try &#123; //进入的时候暂停1毫秒，增加并发问题出现的几率 Thread.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; for (int j = 0; j &lt; 100; j++) &#123; data.addCount(); &#125; System.out.print(count + \" \"); &#125; &#125;).start(); &#125; try &#123; //主程序暂停3秒，以保证上面的程序执行完成 Thread.sleep(3000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(\"count=\" + count); &#125; /** * 增加 synchronized 关键字 */ public synchronized void addCount() &#123; count++; &#125;&#125; 现在再执行上述代码，会发现无论执行多少次，返回的最终结果都是1000。 三、原子性原子性就是指对数据的操作是一个独立的、不可分割的整体。换句话说，就是一次操作，是一个连续不可中断的过程，数据不会执行的一半的时候被其他线程所修改。保证原子性的最简单方式是操作系统指令，就是说如果一次操作对应一条操作系统指令，这样肯定可以能保证原子性。但是很多操作不能通过一条指令就完成。例如，对long类型的运算，很多系统就需要分成多条指令分别对高位和低位进行操作才能完成。还比如，我们经常使用的整数 i++ 的操作，其实需要分成三个步骤：（1）读取整数 i 的值；（2）对 i 进行加一操作；（3）将结果写回内存。这个过程在多线程下就可能出现如下现象： 这也是代码段一执行的结果为什么不正确的原因。对于这种组合操作，要保证原子性，最常见的方式是加锁，如Java中的Synchronized或Lock都可以实现，代码段二就是通过Synchronized实现的。除了锁以外，还有一种方式就是CAS（Compare And Swap），即修改数据之前先比较与之前读取到的值是否一致，如果一致，则进行修改，如果不一致则重新执行，这也是乐观锁的实现原理。不过CAS在某些场景下不一定有效，比如另一线程先修改了某个值，然后再改回原来值，这种情况下，CAS是无法判断的。 四、可见性要理解可见性，需要先对JVM的内存模型有一定的了解，JVM的内存模型与操作系统类似，如图所示： 从这个图中我们可以看出，每个线程都有一个自己的工作内存（相当于CPU高级缓冲区，这么做的目的还是在于进一步缩小存储系统与CPU之间速度的差异，提高性能），对于共享变量，线程每次读取的是工作内存中共享变量的副本，写入的时候也直接修改工作内存中副本的值，然后在某个时间点上再将工作内存与主内存中的值进行同步。这样导致的问题是，如果线程1对某个变量进行了修改，线程2却有可能看不到线程1对共享变量所做的修改。通过下面这段程序我们可以演示一下不可见的问题： 12345678910111213141516171819202122232425262728293031323334353637package com.paddx.test.concurrent; public class VisibilityTest &#123; private static boolean ready; private static int number; private static class ReaderThread extends Thread &#123; public void run() &#123; try &#123; Thread.sleep(10); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; if (!ready) &#123; System.out.println(ready); &#125; System.out.println(number); &#125; &#125; private static class WriterThread extends Thread &#123; public void run() &#123; try &#123; Thread.sleep(10); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; number = 100; ready = true; &#125; &#125; public static void main(String[] args) &#123; new WriterThread().start(); new ReaderThread().start(); &#125;&#125; 从直观上理解，这段程序应该只会输出100，ready的值是不会打印出来的。实际上，如果多次执行上面代码的话，可能会出现多种不同的结果，下面是我运行出来的某两次的结果： 当然，这个结果也只能说是有可能是可见性造成的，当写线程（WriterThread）设置ready=true后，读线程（ReaderThread）看不到修改后的结果，所以会打印false，对于第二个结果，也就是执行if(!ready)时还没有读取到写线程的结果，但执行System.out.println(ready)时读取到了写线程执行的结果。不过，这个结果也有可能是线程的交替执行所造成的。Java中可通过Synchronized或Volatile来保证可见性，具体细节会在后续的文章中分析。 五、有序性为了提高性能，编译器和处理器可能会对指令做重排序。重排序可以分为三种： （1）编译器优化的重排序。编译器在不改变单线程程序语义的前提下，可以重新安排语句的执行顺序。 （2）指令级并行的重排序。现代处理器采用了指令级并行技术（Instruction-Level Parallelism， ILP）来将多条指令重叠执行。如果不存在数据依赖性，处理器可以改变语句对应机器指令的执行顺序。（3）内存系统的重排序。由于处理器使用缓存和读/写缓冲区，这使得加载和存储操作看上去可能是在乱序执行。 我们可以直接参考一下JSR 133 中对重排序问题的描述： （1） （2） 先看上图中的（1）源码部分，从源码来看，要么指令 1 先执行要么指令 3先执行。如果指令 1 先执行，r2不应该能看到指令 4 中写入的值。如果指令 3 先执行，r1不应该能看到指令 2 写的值。但是运行结果却可能出现r2==2，r1==1的情况，这就是“重排序”导致的结果。上图（2）即是一种可能出现的合法的编译结果，编译后，指令1和指令2的顺序可能就互换了。因此，才会出现r2==2，r1==1的结果。Java中也可通过Synchronized或Volatile来保证顺序性。 六、总结本文对Java 并发编程中的理论基础进行了讲解，有些东西在后续的分析中还会做更详细的讨论，如可见性、顺序性等。后续的文章都会以本章内容作为理论基础来讨论。如果大家能够很好的理解上述内容，相信无论是去理解其他并发编程的文章还是在平时的并发编程的工作中，都能够对大家有很好的帮助。","tags":[{"name":"java","slug":"java","permalink":"https://sunshine-zwq.gitee.io/tags/java/"},{"name":"并发编程","slug":"并发编程","permalink":"https://sunshine-zwq.gitee.io/tags/%E5%B9%B6%E5%8F%91%E7%BC%96%E7%A8%8B/"}]},{"title":"element-ui的Tree树形控件触发指定节点点击处理","date":"2020-11-30T16:00:00.000Z","path":"2020/12/01/element-ui的Tree树形控件触发指定节点点击处理/","text":"项目需求有个多路搜索框（从服务器搜索），可支持同时根据关键字搜索科室和医生，页面左侧是科室树，右侧是医生列表表格，当选择关键字搜索结果的某个科室（可获取到科室id），需要触发选中左侧的科室节点，并查询出相应的科室所有医生信息。所以这个不适合直接采用element-ui的节点过滤搜索框来过滤节点，而element-ui也没有直接根据tree节点值触发节点点击的事件，所以需要额外写代码来实现这个交互效果。 效果图 主要实现代码123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113&lt;template&gt; &lt;el-select class=\"searchInput\" v-model=\"selectedSearchItem\" filterable remote reserve-keyword size=\"mini\" placeholder=\"搜索成员或科室\" :remote-method=\"queryDeptOrDoctor\" @change=\"selectSearchItem\" :loading=\"searchLoading\"&gt; &lt;el-option-group v-for=\"group in searchOptionGroups\" :key=\"group.name\" :label=\"group.name\"&gt; &lt;el-option v-for=\"item in group.options\" :key=\"item.id\" :label=\"item.name\" :value=\"item.id\"&gt; &lt;/el-option&gt; &lt;/el-option-group&gt; &lt;/el-select&gt; &lt;el-tree class=\"deptTreeCntr\" ref=\"deptTree\" :data=\"treeData\" :props=\"treeProps\" node-key=\"id\" :default-expanded-keys=\"['0']\" :expand-on-click-node=\"false\" @node-click=\"handleTreeNodeClick\"&gt; &lt;/el-tree&gt;&lt;/template&gt;&lt;script&gt; export default &#123; data () &#123; return &#123; selectedSearchItem: '', searchLoading: false, searchOptionGroups: [], treeData: [], treeProps: &#123; value: 'id', children: 'children', label: 'title' &#125;, &#125; &#125;, methods: &#123; // 根据关键字搜索科室或医生 queryDeptOrDoctor(keyword)&#123; this.searchOptionGroups = []; if(keyword == '')&#123; return; &#125; this.searchLoading = true; // 发起服务器查询，并组装this.searchOptionGroups数据 // ... this.searchLoading = false; &#125;, // 多路搜索框选择了搜索的item处理 selectSearchItem(selectedVal)&#123; // selectedVal的前缀用于区分是科室还是医生，科室是“dept-”开头，医生是“doct-”开头 let type = selectedVal.substring(0, 4); // 截取实际的科室id或者医生id let val = selectedVal.substring(5); if(type == 'dept') &#123;// 科室 // 设置当前选中key this.$refs.deptTree.setCurrentKey(val); // 根据el-tree的getNode方法获取到val相应的Node let node = this.$refs.deptTree.getNode(val); // 触发点击处理（由于elem参数没用到，所以这里忽略不传） this.handleTreeNodeClick(node.data, node); // 除了选中相应的科室节点及触发查询，还有件事要做：就是有可能这个节点处于树比较深的位置，那应该把这个节点的所有父节点都展开（默认不展开） // 获取自身及所有父节点的id let selfAndParentIdArr = this.findTreeParentDataAttr(node, 'id'); if(selfAndParentIdArr.length &gt; 1)&#123; // 这里只展开所有父节点，当前节点不处理 for(let i = 0; i &lt; selfAndParentIdArr.length - 1; i++)&#123; // 这里通过设置节点数据的expanded属性来展开指定节点 this.$refs.deptTree.store.nodesMap[selfAndParentIdArr[i]].expanded = true; &#125; &#125; &#125;else if(type == 'doct') &#123;// 医生 // 触发查询指定医生的处理... &#125; &#125;, // 点击树节点事件处理 handleTreeNodeClick(data, node, elem)&#123; // data.id即为科室id，根据这个科室id触发医生表格数据的查询... &#125;, // 递归找出选择科室及所有上级科室的data指定属性（如title、id） findTreeParentDataAttr(node, attrName, parentNameArr)&#123; if(!parentNameArr)&#123; parentNameArr = []; &#125; // 因为是一层一层往上找，这里把父节点放最前面 parentNameArr.unshift(node.data[attrName]); if(node.data.id == '0')&#123;// 根节点 &#125;else&#123; this.findTreeParentDataAttr(node.parent, attrName, parentNameArr); &#125; // 返回找到的所有节点名称 return parentNameArr; &#125; &#125; &#125;&lt;/script&gt; 一些属性、方法说明el-tree： data =》 tree的展示数据，类型：array，需要在后端封装好 props =》 配置选项，类型：object。这个主要用于匹配tree相应节点属性和后端返回数据的属性 label：指定节点标签（即显示的节点文本）为节点对象的某个属性值 children：指定子树为节点对象的某个属性值 node-key =》 每个树节点用来作为唯一标识的属性，整棵树应该是唯一的 default-expanded-keys =》 默认展开的节点的 key 的数组，由于科室树都有个默认的根节点id为0，所以这里会默认展开根节点下的一级节点 expand-on-click-node =》 是否在点击节点的时候展开或者收缩节点， 默认值为 true，如果为 false，则只有点箭头图标的时候才会展开或者收缩节点。 node-click =》 节点被点击时的回调。共三个参数，依次为：传递给 data 属性的数组中该节点所对应的对象、节点对应的 Node、节点组件本身。 setCurrentKey =》 通过 key 设置某个节点的当前选中状态，使用此方法必须设置 node-key 属性 getNode =》 根据 data 或者 key 拿到 Tree 组件中的 node","tags":[{"name":"vue","slug":"vue","permalink":"https://sunshine-zwq.gitee.io/tags/vue/"},{"name":"element-ui","slug":"element-ui","permalink":"https://sunshine-zwq.gitee.io/tags/element-ui/"}]},{"title":"正则表达式","date":"2020-11-24T16:00:00.000Z","path":"2020/11/25/正则表达式/","text":"简介 正则表达式，用来匹配一系列符合某个规则的字符串的表达式。正则的意思是正规、规则。正则表达式的英文名是 Regular Expression，可以直译为描述某种规则的表达式，一般缩写为 regex。 语法正则表达式的便利之处示例（校验手机号码）： 未使用正则表达式的代码： 123456789public static boolean isValidPhoneNumber(String number) &#123; // 判断是否是 11 位 if (number.length() != 11) return false; // 判断每一位是否全为数字 for (int i = 0; i &lt; number.length(); i++) &#123; if (number.charAt(i) &lt; '0' || number.charAt(i) &gt; '9') return false; &#125; return true;&#125; 使用正则表达式的代码： 123public static boolean isValidPhoneNumber(String number) &#123; return number.matches(\"\\\\d&#123;11&#125;\");&#125; 精确匹配 一个普通的字符串，比如 abc，它如果用来做正则表达式匹配的话，只能匹配自己。也就是说它只能匹配字符串 abc，不能匹配 ab，Abc 等其他任何字符串。 示例代码： 123System.out.println(\"abc\".matches(\"abc\")); // 输出为 trueSystem.out.println(\"ab\".matches(\"abc\")); // 输出为 falseSystem.out.println(\"Abc\".matches(\"abc\")); // 输出为 false 特殊字符 如果需要匹配的字符串含有特殊字符，那就需要用 \\转义。比如 a&amp;b，在用正则表达式匹配时，需要使用 a\\&amp;b，又由于在 Java 字符串中，\\ 也是特殊字符，它也需要转义，所以 a\\&amp;b 对应的 Java 字符串是 a\\\\&amp;b，它是用来匹配 a&amp;b 的。 示例代码： 1System.out.println(\"a&amp;b\".matches(\"a\\\\&amp;b\")); // 输出为 true 数字、字符、空格 \\d：d 是 digital 的简写，在正则表达式中表示匹配任意数字。 \\w：w 是 word 的简写，表示匹配一个常用字符，包括字母、数字、下划线。 \\s：s 是 space 的简写，表示匹配一个空格，包括三种：空格键打出来的空格、Tab 键打出来的空格、回车键打出来的空格 示例代码： 1234567System.out.println(\"1\".matches(\"\\\\d\\\\d\")); // 输出为 falseSystem.out.println(\"11\".matches(\"\\\\d\\\\d\")); // 输出为 trueSystem.out.println(\"111\".matches(\"\\\\d\\\\d\")); // 输出为 falseSystem.out.println(\"LeetCode_666\".matches(\"\\\\w&#123;12&#125;\")); // 输出为 trueSystem.out.println(\"\\t \\n\".matches(\"\\\\s&#123;3&#125;\")); // 输出为 trueSystem.out.println(\"Leet\\tCode 666\".matches(\"\\\\w&#123;4&#125;\\\\s\\\\w&#123;4&#125;\\\\s\\\\d&#123;3&#125;\")); // 输出为 true 相反 将字母换成大写，就表示相反的意思。用 \\d 你可以匹配一个数字，\\D 则表示匹配一个非数字。 示例代码： 12345System.out.println(\"a\".matches(\"\\\\d\")); // 输出为 falseSystem.out.println(\"1\".matches(\"\\\\d\")); // 输出为 trueSystem.out.println(\"a\".matches(\"\\\\D\")); // 输出为 trueSystem.out.println(\"1\".matches(\"\\\\D\")); // 输出为 false 匹配次数 . ：匹配任意字符； * ：匹配任意次，包括 0 次； + ：匹配至少 1 次； ? ：匹配 0 次或 1 次； {}：指定次数，{n} 表示匹配 n 次， {n,m} 表示匹配 n ~ m 次，{n,} 表示匹配至少n次，{0,m} 表示匹配最多m次 示例代码： 1234567891011121314151617181920System.out.println(\"a0b\".matches(\"a.b\")); // 输出为 trueSystem.out.println(\"a_b\".matches(\"a.b\")); // 输出为 trueSystem.out.println(\"a b\".matches(\"a.b\")); // 输出为 trueSystem.out.println(\"1\".matches(\"\\\\d*\")); // 输出为 trueSystem.out.println(\"123\".matches(\"\\\\d*\")); // 输出为 trueSystem.out.println(\"\".matches(\"\\\\d*\")); // 输出为 trueSystem.out.println(\"1\".matches(\"\\\\d+\")); // 输出为 trueSystem.out.println(\"123\".matches(\"\\\\d+\")); // 输出为 trueSystem.out.println(\"\".matches(\"\\\\d+\")); // 输出为 falseSystem.out.println(\"\".matches(\"\\\\d?\")); // 输出为 trueSystem.out.println(\"1\".matches(\"\\\\d?\")); // 输出为 trueSystem.out.println(\"123\".matches(\"\\\\d?\")); // 输出为 falseSystem.out.println(\"1\".matches(\"\\\\d&#123;1,2&#125;\")); // 输出为 trueSystem.out.println(\"12\".matches(\"\\\\d&#123;1,2&#125;\")); // 输出为 trueSystem.out.println(\"123\".matches(\"\\\\d&#123;1,2&#125;\")); // 输出为 falseSystem.out.println(\"123\".matches(\"\\\\d&#123;2,&#125;\")); // 输出为 true 指定范围 [] 用于匹配指定范围内的字符，比如[123456789] 可以匹配 19，也可以写作 [1-9]。[a-g] 表示 [abcdefg]，[U-Z] 表示 [UVWXYZ]。[1-9a-gU-Z] 表示既可以是数字 19，又可以是字母 ag，还可以是字母 UZ。 或 运算符：正则的 或 运算符是 |，[0189] 也可以写作 0|1|8|9。 [] 取反的方式是：[^]，比如不能是 [123] 的表示方法为 [^123] 或者 [^1-3] 示例代码： 1234567891011121314System.out.println(\"1\".matches(\"[1-9a-gU-Z]\")); // 输出为 trueSystem.out.println(\"b\".matches(\"[1-9a-gU-Z]\")); // 输出为 trueSystem.out.println(\"X\".matches(\"[1-9a-gU-Z]\")); // 输出为 trueSystem.out.println(\"A\".matches(\"[1-9a-gU-Z]\")); // 输出为 falseSystem.out.println(\"1\".matches(\"[0-18-9]\")); // 输出为 true，由于正则一次只匹配一个字符，所以这样写并不会有歧义，也就是说计算机不会把这种写法误解成要匹配 0~18 之类的。System.out.println(\"5\".matches(\"[0-18-9]\")); // 输出为 falseSystem.out.println(\"1\".matches(\"0|1|8|9\")); // 输出为 trueSystem.out.println(\"5\".matches(\"0|1|8|9\")); // 输出为 falseSystem.out.println(\"abc\".matches(\"abc|ABC\")); // 输出为 trueSystem.out.println(\"ABC\".matches(\"abc|ABC\")); // 输出为 trueSystem.out.println(\"123\".matches(\"abc|ABC\")); // 输出为 false 匹配取值考虑一个实际需求，有许许多多以下格式的字符串，你需要用正则表达式匹配出其姓名和年龄。 Name：Aurora Age：18 其中还夹杂着一些无关紧要的数据 Name：Bob Age：20 错误的数据有着各种各样错误的格式 Name：Cassin Age：22 … 示例代码： 12345System.out.println(\"Name:Aurora Age:18\".matches(\"Name:\\\\w+\\\\s*Age:\\\\d&#123;1,3&#125;\")); // 输出为 trueSystem.out.println(\"其中还夹杂着一些无关紧要的数据\".matches(\"Name:\\\\w+\\\\s*Age:\\\\d&#123;1,3&#125;\")); // 输出为 falseSystem.out.println(\"Name:Bob Age:20\".matches(\"Name:\\\\w+\\\\s*Age:\\\\d&#123;1,3&#125;\")); // 输出为 trueSystem.out.println(\"错误的数据有着各种各样错误的格式\".matches(\"Name:\\\\w+\\\\s*Age:\\\\d&#123;1,3&#125;\")); // 输出为 falseSystem.out.println(\"Name:Cassin Age:22\".matches(\"Name:\\\\w+\\\\s*Age:\\\\d&#123;1,3&#125;\")); // 输出为 true 下一步，取出这些表达式中的姓名和年龄。 示例代码： 12345678910Pattern pattern = Pattern.compile(\"Name:(\\\\w+)\\\\s*Age:(\\\\d&#123;1,3&#125;)\");Matcher matcher = pattern.matcher(\"Name:Aurora Age:18\");if(matcher.matches()) &#123; // group(0) 被用来保存整个匹配的字符串了，所以从1开始 String group1 = matcher.group(1); String group2 = matcher.group(2); System.out.println(matcher.group(0)); // 输出为 Name:Aurora Age:18 System.out.println(group1); // 输出为 Aurora System.out.println(group2); // 输出为 18&#125; tips：每次调用 String.matches 函数，都会新建出一个 Pattern 对象。所以如果要用同一个正则表达式多次匹配字符串的话，最佳的做法不是直接调用 String.matches 方法，而应该先用正则表达式新建一个 Pattern 对象，然后反复使用，以提高程序运行效率。 示例代码： 12345678910111213// 错误的做法，每次都会新建一个 Pattern，效率低boolean result1 = \"Name:Aurora Age:18\".matches(\"Name:(\\\\w+)\\\\s*Age:(\\\\d&#123;1,3&#125;)\"); boolean result2 = \"Name:Bob Age:20\".matches(\"Name:(\\\\w+)\\\\s*Age:(\\\\d&#123;1,3&#125;)\");boolean result3 = \"Name:Cassin Age:22\".matches(\"Name:(\\\\w+)\\\\s*Age:(\\\\d&#123;1,3&#125;)\"); // 正确的做法，复用同一个 Pattern，效率高Pattern pattern = Pattern.compile(\"Name:(\\\\w+)\\\\s*Age:(\\\\d&#123;1,3&#125;)\");boolean result4 = pattern.matcher(\"Name:Aurora Age:18\").matches();boolean result5 = pattern.matcher(\"Name:Bob Age:20\").matches();boolean result6 = pattern.matcher(\"Name:Cassin Age:22\").matches(); 贪婪匹配和非贪婪匹配给出一些字符串，统计其末尾 e 的个数 LeetCode LeetCodeeee LeetCodeee 错误示例： 12345678Pattern pattern = Pattern.compile(\"(\\\\w+)(e*)\");Matcher matcher = pattern.matcher(\"LeetCode\");if (matcher.matches()) &#123; String group1 = matcher.group(1); String group2 = matcher.group(2); System.out.println(\"group1 = \" + group1 + \", length = \" + group1.length()); System.out.println(\"group2 = \" + group2 + \", length = \" + group2.length());&#125; 输出结果： 12group1 &#x3D; LeetCode, length &#x3D; 8group2 &#x3D; , length &#x3D; 0 这是因为 e 仍然属于 \\w 能匹配的范畴，正则表达式默认会尽可能多地向后匹配，这个称为 贪婪匹配。与之对应的匹配方式叫做 非贪婪匹配，非贪婪匹配 会在能匹配目标字符串的前提下，尽可能少的向后匹配。在需要非贪婪匹配的正则表达式后面加个 ? 即可表示非贪婪匹配。 正确示例： 12345678Pattern pattern = Pattern.compile(\"(\\\\w+?)(e*)\");Matcher matcher = pattern.matcher(\"LeetCode\");if (matcher.matches()) &#123; String group1 = matcher.group(1); String group2 = matcher.group(2); System.out.println(\"group1 = \" + group1 + \", length = \" + group1.length()); System.out.println(\"group2 = \" + group2 + \", length = \" + group2.length());&#125; 输出结果： 12group1 &#x3D; LeetCod, length &#x3D; 7group2 &#x3D; e, length &#x3D; 1 java中的一些应用split split 函数传入的参数实际上是一个正则表达式 一个实际场景：你有一个让用户输入标签的输入框，用户可以输入多个标签。可是你并没有提示用户，标签之前用什么间隔符号隔开。用户的输入五花八门，有用逗号的，有用分号的，有用空格的，还有用制表符的…… 二分，回溯，递归，分治 搜索；查找；旋转；遍历 数论 图论 逻辑 概率 示例代码（未使用正则表达式）： 123456789101112public static String[] splitTabs(String tabs) &#123; if(tabs.split(\",\").length == 4) return tabs.split(\",\"); if(tabs.split(\";\").length == 4) return tabs.split(\";\"); if(tabs.split(\" \").length == 4) return tabs.split(\" \"); return new String[0];&#125;public static void main(final String[] args)&#123; System.out.println(Arrays.toString(splitTabs(\"二分,回溯,递归,分治\"))); System.out.println(Arrays.toString(splitTabs(\"搜索;查找;旋转;遍历\"))); System.out.println(Arrays.toString(splitTabs(\"数论 图论 逻辑 概率\")));&#125; 输出为： 123[二分, 回溯, 递归, 分治][搜索, 查找, 旋转, 遍历][数论, 图论, 逻辑, 概率] 示例代码（使用正则表达式）： 123System.out.println(Arrays.toString(\"二分,回溯,递归,分治\".split(\"[,;\\\\s]\")));System.out.println(Arrays.toString(\"搜索;查找;旋转;遍历\".split(\"[,;\\\\s]\")));System.out.println(Arrays.toString(\"数论 图论 逻辑 概率\".split(\"[,;\\\\s]\"))); 输出为： 123[二分, 回溯, 递归, 分治][搜索, 查找, 旋转, 遍历][数论, 图论, 逻辑, 概率] replaceAll上面这个例子，我们可以把用户输入的所有数据统一规范为使用 ; 分隔，那我们就可以这样写。 示例代码： 123System.out.println(\"二分,回溯,递归,分治\".replaceAll(\"[,;\\\\s]+\", \";\"));System.out.println(\"搜索;查找;旋转;遍历\".replaceAll(\"[,;\\\\s]+\", \";\"));System.out.println(\"数论 图论 逻辑 概率\".replaceAll(\"[,;\\\\s]+\", \";\")); 输出为： 123二分;回溯;递归;分治搜索;查找;旋转;遍历数论;图论;逻辑;概率 在 replaceAll 的第二个参数中，我们可以通过 $1，$2，…来反向引用匹配到的子串。只要将需要引用的部分用 () 括起来就可以了。 示例代码： 123System.out.println(\"二分,回溯,递归,分治\".replaceAll(\"([,;\\\\s]+)\", \"---$1---\"));System.out.println(\"搜索;查找;旋转;遍历\".replaceAll(\"([,;\\\\s]+)\", \"---$1---\"));System.out.println(\"数论 图论 逻辑 概率\".replaceAll(\"([,;\\\\s]+)\", \"---$1---\")); 输出为： 123二分---,---回溯---,---递归---,---分治搜索---;---查找---;---旋转---;---遍历数论--- ---图论--- ---逻辑--- ---概率 参考链接https://mp.weixin.qq.com/s/zxQ-itkICaZlhevvwuBGsw","tags":[{"name":"正则表达式","slug":"正则表达式","permalink":"https://sunshine-zwq.gitee.io/tags/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/"}]},{"title":"常用js工具方法","date":"2020-11-23T16:00:00.000Z","path":"2020/11/24/常用js工具方法/","text":"比较通用的一些js工具方法 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398399400401402403404405406407408409410411412413414415416417418419420421422423424425426427428429430431432433434435436437438439440441442443444445446447448449450451452453454455456457458459460461462463464465466467468469470471472473474475476477478479480481482483484485486487488489490491492493494495496497498499500501502503504505506507508509510511512513514515516517518519520521522523524525526527528529530531532533534535536537538539540541542543544545546547548549550551552553554555556557558559560561562563564565566567568569570571572573574575576577578579580581582583584585586587588589590591592593594595596597598599600601602603604605606607608609610611612613614615616617618619620621622623624625626627628629630631632633634635636637638639640641642643644/********************日期时间相关-start********************//** * 获取指定天数后的日期 * @param addDays 指定天数，如果要获取过去时间则传负数值 * @param fillZero 是否给小于10的补零，默认否 * @returns 指定天数后的日期，格式为“2017-05-04” */function getDayAdd(addDays, fillZero)&#123; var date1 = new Date(); var date2 = new Date(date1); date2.setDate(date1.getDate() + addDays); var month = date2.getMonth() + 1; if(month &lt; 10 &amp;&amp; fillZero)&#123; month = \"0\" + month; &#125; var date = date2.getDate(); if(date &lt; 10 &amp;&amp; fillZero)&#123; date = \"0\" + date; &#125; var time = date2.getFullYear() + \"-\" + month + \"-\" + date; return time;&#125;/** * 获取当前日期 * @param type 格式，0（默认）表示“2017-05-04”，1表示“2017/05/04”，2表示“2017年05月04日” * @param fillZero 是否给小于10的补零，默认否 * @returns 当前日期 */function getTodayDate(type, fillZero)&#123; var date1 = new Date(); var month = date1.getMonth() + 1; if(month &lt; 10 &amp;&amp; fillZero)&#123; month = \"0\" + month; &#125; var date = date1.getDate(); if(date &lt; 10 &amp;&amp; fillZero)&#123; date = \"0\" + date; &#125; var time = date1.getFullYear() + \"-\" + month + \"-\" + date; if(type)&#123; if(type == 1)&#123; time = date1.getFullYear() + \"/\" + month + \"/\" + date; &#125;else if(type == 2)&#123; time = date1.getFullYear() + \"年\" + month + \"月\" + date + \"日\"; &#125; &#125; return time;&#125;/** * 获取指定月后的年月 * @param addMonths 指定月数，如果要获取过去时间则传负数值 * @returns 指定月数后的年月，格式为“2017-05” */function getMonthAdd(addMonths)&#123; var date1 = new Date(); var date2 = new Date(date1); date2.setMonth(date2.getMonth() + addMonths); var month = date2.getMonth() + 1; if(month &lt; 10)&#123; month = \"0\" + month; &#125; var time = date2.getFullYear() + \"-\" + month; return time;&#125;/** * 获取n个月后的日期，格式为yyyy-MM-dd * @param addMonths * @returns &#123;*&#125; */function getAfterMonths(addMonths)&#123; var date = new Date(); date.setMonth(date.getMonth() + addMonths); return dateFormat(date);&#125;/** * 获取当前年月 * @returns 当前年月，格式为“2017-05” */function getCurrMonth()&#123; var date1 = new Date(); var month = date1.getMonth() + 1; if(month &lt; 10)&#123; month = \"0\" + month; &#125; var time = date1.getFullYear() + \"-\" + month; return time;&#125;/** * 计算两个日期之间相差的天数 * @param startDate 开始日期，格式为2017-05-19 * @param endDate 结束日期，格式为2017-05-19 * @returns 相差天数 */function getDateDiff(startDate,endDate)&#123; var startTime = new Date(Date.parse(startDate.replace(/-/g, \"/\"))).getTime(); var endTime = new Date(Date.parse(endDate.replace(/-/g, \"/\"))).getTime(); var dates = Math.abs((startTime - endTime))/(1000*60*60*24); return dates;&#125;/** * 计算两个日期之间相差的月数 * @param startDate 开始日期，格式为2017-05-19 * @param endDate 结束日期，格式为2017-05-19 * @returns 相差月数 */function getMonthDiff(startDate,endDate)&#123; var year1 = startDate.split('-')[0]; var year2 = endDate.split('-')[0]; var month1 = startDate.split('-')[1]; var month2 = endDate.split('-')[1]; var len = (year2 - year1) * 12 + (month2 - month1); return len;&#125;/** * 获取指定日期是星期几 */function getWeekDate(date) &#123; var day = date.getDay(); var weeks = new Array(\"星期日\", \"星期一\", \"星期二\", \"星期三\", \"星期四\", \"星期五\", \"星期六\"); var week = weeks[day]; return week;&#125;/** * 获取当前星期几 */function getTodayWeekDate() &#123; var now = new Date(); return getWeekDate(now);&#125;/** * 获取当前时间 * @returns &#123;string&#125; */function getCurrTime()&#123; var date1 = new Date(); var hour = date1.getHours(); //获取系统时 var minute = date1.getMinutes(); //分 var second = date1.getSeconds(); //秒 if(hour &lt; 10)&#123; hour = \"0\" + hour; &#125; if(minute &lt; 10)&#123; minute = \"0\" + minute; &#125; if(second &lt; 10)&#123; second = \"0\" + second; &#125; var time = hour + \":\" + minute + \":\" + second; return time;&#125;/** * 获取当前时段的名称 * @returns &#123;string&#125; */function getTimePeriodText()&#123; // 获取当前时间 let timeNow = new Date(); // 获取当前小时 let hours = timeNow.getHours(); // 设置默认文字 let text = ''; // 判断当前时间段 if (hours &gt;= 0 &amp;&amp; hours &lt; 6) &#123; text = '早上'; &#125; else if (hours &gt;= 6 &amp;&amp; hours &lt; 12) &#123; text = '上午'; &#125; else if (hours &gt;= 12 &amp;&amp; hours &lt; 14) &#123; text = '中午'; &#125; else if (hours &gt;= 14 &amp;&amp; hours &lt; 18) &#123; text = '下午'; &#125; else if (hours &gt;= 18 &amp;&amp; hours &lt; 24) &#123; text = '晚上'; &#125; // 返回当前时间段名称 return text;&#125;/** * 计算某月1号是星期几 * @param year * @param month * @returns &#123;number&#125; */function getWeekInMonth(year, month) &#123; return new Date(year + '/' + month + '/' + '01').getDay();&#125;/** * 判断指定年份是否是闰年 * @param year * @returns &#123;boolean&#125; */function isLeapYear(year) &#123; return year % 400 == 0 || year % 4 == 0 &amp;&amp; year % 100 != 0&#125;/** * 计算某年某月有多少天 * @param year * @param month * @returns &#123;*|number&#125; */function getDaysInMonth(year, month) &#123; return [null, 31, null, 31, 30, 31, 30, 31, 31, 30, 31, 30, 31][month] || (isLeapYear(year) ? 29 : 28)&#125;/** * 计算得到指定月日历的所有日期arr，并对第一周和最后一周进行补位（如有需要） * @param year * @param month * @returns &#123;Array&#125; */function getMonthCalendarDay(year, month)&#123; // 0是星期日，1是星期一...6是星期六 let monthFirstDay = getWeekInMonth(year, month); if(monthFirstDay == 0)&#123; monthFirstDay = 7; &#125; let dayArr = []; // 如果1号是星期一，不补位；否则要把1号本周的前几天补位 if(monthFirstDay != 1)&#123; for(let i = 0; i &lt; monthFirstDay - 1; i++)&#123; dayArr.push(\"\"); &#125; &#125; // 本月所有常规日期 let days = getDaysInMonth(parseInt(year), parseInt(month)); for(let i = 1; i &lt;= days; i++)&#123; dayArr.push(i+''); &#125; // 如果最后一天是星期日，不补位；否则最后一天所在周的剩余后几天补位 if(dayArr.length % 7 != 0)&#123; let lastWeekDays = dayArr.length % 7; for(let i = 0; i &lt; 7 - lastWeekDays; i++)&#123; dayArr.push(\"\"); &#125; &#125; return dayArr;&#125;/** * 获取指定年月的前n月，后n月 * @param date 代表指定的年月，格式：2018-09 * @param day 传-1表始前一月，传1表始后一月 * @returns &#123;string&#125; 格式：2018-09 */function getNextMonth(monthDate, month) &#123; var arr = monthDate.split(/[-]/); let dd = new Date(arr[0], arr[1] - 1); dd.setMonth(dd.getMonth() + month); var y = dd.getFullYear(); var m = dd.getMonth() + 1 &lt; 10 ? \"0\" + (dd.getMonth() + 1) : dd.getMonth() + 1; return y + \"-\" + m;&#125;/** * 获取指定日期的前n天，后n天 * @param date 代表指定的日期，格式：2018-09-27 * @param day 传-1表始前一天，传1表始后一天 * @returns &#123;string&#125; 格式：2018-09-27 */function getNextDate(date, day) &#123; var arr = date.split(/[-]/); let dd = new Date(arr[0], arr[1] - 1, arr[2]); dd.setDate(dd.getDate() + day); var y = dd.getFullYear(); var m = dd.getMonth() + 1 &lt; 10 ? \"0\" + (dd.getMonth() + 1) : dd.getMonth() + 1; var d = dd.getDate() &lt; 10 ? \"0\" + dd.getDate() : dd.getDate(); return y + \"-\" + m + \"-\" + d;&#125;/** * 获取当前日期，格式2019-07-15 * @returns &#123;string&#125; */function getNowFormatDate() &#123; var date = new Date(); return dateFormat(date);&#125;/** * 日期格式化 * @param date */function dateFormat(date) &#123; if (!date || typeof (date) === \"string\") &#123; console.error(\"参数异常，请检查...\"); return null; &#125; var separator = \"-\"; var year = date.getFullYear(); var month = date.getMonth() + 1; var strDate = date.getDate(); if (month &gt;= 1 &amp;&amp; month &lt;= 9) &#123; month = \"0\" + month; &#125; if (strDate &gt;= 0 &amp;&amp; strDate &lt;= 9) &#123; strDate = \"0\" + strDate; &#125; var formatDate = year + separator + month + separator + strDate; return formatDate;&#125;/** * 计算距离etime剩余时间 * @param etime * @returns &#123;*&#125; */function formatLeftTime(etime) &#123; var timestamp = Date.parse(new Date()); var surplus = etime - timestamp; if (surplus &gt; 0) &#123; var secondTime = surplus / 1000;// 毫秒转为秒 var second = Math.floor(secondTime % 60); // 计算秒 var minute = Math.floor((secondTime / 60) % 60); // 计算分 var hour = Math.floor((secondTime / 3600)); // 计算小时 return [hour, minute, second].map(formatNumber).join(':') &#125; return null;&#125;/** * 获取指定日期之间的所有日期（包含开始结束日期） * @param stime * @param etime * @returns &#123;any[]&#125; */function getBetweenDateStr(stime,etime)&#123; //初始化日期列表，数组 var dateStrArr = new Array(); var i=0; //开始日期小于等于结束日期,并循环 while(stime&lt;=etime)&#123; dateStrArr[i] = stime; //获取开始日期时间戳 var stime_ts = new Date(stime).getTime(); //增加一天时间戳后的日期 var next_date = stime_ts + (24*60*60*1000); //拼接年月日，这里的月份会返回（0-11），所以要+1 var next_dates_y = new Date(next_date).getFullYear()+'-'; var next_dates_m = (new Date(next_date).getMonth()+1 &lt; 10)?'0'+(new Date(next_date).getMonth()+1)+'-':(new Date(next_date).getMonth()+1)+'-'; var next_dates_d = (new Date(next_date).getDate() &lt; 10)?'0'+new Date(next_date).getDate():new Date(next_date).getDate(); stime = next_dates_y+next_dates_m+next_dates_d; //增加数组key i++; &#125; return dateStrArr;&#125;// 获取本周的周一日期function getFirstDayOfWeek()&#123; var date = new Date(); var weekday = date.getDay()||7; //获取星期几,getDay()返回值是 0（周日） 到 6（周六） 之间的一个整数。0||7为7，即weekday的值为1-7 date.setDate(date.getDate()-weekday+1);//往前算（weekday-1）天，年份、月份会自动变化 return dateFormat(date);&#125;/** * 如果是yyyy-MM-dd HH:mm:ss格式直接转Date，在iOS上不支持 * @param dateStr * @returns &#123;number&#125; */function parseDate(dateStr) &#123; var arr = dateStr.split(/[- :]/); let nndate = new Date(arr[0], arr[1] - 1, arr[2], arr[3], arr[4], arr[5]); return Date.parse(nndate);&#125;/********************日期时间相关-end********************//********************验证相关-start********************//** * 验证手机号是否合法 * @param phone * @returns &#123;boolean&#125; */function validMobile(phone)&#123; var reg=/^1[3456789]\\d&#123;9&#125;$/; if(!reg.test(phone))&#123; return false; &#125; return true;&#125;/** * 验证固定电话号码是否合法 * @param phone * @returns &#123;boolean&#125; */function validPhone(phone)&#123; var reg=/^0\\d&#123;2,3&#125;-?\\d&#123;7,8&#125;$/; if(!reg.test(phone))&#123; return false; &#125; return true;&#125;/** * 验证网址是否合法 * @param website * @returns &#123;boolean&#125; */function validWebsite(website)&#123; var reg=/^(?:http(s)?:\\/\\/)?[\\w.-]+(?:\\.[\\w\\.-]+)+[\\w\\-\\._~:/?#[\\]@!\\$&amp;'\\*\\+,;=.]+$/; if(!reg.test(website))&#123; return false; &#125; return true;&#125;/** * 校验身份证号 * @param cardNo * @returns &#123;boolean&#125; */function validIDCardNo(cardNo)&#123; var reg=/^[1-9]&#123;1&#125;[0-9]&#123;14&#125;$|^[1-9]&#123;1&#125;[0-9]&#123;16&#125;([0-9]|[xX])$/; if(!reg.test(cardNo))&#123; return false; &#125; return true;&#125;/** * 验证邮编是否合法 * @param postcode * @returns &#123;boolean&#125; */function validPostcode(postcode)&#123; var reg=/^[0-9]&#123;6&#125;$/; if(!reg.test(postcode))&#123; return false; &#125; return true;&#125;/** * 验证邮箱是否合法 * @param email * @returns &#123;boolean&#125; */function validEmail(email)&#123; var reg=/^[a-zA-Z0-9]+([-_.][a-zA-Z0-9]+)*@[a-zA-Z0-9]+([-_.][a-zA-Z0-9]+)*\\.[a-z]&#123;2,&#125;$/; if(!reg.test(email))&#123; return false; &#125; return true;&#125;/** * 校验金额是否合法，返回true校验通过 */function verifyAmount(amount)&#123; var exp = /^(([1-9]\\d*)|\\d)(\\.\\d&#123;1,2&#125;)?$/; if(!exp.test(amount))&#123; return false; &#125; return true;&#125;/********************验证相关-end********************//********************数字相关-start********************//** * 小于10的前面补0 * @param n * @returns &#123;string&#125; */function formatNumber(n) &#123; n = n.toString() return n[1] ? n : '0' + n&#125;/** * 千位分隔符处理 * @param strNum * @returns &#123;*|string&#125; */function thousandBitSeparator(strNum) &#123; if(strNum.length &lt;= 3) &#123; return strNum; &#125; if(!/^(\\+|-)?(\\d+)(\\.\\d+)?$/.test(strNum)) &#123; return strNum; &#125; var a = RegExp.$1, b = RegExp.$2, c = RegExp.$3; var re = new RegExp(); re.compile(\"(\\\\d)(\\\\d&#123;3&#125;)(,|$)\"); while(re.test(b)) &#123; b = b.replace(re, \"$1,$2$3\"); &#125; return a + \"\" + b + \"\" + c;&#125;/** * 返回beginNum和endNum之间的所有数字数组 * @param beginNum 开始数字 * @param endNum 结束数字（包含） * @param fillZeroFlag 小于10的数是否补0 */function getNumArr(beginNum, endNum, fillZeroFlag)&#123; var numArr = [] for(var i = beginNum; i &lt;= endNum; i++)&#123; if(fillZeroFlag &amp;&amp; i &lt; 10)&#123; numArr.push('0' + i); &#125;else&#123; numArr.push('' + i); &#125; &#125; return numArr;&#125;// 以下方法主要用于小数的基本运算，防止丢精// 除法function accDivide(arg1,arg2)&#123; var t1=0,t2=0,r1,r2; try&#123;t1=arg1.toString().split(\".\")[1].length&#125;catch(e)&#123;&#125; try&#123;t2=arg2.toString().split(\".\")[1].length&#125;catch(e)&#123;&#125; with(Math)&#123; r1=Number(arg1.toString().replace(\".\",\"\")) r2=Number(arg2.toString().replace(\".\",\"\")) return accMulti((r1/r2),pow(10,t2-t1)); &#125;&#125;//乘法function accMulti(arg1,arg2)&#123; var m=0,s1=arg1.toString(),s2=arg2.toString(); try&#123;m+=s1.split(\".\")[1].length&#125;catch(e)&#123;&#125; try&#123;m+=s2.split(\".\")[1].length&#125;catch(e)&#123;&#125; return Number(s1.replace(\".\",\"\"))*Number(s2.replace(\".\",\"\"))/Math.pow(10,m)&#125;//加法function accAdd(arg1,arg2)&#123; var r1,r2,m; try&#123;r1=arg1.toString().split(\".\")[1].length&#125;catch(e)&#123;r1=0&#125; try&#123;r2=arg2.toString().split(\".\")[1].length&#125;catch(e)&#123;r2=0&#125; m=Math.pow(10,Math.max(r1,r2)) return (arg1*m+arg2*m)/m&#125;//减法function accMinus(arg1,arg2)&#123; var r1,r2,m,n; try&#123;r1=arg1.toString().split(\".\")[1].length&#125;catch(e)&#123;r1=0&#125; try&#123;r2=arg2.toString().split(\".\")[1].length&#125;catch(e)&#123;r2=0&#125; m=Math.pow(10,Math.max(r1,r2)); n=(r1&gt;=r2)?r1:r2; return ((arg1*m-arg2*m)/m).toFixed(n);&#125;/********************数字相关-end********************//********************金额相关-start********************//** * 金额统一保留2位小数 * @param amount 金额，单位为元 * @returns &#123;string&#125; */function formatPayAmount(amount)&#123; return parseFloat(amount).toFixed(2);&#125;/********************金额相关-end********************//********************其他相关-start********************/// 原生js实现addClass,removeClass,hasClass方法function hasClass(elem, cls) &#123; cls = cls || ''; if (cls.replace(/\\s/g, '').length == 0) return false; //当cls没有参数时，返回false return new RegExp(' ' + cls + ' ').test(' ' + elem.className + ' ');&#125;function addClass(elem, cls) &#123; if (!hasClass(elem, cls)) &#123; elem.className = elem.className == '' ? cls : elem.className + ' ' + cls; &#125;&#125;function removeClass(elem, cls) &#123; if (hasClass(elem, cls)) &#123; var newClass = ' ' + elem.className.replace(/[\\t\\r\\n]/g, '') + ' '; while (newClass.indexOf(' ' + cls + ' ') &gt;= 0) &#123; newClass = newClass.replace(' ' + cls + ' ', ' '); &#125; elem.className = newClass.replace(/^\\s+|\\s+$/g, ''); &#125;&#125;/** * 根据身份证号获取性别 * @param cardNo * @returns &#123;string&#125; */function getSexByIDCardNo(cardNo)&#123; if(cardNo.length == 18)&#123; if (parseInt(cardNo.substr(16, 1)) % 2 == 1) &#123; return \"男\"; &#125; else &#123; return \"女\"; &#125; &#125;else if(cardNo.length == 15)&#123; if (parseInt(cardNo.substr(14, 1)) % 2 == 1) &#123; return \"男\"; &#125; else &#123; return \"女\"; &#125; &#125; return '';&#125;/** * 查找元素在js数组的索引，不存在则返回-1 * @param arr * @param obj * @returns &#123;*&#125; */function findIndexOfArr(arr, obj) &#123; var i = arr.length; while (i--) &#123; if (arr[i] === obj) &#123; return i; &#125; &#125; return -1;&#125;// 调用微信关闭浏览器function closeWxWindow()&#123; WeixinJSBridge.invoke('closeWindow',&#123;&#125;,function(res)&#123; &#125;);&#125;/********************其他相关-end********************/","tags":[{"name":"js","slug":"js","permalink":"https://sunshine-zwq.gitee.io/tags/js/"},{"name":"工具","slug":"工具","permalink":"https://sunshine-zwq.gitee.io/tags/%E5%B7%A5%E5%85%B7/"}]},{"title":"利用LinkedHashMap实现LRU算法","date":"2020-11-15T16:00:00.000Z","path":"2020/11/16/利用LinkedHashMap实现LRU算法/","text":"LRU LRU（Least recently used，最近最少使用）算法根据数据的历史访问记录来进行淘汰数据，其核心思想是“如果数据最近被访问过，那么将来被访问的几率也更高”。 代码实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990import java.util.ArrayList;import java.util.Collection;import java.util.LinkedHashMap;import java.util.concurrent.locks.Lock;import java.util.concurrent.locks.ReentrantLock;import java.util.Map;/** * 类说明：利用LinkedHashMap实现简单的缓存， 必须实现removeEldestEntry方法，具体参见JDK文档 * * @author dennis * * @param &lt;K&gt; * @param &lt;V&gt; */public class LRULinkedHashMap&lt;K, V&gt; extends LinkedHashMap&lt;K, V&gt; &#123; private final int maxCapacity; private static final float DEFAULT_LOAD_FACTOR = 0.75f; private final Lock lock = new ReentrantLock(); public LRULinkedHashMap(int maxCapacity) &#123; super(maxCapacity, DEFAULT_LOAD_FACTOR, true); this.maxCapacity = maxCapacity; &#125; @Override protected boolean removeEldestEntry(java.util.Map.Entry&lt;K, V&gt; eldest) &#123; return size() &gt; maxCapacity; &#125; @Override public boolean containsKey(Object key) &#123; try &#123; lock.lock(); return super.containsKey(key); &#125; finally &#123; lock.unlock(); &#125; &#125; @Override public V get(Object key) &#123; try &#123; lock.lock(); return super.get(key); &#125; finally &#123; lock.unlock(); &#125; &#125; @Override public V put(K key, V value) &#123; try &#123; lock.lock(); return super.put(key, value); &#125; finally &#123; lock.unlock(); &#125; &#125; public int size() &#123; try &#123; lock.lock(); return super.size(); &#125; finally &#123; lock.unlock(); &#125; &#125; public void clear() &#123; try &#123; lock.lock(); super.clear(); &#125; finally &#123; lock.unlock(); &#125; &#125; public Collection&lt;Map.Entry&lt;K, V&gt;&gt; getAll() &#123; try &#123; lock.lock(); return new ArrayList&lt;Map.Entry&lt;K, V&gt;&gt;(super.entrySet()); &#125; finally &#123; lock.unlock(); &#125; &#125;&#125; 参考链接： 缓存淘汰算法–LRU算法(java代码实现)","tags":[{"name":"java","slug":"java","permalink":"https://sunshine-zwq.gitee.io/tags/java/"},{"name":"算法","slug":"算法","permalink":"https://sunshine-zwq.gitee.io/tags/%E7%AE%97%E6%B3%95/"}]},{"title":"Java8特性","date":"2020-09-29T16:00:00.000Z","path":"2020/09/30/Java8特性/","text":"Java 8 新特性简介 速度更快 代码更少（增加了新的语法 Lambda 表达式） 强大的 Stream API 便于并行 最大化减少空指针异常 Optional 1.Lambda 表达式简介： Lambda 是一个 匿名函数。Lambda 表达式在Java 语言中引入了一个新的语法元素和操作符 “-&gt;” ，该操作符被称为 Lambda 操作符或箭头操作符。它将 Lambda 分为两个部分： 左侧：指定了 Lambda 表达式需要的所有参数右侧：指定了 Lambda 体，即 Lambda 表达式要执行的功能。 从匿名类到 Lambda 的转换： 12345678910// 匿名内部类Runnable r1 = new Runnable() &#123; @Override public void run() &#123; System.out.println(\"Hello World\"); &#125;&#125;// Lambda表达式Runnable r1 = () -&gt; System.out.println(\"Hello World\"); Lambda 表达式语法： 12345678910111213141516171819202122// 语法格式1：无参，无返回值，Lambda体只需要一条语句Runnable r1 = () -&gt; System.out.println(\"Hello Lambda!\");// 语法格式2：Lambda只需要一个参数Consumer&lt;String&gt; fun = (args) -&gt; System.out.println(args);// 只有一个参数时，参数的括号可省略（参数有2个或以上时，括号不能省略）Consumer&lt;String&gt; fun = args -&gt; System.out.println(args);// 语法格式3：Lambda需要2个参数，并且有返回值BinaryOperator&lt;Long&gt; bo = (x, y) -&gt; &#123; System.out.println(\"实现函数接口方法\"); return x + y;&#125;// 语法格式4：当Lambda体有返回值且只有一条语句时，return与大括号可以省略BinaryOperator&lt;Long&gt; bo = (x, y) -&gt; x + y;// 语法格式5：数据类型可以省略，因为可由编译器推断得出，称为“类型推断”BinaryOperator&lt;Long&gt; bo = (Long x, Long y) -&gt; &#123; System.out.println(\"实现函数接口方法\"); return x + y;&#125; 类型推断 上述 Lambda 表达式中的参数类型都是由编译器推断得出的。Lambda 表达式中无需指定类型，程序依然可以编译，这是因为 javac根据程序的上下文，在后台推断出了参数的类型。Lambda 表达式的类型依赖于上下文环境，是由编译器推断出来的。 2.函数式接口简介： 只包含一个抽象方法的接口，称为 函数式接口。 可以通过 Lambda 表达式来创建该接口的对象。（若 Lambda表达式抛出一个受检异常，那么该异常需要在目标接口的抽象方法上进行声明）。 我们可以在任意函数式接口上使用 @FunctionalInterface 注解，这样做可以检查它是否是一个函数式接口，同时 javadoc 也会包含一条声明，说明这个接口是一个函数式接口 自定义函数式接口： 12345678910@FunctionalInterfacepublic interface MyNumber &#123; public double getValue();&#125;// 函数式接口中使用泛型@FunctionalInterfacepublic interface MyFunc&lt;T&gt; &#123; public T getValue(T t);&#125; 作为参数传递Lambda表达式： 123456public String toUpperString(MyFunc&lt;String&gt; mf, String str)&#123; return mf.getValue(str);&#125;String newStr = toUpperString((str) -&gt; str.toUpperCase(), \"abcdef\");System.out.println(newStr); Java内置四大核心函数式接口： 函数式接口 参数类型 返回类型 用途 Consumer：消费型接口 T void 对类型为T的对象应用操作，包含方法：void accept(T t) Supplier：供给型接口 无 T 返回类型为T的对象，包含方法：T get(); Function&lt;T, R&gt;：函数型接口 T R 对类型为T的对象应用操作，并返回结果。结果是R类型的对象。包含方法：R apply(T t); Predicate：断定型接口 T boolean 确定类型为T的对象是否满足某约束，并返回boolean 值。包含方法：boolean test(T t); 示例代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162// Consumer&lt;T&gt; 消费型接口 @Test public void test1()&#123; buy(1000, (m) -&gt; System.out.println(\"本次超市购物消费\" + m + \"元\")); &#125; public void buy(double money, Consumer&lt;Double&gt; con)&#123; con.accept(money); &#125; // Supplier&lt;T&gt; 供给型接口 @Test public void test2()&#123; List&lt;Integer&gt; numList = getNumList(10, () -&gt; (int)(Math.random() * 100)); for (Integer num : numList) &#123; System.out.println(num); &#125; &#125; // 需求：产生指定个数的整数，并放入集合中 public List&lt;Integer&gt; getNumList(int num, Supplier&lt;Integer&gt; sup)&#123; List&lt;Integer&gt; list = new ArrayList&lt;&gt;(); for(int i = 0; i &lt; num; i++)&#123; list.add(sup.get()); &#125; return list; &#125; // Function&lt;T, R&gt; 函数型接口 @Test public void test3()&#123; String newStr = strHandler(\" 测试Function函数式接口 \", (s) -&gt; s.trim()); System.out.println(newStr); String subStr = strHandler(\"测试Function函数式接口\", (s) -&gt; s.substring(2, 5)); System.out.println(subStr); &#125; public String strHandler(String str, Function&lt;String, String&gt; fun)&#123; return fun.apply(str); &#125; // Predicate&lt;T&gt; 断言型接口 @Test public void test4()&#123; List&lt;String&gt; list = Arrays.asList(\"Hello\", \"www\", \"ok\", \"Lambda\", \"test\"); List&lt;String&gt; resultList = filterStr(list, (s) -&gt; s.contains(\"e\")); for (String s : resultList) &#123; System.out.println(s); &#125; &#125; public List&lt;String&gt; filterStr(List&lt;String&gt; list, Predicate&lt;String&gt; pre)&#123; List&lt;String&gt; strList = new ArrayList&lt;&gt;(); for (String s : list) &#123; if(pre.test(s))&#123; strList.add(s); &#125; &#125; return strList; &#125; 其他接口： 函数式接口 参数类型 返回类型 用途 BiFunction&lt;T, U, R&gt; T, U R 对类型为 T, U 参数应用操作，返回 R 类型的结果。包含方法：R apply(T t, U u); UnaryOperator(Function 子接口) T T 对类型为T的对象进行一元运算，并返回T类型的结果。包含方法：T apply(T t); BinaryOperator(BiFunction 子接口) T, T T 对类型为T的对象进行二元运算，并返回T类型的结果。包含方法：T apply(T t1, T t2); BiConsumer&lt;T, U&gt; T, U void 对类型为T, U 参数应用操作。包含方法：void accept(T t, U u) ToIntFunctionToLongFunctionToDoubleFunction T intlongdouble 分别计算int 、 long 、double值的函数 IntFunctionLongFunctionDoubleFunction intlongdouble R 参数分别为int、long、double 类型的函数 3.方法引用与构造器引用简介： 当要传递给Lambda体的操作，已经有实现的方法了，可以使用方法引用 可以理解为，方法引用是lambda表达式的另外一种表现形式。 实现抽象方法的参数列表，必须与方法引用方法的参数列表保持一致 方法引用，使用操作符 :: 将方法名和对象或类的名字分隔开来。 (1).对象::实例方法 1234(x) -&gt; System.out.println(x)// 等同于System.out::println (2).类::静态方法 1234BinaryOperator&lt;Double&gt; bo = (x, y) -&gt; Math.pow(x, y);// 等同于BinaryOperator&lt;Double&gt; bo = Math::pow; (3).类::实例方法 当需要引用方法的第一个参数是调用对象，并且第二个参数是需要引用方法的第二个 参数( 或无参数 ) 时：ClassName::methodName 1234compare((x, y) -&gt; x.equals(y), \"abcdef\", \"abcdef\");// 等同于compare(String::equals, \"abcdef\", \"abcdef\"); (4).构造器引用 格式：Class::new 与函数式接口相结合，自动与函数式接口中方法兼容。可以把构造器引用赋值给定义的方法，与构造器参数列表要与接口中抽象方法的参数列表一致！ 1234Function&lt;Integer, MyClass&gt; fun = (n) -&gt; new MyClass(n);// 等同于Function&lt;Integer, MyClass&gt; fun = MyClass::new; (5).数组引用 格式：type[]::new 1234Function&lt;Integer, Integer[]&gt; fun = (n) -&gt; new Integer[n];// 等同于Function&lt;Integer, Integer[]&gt; fun = Integer[]::new; 4.Stream API简介： Stream 是 Java8 中处理集合的关键抽象概念，它可以指定你希望对集合进行的操作，可以执行非常复杂的查找、过滤和映射数据等操作。使用Stream API 对集合数据进行操作，就类似于使用 SQL 执行的数据库查询。也可以使用 Stream API 来并行执行操作。简而言之，Stream API 提供了一种高效且易于使用的处理数据的方式。 什么是Stream？ Stream是数据渠道，用于操作数据源（集合、数组等）所生成的元素序列。“集合讲的是数据，流讲的是计算！ 注意：①Stream 自己不会存储元素。②Stream 不会改变源对象。相反，他们会返回一个持有结果的新Stream。③Stream 操作是延迟执行的。这意味着他们会等到需要结果的时候才执行。 Stream的操作三个步骤： 创建Stream 一个数据源（如：集合、数组），获取一个流 中间操作 一个中间操作链，对数据源的数据进行处理 终止操作（终端操作） 一个终止操作，执行中间操作链，并产生结果 创建Stream(1).通过Collection接口方法 Java8 中的 Collection 接口被扩展，提供了两个获取流的方法 ： default Stream stream() : 返回一个顺序流 default Stream parallelStream() : 返回一个并行流 (2).由数组创建流 Java8 中的 Arrays 的静态方法 stream() 可以获取数组流： static Stream stream(T[] array): 返回一个流 (3).由值创建流 可以使用静态方法 Stream.of(), 通过显示值创建一个流。它可以接收任意数量的参数。 public static Stream of(T… values) : 返回一个流 (4).由函数创建流：创建无限流 可以使用静态方法 Stream.iterate() 和Stream.generate()，创建无限流。 迭代 public static Stream iterate(final T seed, final UnaryOperator f) 生成 public static Stream generate(Supplier s) 示例代码： 12345678910111213141516171819202122// 1.可以通过Collection系列集合提供的stream()或parallelStream() List&lt;String&gt; list = new ArrayList&lt;&gt;(); Stream&lt;String&gt; stream1 = list.stream(); // 2.通过Arrays中的静态方法stream()获取数据流 Employee[] emps = new Employee[10]; Stream&lt;Employee&gt; stream2 = Arrays.stream(emps); // 3.通过Stream类中的静态方法of Stream&lt;String&gt; stream3 = Stream.of(\"aa\", \"bb\", \"cc\"); // 4.创建无限流 // 迭代 Stream&lt;Integer&gt; stream4 = Stream.iterate(0, (x) -&gt; x + 2); stream4.limit(10).forEach(System.out::println); System.out.println(\"===========================================\"); // 生成 Stream.generate(() -&gt; Math.random()) .limit(5) .forEach(System.out::println); 中间操作多个中间操作可以连接起来形成一个流水线，除非流水线上触发终止操作，否则中间操作不会执行任何的处理！而在终止操作时一次性全部处理，称为“惰性求值”。 筛选与切片 方法 描述 filter(Predicate p) 接收 Lambda ， 从流中排除某些元素 distinct() 筛选，通过流所生成元素的 hashCode() 和 equals() 去除重复元素 limit(long maxSize) 截断流，使其元素不超过给定数量 skip(long n) 跳过元素，返回一个扔掉了前 n 个元素的流。若流中元素不足 n 个，则返回一个空流。与 limit(n) 互补 示例代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546List&lt;Employee&gt; emps = Arrays.asList( new Employee(101, \"张三\", 18, 9999.99), new Employee(102, \"李四\", 59, 6666.66), new Employee(103, \"王五\", 28, 3333.33), new Employee(104, \"赵六\", 8, 7777.77), new Employee(105, \"田七\", 38, 5555.55), new Employee(105, \"田七\", 38, 5555.55), new Employee(105, \"田七\", 38, 5555.55) ); // filter @Test public void test1()&#123; Stream&lt;Employee&gt; stream = emps.stream() .filter((e) -&gt; e.getAge() &gt; 35); stream.forEach(System.out::println); &#125; // limit @Test public void test2()&#123; emps.stream() .filter((e) -&gt; e.getSalary() &gt; 5000) .limit(2) .forEach(System.out::println); &#125; // skip @Test public void test3()&#123; emps.stream() .filter((e) -&gt; e.getSalary() &gt; 5000) .skip(2) .forEach(System.out::println); &#125; // distinct @Test public void test4()&#123; emps.stream() .filter((e) -&gt; e.getSalary() &gt; 5000) .skip(2) .distinct() .forEach(System.out::println); &#125; 映射 方法 描述 map(Function f) 接收一个函数作为参数，该函数会被应用到每个元素上，并将其映射成一个新的元素。 mapToDouble(ToDoubleFunction f) 接收一个函数作为参数，该函数会被应用到每个元素上，产生一个新的 DoubleStream。 mapToInt(ToIntFunction f) 接收一个函数作为参数，该函数会被应用到每个元素上，产生一个新的 IntStream。 mapToLong(ToLongFunction f) 接收一个函数作为参数，该函数会被应用到每个元素上，产生一个新的 LongStream。 flatMap(Function f) 接收一个函数作为参数，将流中的每个值都换成另一个流，然后把所有流连接成一个流 示例代码： 12345678910111213141516171819202122232425262728293031323334 // map @Test public void test5()&#123; List&lt;String&gt; list = Arrays.asList(\"aaa\", \"bbb\", \"ccc\", \"ddd\"); list.stream() .map((str) -&gt; str.toUpperCase()) .forEach(System.out::println); System.out.println(\"===========================================\"); emps.stream() .map((e) -&gt; e.getName()) .forEach(System.out::println); System.out.println(\"===========================================\");// Stream&lt;Stream&lt;Character&gt;&gt; stream = list.stream()// .map((s) -&gt; filterCharacter(s));// stream.forEach((sm) -&gt; &#123;// sm.forEach(System.out::println);// &#125;); list.stream() .flatMap((s) -&gt; filterCharacter(s)) .forEach(System.out::println); &#125; public static Stream&lt;Character&gt; filterCharacter(String str)&#123; List&lt;Character&gt; list = new ArrayList&lt;&gt;(); for (char ch : str.toCharArray()) &#123; list.add(ch); &#125; return list.stream(); &#125; 排序 方法 描述 sorted() 产生一个新流，其中按自然顺序排序 sorted(Comparator comp) 产生一个新流，其中按比较器顺序排序 示例代码： 123456789101112131415161718@Test public void test6()&#123; List&lt;String&gt; list = Arrays.asList(\"ccc\", \"aaa\", \"ddd\", \"eee\", \"bbb\"); list.stream() .sorted() .forEach(System.out::println); System.out.println(\"===========================================\"); emps.stream() .sorted((e1, e2) -&gt; &#123; if(e1.getAge() == e2.getAge())&#123; return e1.getName().compareTo(e2.getName()); &#125;else&#123; return e1.getAge() - e2.getAge(); &#125; &#125;).forEach(System.out::println); &#125; 终止操作终端操作会从流的流水线生成结果。其结果可以是任何不是流的值，例如：List、Integer，甚至是 void。 查找与匹配 方法 描述 allMatch(Predicate p) 检查是否匹配所有元素 anyMatch(Predicate p) 检查是否至少匹配一个元素 noneMatch(Predicate p) 检查是否没有匹配所有元素 findFirst() 返回第一个元素 findAny() 返回当前流中的任意元素 count() 返回流中元素总数 max(Comparator c) 返回流中最大值 min(Comparator c) 返回流中最小值 forEach(Consumer c) 内部迭代(使用 Collection 接口需要用户去做迭代，称为外部迭代 。相反， Stream API 使用内部迭代 —— 它帮你把迭代做了) 示例代码： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647List&lt;Employee&gt; emps = Arrays.asList( new Employee(101, \"张三\", 18, 9999.99), new Employee(102, \"李四\", 59, 6666.66), new Employee(103, \"王五\", 28, 3333.33), new Employee(104, \"赵六\", 8, 7777.77), new Employee(105, \"田七\", 38, 5555.55) ); @Test public void test1()&#123; boolean b1 = emps.stream() .allMatch((e) -&gt; e.getSalary() &gt; 5000); System.out.println(b1); boolean b2 = emps.stream() .anyMatch((e) -&gt; e.getSalary() &gt; 5000); System.out.println(b2); boolean b3 = emps.stream() .noneMatch((e) -&gt; e.getSalary() &gt; 5000); System.out.println(b3); Optional&lt;Employee&gt; op = emps.stream() .sorted((e1, e2) -&gt; Double.compare(e1.getSalary(), e2.getSalary())) .findFirst(); System.out.println(op.get()); Optional&lt;Employee&gt; op2 = emps.parallelStream() .filter((e) -&gt; e.getSalary() &gt; 5000) .findAny(); System.out.println(op2.get()); &#125; @Test public void test2()&#123; long count = emps.stream().count(); System.out.println(count); Optional&lt;Employee&gt; op1 = emps.stream() .max((e1, e2) -&gt; Double.compare(e1.getSalary(), e2.getSalary())); System.out.println(op1.get()); Optional&lt;Double&gt; op2 = emps.stream() .map(Employee::getSalary) .min(Double::compare); System.out.println(op2.get()); &#125; 规约 方法 描述 reduce(T iden, BinaryOperator b) 可以将流中元素反复结合起来，得到一个值。返回 T reduce(BinaryOperator b) 可以将流中元素反复结合起来，得到一个值。返回 Optional 示例代码： 12345678910111213@Test public void test3()&#123; List&lt;Integer&gt; list = Arrays.asList(1,2,3,4,5,6,7,8,9,10); Integer sum = list.stream() .reduce(0, (x, y) -&gt; x + y); System.out.println(sum); Optional&lt;Double&gt; op = emps.stream() .map(Employee::getSalary) .reduce(Double::sum); System.out.println(op.get()); &#125; 收集 方法 描述 collect(Collector c) 将流转换为其他形式。接收一个 Collector接口的实现，用于给Stream中元素做汇总的方法 Collector 接口中方法的实现决定了如何对流执行收集操作(如收集到 List、Set、Map)。但是 Collectors 实用类提供了很多静态方法，可以方便地创建常见收集器实例，具体方法与实例如下表： 方法 返回类型 作用 示例 toList List 把流中元素收集到List List emps = list.stream().collect(Collectors.toList()); toSet Set 把流中元素收集到Set Set emps= list.stream().collect(Collectors.toSet()); toCollection Collection 把流中元素收集到创建的集合 Collectionemps=list.stream().collect(Collectors.toCollection(ArrayList::new)); counting Long 计算流中元素的个数 long count = list.stream().collect(Collectors.counting()); summingInt Integer 对流中元素的整数属性求和 inttotal=list.stream().collect(Collectors.summingInt(Employee::getSalary)); averagingInt Double 计算流中元素Integer属性的平均值 doubleavg= list.stream().collect(Collectors.averagingInt(Employee::getSalary)); summarizingInt IntSummaryStatistics 收集流中Integer属性的统计值。如：平均值 IntSummaryStatisticsiss= list.stream().collect(Collectors.summarizingInt(Employee::getSalary)); joining String 连接流中每个字符串 String str= list.stream().map(Employee::getName).collect(Collectors.joining()); maxBy Optional 根据比较器选择最大值 Optionalmax= list.stream().collect(Collectors.maxBy(comparingInt(Employee::getSalary))); minBy Optional 根据比较器选择最小值 Optional min = list.stream().collect(Collectors.minBy(comparingInt(Employee::getSalary))); reducing 归约产生的类型 从一个作为累加器的初始值开始，利用BinaryOperator与流中元素逐个结合，从而归约成单个值 inttotal=list.stream().collect(Collectors.reducing(0, Employee::getSalar, Integer::sum)); collectingAndThen 转换函数返回的类型 包裹另一个收集器，对其结果转换函数 inthow= list.stream().collect(Collectors.collectingAndThen(Collectors.toList(), List::size)); groupingBy Map&lt;K, List&gt; 根据某属性值对流分组，属性为K，结果为V Map&lt;Emp.Status, List&gt; map= list.stream().collect(Collectors.groupingBy(Employee::getStatus)); partitioningBy Map&lt;Boolean, List&gt; 根据true或false进行分区 Map&lt;Boolean,List&gt;vd= list.stream().collect(Collectors.partitioningBy(Employee::getManage)); 示例代码： 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485@Test public void test4()&#123; List&lt;String&gt; list = emps.stream() .map(Employee::getName) .collect(Collectors.toList()); list.forEach(System.out::println); Set&lt;String&gt; set = emps.stream() .map(Employee::getName) .collect(Collectors.toSet()); set.forEach(System.out::println); HashSet&lt;String&gt; hs = emps.stream() .map(Employee::getName) .collect(Collectors.toCollection(HashSet::new)); hs.forEach(System.out::println); &#125; @Test public void test5()&#123; // 总数 Long count = emps.stream() .collect(Collectors.counting()); System.out.println(count); // 平均值 Double avg = emps.stream() .collect(Collectors.averagingDouble(Employee::getSalary)); System.out.println(avg); // 总和 Double sum = emps.stream() .collect(Collectors.summingDouble(Employee::getSalary)); System.out.println(sum); // 最大值 Optional&lt;Employee&gt; max = emps.stream() .collect(Collectors.maxBy((e1, e2) -&gt; Double.compare(e1.getSalary(), e2.getSalary()))); System.out.println(max.get()); // 最小值 Optional&lt;Double&gt; min = emps.stream() .map(Employee::getSalary) .collect(Collectors.minBy(Double::compare)); System.out.println(min.get()); &#125; @Test public void test6()&#123; // 分组 Map&lt;String, List&lt;Employee&gt;&gt; map = emps.stream() .collect(Collectors.groupingBy((e) -&gt; &#123; if (((Employee) e).getSalary() &gt; 7000) &#123; return \"高薪\"; &#125; else &#123; return \"低薪\"; &#125; &#125;)); System.out.println(map); &#125; @Test public void test7()&#123; // 分区 Map&lt;Boolean, List&lt;Employee&gt;&gt; map = emps.stream() .collect(Collectors.partitioningBy((e) -&gt; e.getSalary() &gt; 7000)); System.out.println(map); &#125; @Test public void test8()&#123; DoubleSummaryStatistics dss = emps.stream() .collect(Collectors.summarizingDouble(Employee::getSalary)); System.out.println(dss.getSum()); System.out.println(dss.getAverage()); System.out.println(dss.getMax()); &#125; @Test public void test9()&#123; String str = emps.stream() .map(Employee::getName) .collect(Collectors.joining(\",\")); System.out.println(str); &#125; 并行流与串行流 并行流 就是把一个内容分成多个数据块，并用不同的线程分别处理每个数据块的流。 Java 8 中将并行进行了优化，我们可以很容易的对数据进行并行操作。Stream API 可以声明性地通过 parallel() 与sequential() 在并行流与顺序流之间进行切换。 5.Optional类简介： Optional 类(java.util.Optional) 是一个容器类，代表一个值存在或不存在，原来用 null 表示一个值不存在，现在 Optional 可以更好的表达这个概念。并且可以避免空指针异常。 常用方法： Optional.of(T t)：创建一个 Optional 实例 Optional.empty()：创建一个空的 Optional 实例 Optional.ofNullable(T t)：若 t 不为 null,创建 Optional 实例,否则创建空实例 isPresent()：判断是否包含值 orElse(T t)：如果调用对象包含值，返回该值，否则返回t orElseGet(Supplier s) ：如果调用对象包含值，返回该值，否则返回 s 获取的值 map(Function f)：如果有值对其处理，并返回处理后的Optional，否则返回 Optional.empty() flatMap(Function mapper)：与 map 类似，要求返回值必须是Optional 示例代码： 12345678910111213141516171819202122232425262728293031323334353637@Test public void test1()&#123; Optional&lt;Employee&gt; op = Optional.of(new Employee()); Employee emp = op.get(); System.out.println(emp); &#125; @Test public void test2()&#123; Optional&lt;Employee&gt; op = Optional.empty(); System.out.println(op); &#125; @Test public void test3()&#123; Optional&lt;Employee&gt; op = Optional.ofNullable(null); if(op.isPresent())&#123; System.out.println(op.get()); &#125; Employee emp1 = op.orElse(new Employee(\"张三\", 28)); System.out.println(emp1); Employee emp2 = op.orElseGet(Employee::new); System.out.println(emp2); &#125; @Test public void test4()&#123; Optional&lt;Employee&gt; op = Optional.ofNullable(new Employee(\"张三\", 28)); Optional&lt;String&gt; str = op.map((e) -&gt; e.getName()); System.out.println(str.get()); Optional&lt;String&gt; str2 = op.flatMap((e) -&gt; Optional.of(e.getName())); System.out.println(str2.get()); &#125; 尽量避免使用的地方： 1、避免使用Optional.isPresent()来检查实例是否存在，因为这种方式和null != obj没有区别，这样用就没什么意义了。 2、避免使用Optional.get()方式来获取实例对象，因为使用前需要使用Optional.isPresent()来检查实例是否存在，否则会出现NPE问题。 3、避免使用Optional作为类或者实例的属性，而应该在返回值中用来包装返回实例对象。 4、避免使用Optional作为方法的参数，原因同3。 使用Optional优化的经典案例： 1234567891011121314151617181920212223// java8之前的多重if判断private String getIsoCode(User user)&#123; if (user != null) &#123; Address address = user.getAddress(); if (address != null) &#123; Country country = address.getCountry(); if (country != null) &#123; String isocode = country.getIsocode(); if (isocode != null) &#123; return isocode; &#125; &#125; &#125; &#125; return \"\";&#125;// 用java8的Optional优化后String isoCode = Optional.ofNullable(user) .map(User::getAddress) //Optional&lt;Address&gt; .map(Address::getCountry) //Optional&lt;Country&gt; .map(Country::getIsocode) // Optional&lt;String&gt; .orElse(\"\"); 6.接口中的默认方法与静态方法接口中的默认方法 Java 8中允许接口中包含具有具体实现的方法，该方法称为“默认方法”，默认方法使用 default 关键字修饰。 示例代码： 1234567public interface MyFunc &#123; default String getName()&#123; return \"Hello Java8\"; &#125;&#125; 接口默认方法的 ” 类优先 ”原则 若一个接口中定义了一个默认方法，而另外一个父类或接口中又定义了一个同名的方法时： 选择父类中的方法。如果一个父类提供了具体的实现，那么接口中具有相同名称和参数的默认方法会被忽略。 接口冲突。如果一个父接口提供一个默认方法，而另一个接口也提供了一个具有相同名称和参数列表的方法（不管方法是否是默认方法），那么必须覆盖该方法来解决冲突 示例代码： 1234567891011121314151617interface MyFunc&#123; default String getName()&#123; return \"Hello Java8\"; &#125;&#125;interface Named&#123; default String getName()&#123; return \"Hello World\"; &#125;&#125;class MyClass implements MyFunc, Named&#123; public String getName()&#123; return Named.super.getName(); &#125;&#125; 接口中的静态方法 Java8 中，接口中允许添加静态方法。 示例代码： 123456789101112interface Named&#123; public Integer myFun(); default String getName()&#123; return \"Hello World\"; &#125; static void show()&#123; System.out.println(\"Hi\"); &#125;&#125; 7.新时间日期 API在旧版的 Java 中，日期时间 API 存在诸多问题，其中有： 非线程安全 − java.util.Date 是非线程安全的，所有的日期类都是可变的，这是Java日期类最大的问题之一。 设计很差 − Java的日期/时间类的定义并不一致，在java.util和java.sql的包中都有日期类，此外用于格式化和解析的类在java.text包中定义。java.util.Date同时包含日期和时间，而java.sql.Date仅包含日期，将其纳入java.sql包并不合理。另外这两个类都有相同的名字，这本身就是一个非常糟糕的设计。 时区处理麻烦 − 日期类并不提供国际化，没有时区支持，因此Java引入了java.util.Calendar和java.util.TimeZone类，但他们同样存在上述所有的问题。 使用 LocalDate 、LocalTime 、LocalDateTime LocalDate、LocalTime、LocalDateTime 类的实例是不可变的对象，分别表示使用 ISO-8601日历系统的日期、时间、日期和时间。它们提供了简单的日期或时间，并不包含当前的时间信息。也不包含与时区相关的信息。 方法 描述 示例 now() 静态方法，根据当前时间创建对象 LocalDate localDate = LocalDate.now();LocalTime localTime = LocalTime.now();LocalDateTime localDateTime = LocalDateTime.now(); of() 静态方法，根据指定日期/时间创建对象 LocalDate localDate = LocalDate.of(2016, 10, 26);LocalTime localTime = LocalTime.of(02, 22, 56);LocalDateTime localDateTime = LocalDateTime.of(2016, 10,26, 12, 10, 55); plusDays, plusWeeks,plusMonths, plusYears 向当前 LocalDate 对象添加几天、几周、几个月、几年 minusDays, minusWeeks,minusMonths, minusYears 从当前 LocalDate 对象减去几天、几周、几个月、几年 plus, minus 添加或减少一个 Duration 或 Period withDayOfMonth,withDayOfYear,withMonth,withYear 将月份天数、年份天数、月份、年份修改为指定的值并返回新的LocalDate 对象 getDayOfMonth 获得月份天数(1-31) getDayOfYear 获得年份天数(1-366) getDayOfWeek 获得星期几(返回一个 DayOfWeek枚举值) getMonth 获得月份, 返回一个 Month 枚举值 getMonthValue 获得月份(1-12) getYear 获得年份 until 获得两个日期之间的 Period 对象，或者指定 ChronoUnits 的数字 isBefore, isAfter 比较两个 LocalDate isLeapYear 判断是否是闰年 Instant 时间戳 用于“时间戳”的运算。它是以Unix元年(传统的设定为UTC时区1970年1月1日午夜时分)开始所经历的描述进行运算 Duration 和 Period Duration: 用于计算两个“时间”间隔 Period: 用于计算两个“日期”间隔 日期的操纵 emporalAdjuster : 时间校正器。有时我们可能需要获取例如：将日期调整到“下个周日”等操作。 TemporalAdjusters : 该类通过静态方法提供了大量的常用 TemporalAdjuster 的实现。 解析与格式化 java.time.format.DateTimeFormatter 类：该类提供了三种格式化方法： 预定义的标准格式 语言环境相关的格式 自定义的格式 时区的处理 Java8 中加入了对时区的支持，带时区的时间为分别为：ZonedDate、ZonedTime、ZonedDateTime 其中每个时区都对应着 ID，地区ID都为 “{区域}/{城市}”的格式，例如 ：Asia/Shanghai 等 ZoneId：该类中包含了所有的时区信息 getAvailableZoneIds() : 可以获取所有时区时区信息 of(id) : 用指定的时区信息获取 ZoneId 对象 与传统日期处理的转换 类 To遗留类 From遗留类 java.time.Instantjava.util.Date Date.from(instant) date.toInstant() java.time.Instantjava.sql.Timestamp Timestamp.from(instant) timestamp.toInstant() java.time.ZonedDateTimejava.util.GregorianCalendar GregorianCalendar.from(zonedDateTime) cal.toZonedDateTime() java.time.LocalDatejava.sql.Time Date.valueOf(localDate) date.toLocalDate() java.time.LocalTimejava.sql.Time Date.valueOf(localDate) date.toLocalTime() java.time.LocalDateTimejava.sql.Timestamp Timestamp.valueOf(localDateTime) timestamp.toLocalDateTime() java.time.ZoneIdjava.util.TimeZone Timezone.getTimeZone(id) timeZone.toZoneId() java.time.format.DateTimeFormatterjava.text.DateFormat formatter.toFormat() 无 示例代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126@Test public void test1()&#123; LocalDateTime ldt = LocalDateTime.now(); System.out.println(ldt); System.out.println(ldt.getYear()); System.out.println(ldt.getMonthValue()); System.out.println(ldt.getDayOfMonth()); System.out.println(ldt.getHour()); System.out.println(ldt.getMinute()); System.out.println(ldt.getSecond()); LocalDateTime ldt2 = ldt.plusYears(2); System.out.println(ldt2); LocalDateTime ldt3 = ldt.plusMonths(2); System.out.println(ldt3); &#125; @Test public void test2()&#123; Instant ins = Instant.now(); System.out.println(ins);// 默认获取UTC时区 OffsetDateTime odt = ins.atOffset(ZoneOffset.ofHours(8)); System.out.println(odt); System.out.println(odt.toEpochSecond()); Instant ins2 = Instant.ofEpochSecond(1000); System.out.println(ins2); &#125; @Test public void test3()&#123; Instant ins1 = Instant.now(); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; Instant ins2 = Instant.now(); Duration duration = Duration.between(ins1, ins2); System.out.println(duration.toMillis()); System.out.println(\"======================================\"); LocalTime lt1 = LocalTime.now(); try &#123; Thread.sleep(1000); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; LocalTime lt2 = LocalTime.now(); System.out.println(Duration.between(lt1, lt2).toMillis()); &#125; @Test public void test4()&#123; LocalDate ld1 = LocalDate.of(2015, 6, 1); LocalDate ld2 = LocalDate.now(); Period period = Period.between(ld1, ld2); System.out.println(period); System.out.println(period.getYears()); System.out.println(period.getMonths()); System.out.println(period.getDays()); &#125; // TemporalAdjuster: 时间校正器 @Test public void test5()&#123; LocalDateTime ldt = LocalDateTime.now(); System.out.println(ldt); LocalDateTime ldt2 = ldt.withDayOfMonth(10); System.out.println(ldt2); LocalDateTime ldt3 = ldt.with(TemporalAdjusters.next(DayOfWeek.SUNDAY)); System.out.println(ldt3); // 自定义：下一个工作日 LocalDateTime ldt5 = ldt.with((l) -&gt; &#123; LocalDateTime ldt4 = (LocalDateTime) l; DayOfWeek dow = ldt4.getDayOfWeek(); if (dow.equals(DayOfWeek.FRIDAY)) &#123; return ldt4.plusDays(3); &#125; else if (dow.equals(DayOfWeek.SATURDAY)) &#123; return ldt4.plusDays(2); &#125; else &#123; return ldt4.plusDays(1); &#125; &#125;); System.out.println(ldt5); &#125; // DateTimeFormatter @Test public void test6()&#123; DateTimeFormatter dtf = DateTimeFormatter.ISO_DATE; LocalDateTime ldt = LocalDateTime.now(); String strDate = ldt.format(dtf); System.out.println(strDate); DateTimeFormatter dtf2 = DateTimeFormatter.ofPattern(\"yyyy年MM月dd日 HH:mm:ss\"); String strDate2 = ldt.format(dtf2); System.out.println(strDate2); LocalDateTime newDate = ldt.parse(strDate2, dtf2); System.out.println(newDate); &#125; // ZonedDate、ZonedTime、ZonedDateTime @Test public void test7()&#123; LocalDateTime ldt = LocalDateTime.now(ZoneId.of(\"Asia/Shanghai\")); System.out.println(ldt); ZonedDateTime zdt = ldt.atZone(ZoneId.of(\"Asia/Shanghai\")); System.out.println(zdt); &#125; 8.其他新特性重复注解与类型注解 Java 8对注解处理提供了两点改进：可重复的注解及可用于类型的注解。","tags":[{"name":"java","slug":"java","permalink":"https://sunshine-zwq.gitee.io/tags/java/"},{"name":"java8","slug":"java8","permalink":"https://sunshine-zwq.gitee.io/tags/java8/"},{"name":"Lambda","slug":"Lambda","permalink":"https://sunshine-zwq.gitee.io/tags/Lambda/"},{"name":"Stream","slug":"Stream","permalink":"https://sunshine-zwq.gitee.io/tags/Stream/"}]},{"title":"JS模块化","date":"2020-09-12T16:00:00.000Z","path":"2020/09/13/JS模块化/","text":"简介 什么是模块? 将一个复杂的程序依据一定的规则(规范)封装成几个块(文件), 并进行组合在一起 块的内部数据/实现是私有的, 只是向外部暴露一些接口(方法)与外部其它模块通信 一个模块的组成 数据—&gt;内部的属性 操作数据的行为—&gt;内部的函数 模块化 编码时是按照模块一个一个编码的, 整个项目就是一个模块化的项目 模块化的好处 避免命名冲突（减少命名空间污染） 更好的分离，按需加载 更高复用性 高可维护性 CommonJS 说明 每个文件都可当作一个模块 在服务器端：模块的加载是运行时同步加载的 在浏览器端：模块需要提前编译打包处理 基本语法 暴露模块 module.exports = value exports.xxx = value 引入模块 require(xxx) 第三方模块：xxx为模块名 自定义模块：xxx为模块文件路径 基于服务端应用（Node.js） 项目结构 12345678910|-modules |-module1.js |-module2.js |-module3.js|-app.js|-package.json &#123; &quot;name&quot;: &quot;commonJS-node&quot;, &quot;version&quot;: &quot;1.0.0&quot; &#125; 下载第三方模块 npm install uniq –save 模块化编码 module1.js12345module.exports = &#123; foo() &#123; console.log('moudle1 foo()') &#125;&#125; module2.js123module.exports = function () &#123; console.log('module2()')&#125; module3.js1234567exports.foo = function () &#123; console.log('module3 foo()')&#125;exports.bar = function () &#123; console.log('module3 bar()')&#125; app.js 12345678910111213141516171819202122/** 1. 定义暴露模块: module.exports = value; exports.xxx = value; 2. 引入模块: var module = require(模块名或模块路径); */\"use strict\";//引用模块let module1 = require('./modules/module1')let module2 = require('./modules/module2')let module3 = require('./modules/module3')let uniq = require('uniq')//使用模块module1.foo()module2()module3.foo()module3.bar()console.log(uniq([1, 3, 1, 4, 3])) 通过node运行app.js 命令: node app.js 工具: 右键–&gt;运行 基于浏览器端应用（Browserify ） 项目结构12345678910111213|-js |-dist &#x2F;&#x2F;打包生成文件的目录 |-src &#x2F;&#x2F;源码所在的目录 |-module1.js |-module2.js |-module3.js |-app.js &#x2F;&#x2F;应用主源文件|-index.html|-package.json &#123; &quot;name&quot;: &quot;browserify-test&quot;, &quot;version&quot;: &quot;1.0.0&quot; &#125; 下载browserify 全局: npm install browserify -g 局部: npm install browserify –save-dev 定义模块代码 module1.js12345module.exports = &#123; foo() &#123; console.log('moudle1 foo()') &#125;&#125; module2.js123module.exports = function () &#123; console.log('module2()')&#125; module3.js1234567exports.foo = function () &#123; console.log('module3 foo()')&#125;exports.bar = function () &#123; console.log('module3 bar()')&#125; app.js (应用的主js)1234567891011121314//引用模块let module1 = require('./module1')let module2 = require('./module2')let module3 = require('./module3')let uniq = require('uniq')//使用模块module1.foo()module2()module3.foo()module3.bar()console.log(uniq([1, 3, 1, 4, 3])) 打包处理js: browserify js/src/app.js -o js/dist/bundle.js 页面使用引入: 1&lt;script type=\"text/javascript\" src=\"js/dist/bundle.js\"&gt;&lt;/script&gt; AMD（浏览器端） require.js 基本语法 定义暴露模块 定义没有依赖的模块：define(function(){return 模块}) 定义有依赖的模块：define([‘module1’, ‘module2’], function(m1, m2){return 模块}) 引入模块: require([‘module1’, ‘module2’], function(m1, m2){//使用模块对象}) 配置: 123456789101112131415161718192021require.config(&#123; //基本路径 baseUrl : 'js/', //标识名称与路径的映射 paths : &#123; '模块1' : 'modules/模块1', '模块2' : 'modules/模块2', 'angular' : 'libs/angular', 'angular-messages' : 'libs/angular-messages' &#125;, //非AMD的模块 shim : &#123; 'angular' : &#123; exports : 'angular' &#125;, 'angular-messages' : &#123; exports : 'angular-messages', deps : ['angular'] &#125; &#125;&#125;) 代码实现： 下载require.js, 并引入 官网: http://www.requirejs.cn/ github : https://github.com/requirejs/requirejs 将require.js导入项目: js/libs/require.js 项目结构 12345678|-js |-libs |-require.js |-modules |-alerter.js |-dataService.js |-main.js|-index.html 定义require.js的模块代码 dataService.js 123456789define(function () &#123; let msg = 'Hello world' function getMsg() &#123; return msg.toUpperCase() &#125; return &#123;getMsg&#125;&#125;) alerter.js 12345678910define(['dataService', 'jquery'], function (dataService, $) &#123; let name = 'Tom2' function showMsg() &#123; $('body').css('background', 'gray') alert(dataService.getMsg() + ', ' + name) &#125; return &#123;showMsg&#125;&#125;) 应用主(入口)js: main.js 1234567891011121314151617(function () &#123; //配置 requirejs.config(&#123; //基本路径 baseUrl: \"js/\", //模块标识名与模块路径映射 paths: &#123; \"alerter\": \"modules/alerter\", \"dataService\": \"modules/dataService\", &#125; &#125;) //引入使用模块 requirejs( ['alerter'], function(alerter) &#123; alerter.showMsg() &#125;)&#125;)() 页面使用模块: 1&lt;script data-main=\"js/main\" src=\"js/libs/require.js\"&gt;&lt;/script&gt; 使用第三方基于require.js的框架(jquery) 将jquery的库文件导入到项目: js/libs/jquery-1.10.1.js 在main.js中配置jquery路径 123paths: &#123; &#39;jquery&#39;: &#39;libs&#x2F;jquery-1.10.1&#39; &#125; 在alerter.js中使用jquery 12345678define([&#39;dataService&#39;, &#39;jquery&#39;], function (dataService, $) &#123; var name &#x3D; &#39;xfzhang&#39; function showMsg() &#123; $(&#39;body&#39;).css(&#123;background : &#39;red&#39;&#125;) alert(name + &#39; &#39;+dataService.getMsg()) &#125; return &#123;showMsg&#125;&#125;) 使用第三方不基于require.js的框架(angular) 将angular.js导入项目 js/libs/angular.js 在main.js中配置 1234567891011121314151617181920212223242526272829(function () &#123; require.config(&#123; //基本路径 baseUrl: \"js/\", //模块标识名与模块路径映射 paths: &#123; //第三方库 'jquery' : './libs/jquery-1.10.1', 'angular' : './libs/angular', //自定义模块 \"alerter\": \"./modules/alerter\", \"dataService\": \"./modules/dataService\" &#125;, /* 配置不兼容AMD的模块 exports : 指定与相对应的模块名对应的模块对象 */ shim: &#123; 'angular' : &#123; exports : 'angular' &#125; &#125; &#125;) //引入使用模块 require( ['alerter', 'angular'], function(alerter, angular) &#123; alerter.showMsg() console.log(angular); &#125;)&#125;)() CMD（浏览器端） sea.js 基本语法 定义暴露模块: 定义没有依赖的模块 1234define(function(require, exports, module)&#123; exports.xxx = value module.exports = value&#125;) 定义有依赖的模块 12345678910define(function(require, exports, module)&#123; //引入依赖模块(同步) var module2 = require('./module2') //引入依赖模块(异步) require.async('./module3', function (m3) &#123; &#125;) //暴露模块 exports.xxx = value&#125;) 引入使用模块 123456define(function (require) &#123; var m1 = require('./module1') var m4 = require('./module4') m1.show() m4.show()&#125;) 使用模块seajs.use([‘模块1’, ‘模块2’]) 代码实现： 下载sea.js, 并引入 官网: http://seajs.org/ github : https://github.com/seajs/seajs 将sea.js导入项目: js/libs/sea.js 创建项目结构 12345678910|-js |-libs |-sea.js |-modules |-module1.js |-module2.js |-module3.js |-module4.js |-main.js|-index.html 定义sea.js的模块代码 module1.js 1234567891011define(function (require, exports, module) &#123; //内部变量数据 var data = 'Hello world' //内部函数 function show() &#123; console.log('module1 show() ' + data) &#125; //向外暴露 exports.show = show&#125;) module2.js 12345define(function (require, exports, module) &#123; module.exports = &#123; msg: 'I Will Back' &#125;&#125;) module3.js 1234define(function (require, exports, module) &#123; const API_KEY = 'abc123' exports.API_KEY = API_KEY&#125;) module4.js 1234567891011121314define(function (require, exports, module) &#123; //引入依赖模块(同步) var module2 = require('./module2') function show() &#123; console.log('module4 show() ' + module2.msg) &#125; exports.show = show //引入依赖模块(异步) require.async('./module3', function (m3) &#123; console.log('异步引入依赖模块3 ' + m3.API_KEY) &#125;)&#125;) main.js : 主(入口)模块 123456define(function (require) &#123; var m1 = require('./module1') var m4 = require('./module4') m1.show() m4.show()&#125;) index.html: 12345678910111213141516&lt;!--使用seajs: 1. 引入sea.js库 2. 如何定义导出模块 : define() exports module.exports 3. 如何依赖模块: require() 4. 如何使用模块: seajs.use()--&gt;&lt;script type=\"text/javascript\" src=\"js/libs/sea.js\"&gt;&lt;/script&gt;&lt;script type=\"text/javascript\"&gt; seajs.use('./js/modules/main')&lt;/script&gt; ​ ES6 ES6内置了模块化的实现 基本语法 定义暴露模块 : export 暴露一个对象: 1export default 对象 暴露多个: 123456export var xxx &#x3D; value1export let yyy &#x3D; value2var xxx &#x3D; value1let yyy &#x3D; value2export &#123;xxx, yyy&#125; 引入使用模块 : import default模块: 1import xxx from &#39;模块路径&#x2F;模块名&#39; 其它模块 12import &#123;xxx, yyy&#125; from &#39;模块路径&#x2F;模块名&#39;import * as module1 from &#39;模块路径&#x2F;模块名&#39; 问题: 所有浏览器还不能直接识别ES6模块化的语法 解决: 使用Babel将ES6—&gt;ES5(使用了CommonJS) —-浏览器还不能直接支行 使用Browserify—&gt;打包处理—-浏览器可以运行 代码实现： 定义package.json文件 1234&#123; \"name\" : \"es6-babel-browserify\", \"version\" : \"1.0.0\"&#125; 安装babel-cli, babel-preset-es2015和browserify npm install babel-cli browserify -g npm install babel-preset-es2015 –save-dev preset 预设(将es6转换成es5的所有插件打包) 定义.babelrc文件 123&#123; \"presets\": [\"es2015\"]&#125; 编码 js/src/module1.js 分别暴露 1234567export function foo() &#123; console.log('module1 foo()');&#125;export function bar() &#123; console.log('module1 bar()');&#125;export const DATA_ARR = [1, 3, 5, 1] js/src/module2.js 统一暴露 1234567891011let data = 'module2 data'function fun1() &#123; console.log('module2 fun1() ' + data);&#125;function fun2() &#123; console.log('module2 fun2() ' + data);&#125;export &#123;fun1, fun2&#125; js/src/module3.js 123456export default &#123; name: 'Tom', setName: function (name) &#123; this.name = name &#125;&#125; js/src/app.js 1234567891011121314151617import &#123;foo, bar&#125; from './module1'import &#123;DATA_ARR&#125; from './module1'import &#123;fun1, fun2&#125; from './module2'import person from './module3'import $ from 'jquery'$('body').css('background', 'red')foo()bar()console.log(DATA_ARR);fun1()fun2()person.setName('JACK')console.log(person.name); 编译 使用Babel将ES6编译为ES5代码(但包含CommonJS语法) : babel js/src -d js/lib 使用Browserify编译js : browserify js/lib/app.js -o js/lib/bundle.js 页面中引入测试 1&lt;script type=\"text/javascript\" src=\"js/lib/bundle.js\"&gt;&lt;/script&gt; 引入第三方模块(jQuery) 下载jQuery模块: npm install jquery@1 –save 在app.js中引入并使用 12import $ from 'jquery'$('body').css('background', 'red')","tags":[{"name":"js","slug":"js","permalink":"https://sunshine-zwq.gitee.io/tags/js/"},{"name":"js模块化","slug":"js模块化","permalink":"https://sunshine-zwq.gitee.io/tags/js%E6%A8%A1%E5%9D%97%E5%8C%96/"}]},{"title":"Node.js入门","date":"2020-09-05T16:00:00.000Z","path":"2020/09/06/Node.js入门/","text":"Node.js简介简介： (1).开发者：瑞安·达尔（Ryan Dahl） (2).Node.js是一个能够在服务器端运行JavaScript的开放源代码、跨平台JavaScript运行环境。 (3).Node采用Google开发的V8引擎运行js代码，使用事件驱动、非阻塞和异步I/O模型等技术来提高性能，可优化应用程序的传输量和规模。 (4).Node大部分基本模块都用JavaScript编写。在Node出现之前，JS通常作为客户端程序设计语言使用，以JS写出的程序常在用户的浏览器上运行。 特点： (1).Node.js允许通过JS和一系列模块来编写服务器端应用和网络相关的应用。 (2).核心模块包括文件系统I/O、网络（HTTP、TCP、UDP、DNS、TLS/SSL等）、二进制数据流、加密算法、数据流等等。Node模块的API形式简单，降低了编程的复杂度。 (3).使用框架可以加速开发。常用的框架有Express.js、Socket.IO和Connect等。Node.js的程序可以在Microsoft Windows、Linux、Unix、Mac OS X等服务器上运行。 (4).Node.js也可以使用CoffeeScript、TypeScript、Dart语言，以及其他能够编译成JavaScript的语言编程。 用途： • Web服务API，比如REST• 实时多人游戏• 后端的Web服务，例如跨域、服务器端的请求• 基于Web的应用• 多客户端的通信，如即时通信 Node的基本使用使用node执行js： 1node hello.js CommonJS规范ECMAScript标准的缺陷：• 没有模块系统• 标准库较少• 没有标准接口• 缺乏管理系统 CommonJS简介：• CommonJS规范的提出，主要是为了弥补当前JavaScript没有模块化标准的缺陷。• CommonJS规范为JS指定了一个美好的愿景，希望JS能够在任何地方运行。 模块引用• 在规范中，定义了require()方法，这个方法接收模块标识，以此将一个模块引入到当前运行环境中。使用require()引入模块以后，该函数会返回一个对象，这个对象代表的就是引入的模块。 模块引用的示例代码： 1var math = require('math'); 注意： 1.require()可以传递一个文件的路径作为参数，node会自动根据该路径来引入外部模块 2.这里的路径，如果使用相对路径，必须以 ./ 或者 ../ 开头 3.路径的后缀.js可以省略 模块定义• 在运行环境中，提供了exports对象用于导出当前模块的方法或者变量，并且它是唯一的导出的出口。• 在模块中还存在一个module对象，它代表模块自身，而exports是module的属性。• 在Node中一个文件就是一个模块。• 在Node中，每一个js文件中的js代码都是独立运行在一个函数中，而不是全局作用域，所以一个模块中的变量和函数在其他模块中无法访问。 使用exports向外暴露属性或方法示例： 123exports.x = 10;exports.xxx = function() &#123;&#125;;module.exports = &#123;&#125;; 模块标识• 模块标识其实就是模块的名字，也就是传递给require()方法的参数，它必须是符合驼峰命名法的字符串，或者是以 ./ 或 ../ 开头的相对路径、或者绝对路径。 模块分为两大类：核心模块、文件模块。 (1).核心模块 • 由node引擎提供的模块 • 核心模块的标识，就是模块的名字 (2).文件模块 • 由用户自己创建的模块 • 文件模块的标识，就是文件的路径（绝对路径，或相对路径） 在node中有一个全局变量global，它的作用和网页中window类似 • 在全局中创建的变量都会作为global的属性保存 • 在全局中创建的函数都会作为global的方法保存 当node在执行模块中的代码时，它会在代码首尾包裹一层函数，代码示例： 原始代码： 1234567891011121314var a = 10;/** 在node中有一个全局变量global，它的作用和网页中window类似 • 在全局中创建的变量都会作为global的属性保存 • 在全局中创建的函数都会作为global的方法保存 */// console.log(global.a);/** arguments.callee - 这个属性保存的是当前执行的函数对象 */console.log(arguments.callee + \"\"); 实际执行的代码： 12345678910111213141516function (exports, require, module, __filename, __dirname) &#123; var a = 10;/** 在node中有一个全局变量global，它的作用和网页中window类似 • 在全局中创建的变量都会作为global的属性保存 • 在全局中创建的函数都会作为global的方法保存 */// console.log(global.a);/** arguments.callee - 这个属性保存的是当前执行的函数对象 */console.log(arguments.callee + \"\");&#125; 实际上模块中的代码都是包装在一个函数中执行的，并且在函数执行时，同时传递进了5个实参： (1).exports：该对象用于将变量或函数暴露到外部 (2).require：函数，用来引入外部的模块 (3).module：代表的就是当前模块本身，exports就是module的属性 (4).__filename：当前模块的完整路径 (5).__dirname：当前模块所在文件夹的完整路径 exports和module.exports的区别： (1).通过exports只能使用 . 的方式来向外暴露内部变量，如exports.xxx = yyy (2).module.exports既可以通过 . 的方式，也可以直接赋值 ​ module.exports.xxx = yyy ​ module.exports = { ​ } NPM包 package• CommonJS的包规范允许我们将一组相关的模块组合到一起，形成一组完整的工具。• CommonJS的包规范由包结构和包描述文件两个部分组成 包结构：用于组织包中的各种文件 • 包实际上就是一个压缩文件，解压以后还原为目录。符合规范的目录，应该包含如下文件：– package.json 描述文件（必须要有）– bin 可执行二进制文件– lib js代码– doc 文档– test 单元测试 包描述文件：描述包的相关信息，以供外部读取分析 • 包描述文件用于表达非代码相关的信息，它是一个JSON格式的文件 – package.json，位于包的根目录下，是包的重要组成部分。• package.json中的字段– name、description、version、keywords、maintainers、contributors、bugs、licenses、repositories、dependencies、homepage、os、cpu、engine、builtin、directories、implements、scripts、author、bin、main、devDependencies。 NPM(Node Package Manager)• CommonJS包规范是理论，NPM是其中一种实践。• 对于Node而言，NPM帮助其完成了第三方模块的发布、安装和依赖等。借助NPM，Node与第三方模块之间形成了很好的一个生态系统。 NPM命令常用命令： • npm –v 查看npm的版本 • npm version 查看所有模块的版本 • npm search 包名 搜索包 • npm install / i 包名 安装包 • npm remove / r 包名 删除包 • npm install 包名 –save 安装包并添加到依赖中 • npm install 下载当前项目所依赖的包 • npm install 包名 -g 全局安装包（全局安装的包一般都是一些工具） • npm init 初始化项目生成package.json文件 • npm install 包名 –registry=地址 从镜像源安装 • npm config set registry 地址 设置镜像源 安装cnpm（使用淘宝镜像）: 1npm install -g cnpm --registry=https://registry.npm.taobao.org Node搜索包的流程： • Node在使用模块名字来引入模块时，它会首先在当前目录的node_modules中寻找是否包含有该模块 • 如果有则直接使用，如果没有则去上一级目录的node_modules中寻找 • 如果有则直接使用，如果没有则再去上一级目录寻找，直到找到为止 • 直到找到磁盘的根目录，如果依然没有，则报错 文件系统BufferBuffer(缓冲区) • 从结构上看Buffer非常像一个数组，它的元素为16进制的两位数。 • 实际上一个元素就表示内存中的一个字节。 • 实际上Buffer中的内存不是通过JavaScript分配的，而是在底层通过C++申请的。 • 也就是我们可以直接通过Buffer来创建内存中的空间。 Buffer的操作 • Buffer.from(str) 将一个字符串转换为buffer • Buffer.alloc(size) 创建一个指定大小的buffer • Buffer.allocUnsafe(size) 创建一个指定大小的buffer，但是可能包含敏感数据 • buf.toString() 将缓冲区的数据转换为字符串 写入操作• 向缓冲区中写入字符串 – buf.write(string[, offset[, length]][, encoding])• 替换指定索引位置的数据 – buf[index]• 将指定值填入到缓冲区的指定位置 – buf.fill(value[, offset[, end]][, encoding]) 读取操作• 将缓冲区中的内容，转换为一个字符串返回 – buf.toString([encoding[, start[, end]]])• 读取缓冲区指定索引的内容 – buf[index] 其他操作• 复制缓冲区 – buf.copy(target[, targetStart[, sourceStart[, sourceEnd]]])• 对缓冲区切片 – buf.slice([start[, end]])• 拼接缓冲区 – Buffer.concat(list[, totalLength]) fs（文件系统）• 在Node中，与文件系统的交互是非常重要的，服务器的本质就将本地的文件发送给远程的客户端• Node通过fs模块来和文件系统进行交互• 该模块提供了一些标准文件访问API来打开、读取、写入文件，以及与其交互。• 要使用fs模块，首先需要对其进行加载 – const fs = require(“fs”); 同步和异步调用• fs模块中所有的操作都有两种形式可供选择同步和异步。• 同步文件系统会阻塞程序的执行，也就是除非操作完毕，否则不会向下执行代码。• 异步文件系统不会阻塞程序的执行，而是在操作完成时，通过回调函数将结果返回。 打开和关闭文件• 打开文件 – fs.open(path, flags[, mode], callback) – fs.openSync(path, flags[, mode])• 关闭文件 – fs.close(fd, callback) – fs.closeSync(fd) 打开状态(mode)r 读取文件 , 文件不存在则出现异常r+ 读写文件 , 文件不存在则出现异常rs 在同步模式下打开文件用于读取rs+ 在同步模式下打开文件用于读写w 打开文件用于写操作 , 如果不存在则创建，如果存在则截断wx 打开文件用于写操作 , 如果 存在则打开失败w+ 打开文件用于读写 , 如果不存在则创建 , 如果存在则截断wx+ 打开文件用于读写 , 如果 存在则打开失败a 打开文件用于追加 , 如果不存在则创建ax 打开文件用于追加 , 如果路径存在则失败a+ 打开文件进行读取和追加 , 如果不存在则创建该文件ax+ 打开文件进行读取和追加 , 如果路径存在则失败 同步文件写入• fs.writeSync(fd, buffer, offset, length[, position])• fs.writeSync(fd, data[, position[, encoding]]) • 要完成同步写入文件，先需要通过openSync()打开文件来获取一个文件描述符，然后在通过writeSync()写入文件。 • 参数 – fd 文件描述符，通过openSync()获取 – data 要写入的数据（String 或 Buffer） – offset buffer写入的偏移量 – length 写入的长度 – position 写入的起始位置 – encoding 写入编码 示例代码： 123456789101112131415161718192021222324252627282930313233343536/** 文件系统（File System） - 文件系统简单来说就是通过Node来操作系统中的文件 - 使用文件系统，需要先引入fs模块，fs是核心模块，直接引入不需要下载 同步文件的写入 - 手动操作的步骤 1.打开文件 fs.openSync(path, flags[, mode]) - path 要打开的文件路径 - flags 打开文件要做的操作的类型 r 只读的 w 可写的 - mode 设置文件的操作权限，一般不传 返回值：该方法会返回一个文件的描述符作为结果，我们可以通过该描述符来对文件进行各种操作 2.向文件中写入内容 fs.writeSync(fd, string[, position[, encoding]]) - fd 文件的描述符，需要传递写入的文件的描述符 - string 要写入的内容 - position 写入的起始位置 - encoding 写入的编码，默认utf-8 3.保存并关闭文件 fs.close(fd) - fd 要关闭的文件的描述符 */var fs = require(\"fs\");// 打开文件var fd = fs.openSync(\"hello.txt\", \"w\");// 向文件中写入内容fs.writeSync(fd, \"今天天气真不错~~~\");// 关闭文件fs.closeSync(fd); 异步文件写入• fs.write(fd, buffer, offset, length[, position], callback)• fs.write(fd, data[, position[, encoding]], callback) • 要使用异步写入文件，先需要通过open()打开文件，然后在回调函数中通过write()写入。 • 参数： – fd 文件描述符 – data 要写入的数据（String 或 Buffer） – offset buffer写入的偏移量 – length 写入的长度 – position 写入的起始位置 – encoding 写入编码 示例代码： 12345678910111213141516171819202122232425262728293031323334/** 异步文件写入 fs.open(path, flags[, mode], callback) - 用来打开一个文件 - 异步调用的方法，结果都是通过回调函数的参数返回的 - 回调函数的两个参数： - err 错误对象，如果没有错误则为null - fd 文件的描述符 fs.write(fd, string[, position[, encoding]], callback) - 用来异步写入一个文件 fs.close(fd, callback) - 用来关闭文件 */var fs = require(\"fs\");// 打开文件fs.open(\"hello2.txt\", \"w\", function (err, fd) &#123; if(!err)&#123; fs.write(fd, \"这是异步写入的内容\", function (err) &#123; if(!err)&#123; console.log(\"写入成功~~~\"); &#125; // 关闭文件 fs.close(fd, function () &#123; if(!err)&#123; console.log(\"文件已关闭~~~\"); &#125; &#125;) &#125;) &#125;else&#123; console.log(err); &#125;&#125;) 简单文件写入• fs.writeFile(file, data[, options], callback)• fs.writeFileSync(file, data[, options]) • 参数： – file 文件路径 – data 被写入的内容，可以是String或Buffer – options 对象，包含属性（encoding、mode、flag） – callback 回调函数 示例代码： 12345678910111213141516171819202122/** 简单文件写入 fs.writeFile(file, data[, options], callback) fs.writeFileSync(file, data[, options]) - file 要操作的文件路径 - data 要写入的数据 - options 选项，可以对写入进行一些设置 - flag r 只读 w 可写 a 追加 - callback 当写入完成以后执行的函数 */var fs = require(\"fs\");fs.writeFile(\"hello3.txt\", \"这是通过writeFile写入的内容\", &#123;flag: \"a\"&#125;, function (err) &#123; if(!err)&#123; console.log(\"写入成功~~~\"); &#125;else&#123; console.log(err); &#125;&#125;) 流式文件写入• 往一个文件中写入大量数据时，最好的方法之一是使用流。• 若要将数据异步传送到文件，首需要使用以下语法创建一个Writable对象： – fs.createWriteStream(path[, options]) • path 文件路径 • options {encoding:””,mode:””,flag:””}• 一旦你打开了Writable文件流，就可以使用write()方法来写入它，写入完成后，再调用end()方法来关闭流。 示例代码： 1234567891011121314151617181920212223242526272829303132333435363738/** 同步、异步、简单文件的写入，都不适合大文件的写入，性能较差，容易导致内存溢出 */var fs = require(\"fs\");// 流式文件写入// 创建一个可写流/** fs.createWriteStram(path[, options]) - 可以用来创建一个可写流 - path 文件路径 - options 配置的参数 */var ws = fs.createWriteStream(\"hello5.txt\");// 可以通过监听流的open和close事件来监听流的打开和关闭/** on(事件字符串， 回调函数) - 可以为对象绑定一个事件 once(事件字符串， 回调函数) - 可以为对象绑定一个一次性的事件，该事件将会在触发一次之后自动失效 */ws.once(\"open\", function () &#123; console.log(\"流打开了~\")&#125;)ws.once(\"close\", function () &#123; console.log(\"流关闭了~\")&#125;)// 通过ws向文件中输出内容ws.write(\"通过可写流写入文件的内容1\");ws.write(\"通过可写流写入文件的内容2\");ws.write(\"通过可写流写入文件的内容3\");ws.write(\"通过可写流写入文件的内容4\");ws.write(\"通过可写流写入文件的内容5\");// 关闭流ws.end(); 同步文件读取• fs.readSync(fd, buffer, offset, length, position) – 参数： • fd 文件描述符 • buffer 读取文件的缓冲区 • offset buffer的开始写入的位置 • length 要读取的字节数 • position 开始读取文件的位置 异步文件读取• fs.read(fd, buffer, offset, length, position, callback) – 参数： • fd 文件描述符 • buffer 读取文件的缓冲区 • offset buffer的开始写入的位置 • length 要读取的字节数 • position 开始读取文件的位置 • callback 回调函数 参数err , bytesRead , buffer 简单文件读取• fs.readFile(file[, options], callback)• fs.readFileSync(file[, options]) – 参数： • file 文件路径或文件描述符 • options – encoding 默认 = null – flag 默认 = ‘r’ • callback 回调函数，有两个参数err 、data 示例代码： 12345678910111213141516171819202122232425/** 简单文件读取 fs.readFile(path[, options], callback) fs.readFileSync(path[, options]) - path 要读取的文件路径 - options 读取的选项 - callback 回调函数，通过回调函数将读取到内容返回(err, data) err 错误对象 data 读取到的数据，会返回一个Buffer */var fs = require(\"fs\");fs.readFile(\"hello3.txt\", function (err, data) &#123; if(!err)&#123; console.log(data.toString()) // 将data写入到文件中 fs.writeFile(\"copyOf_hello3.txt\", data, function (err) &#123; if(!err)&#123; console.log(\"文件写入成功\"); &#125;else&#123; console.log(err); &#125; &#125;) &#125;&#125;) 流式文件读取• 从一个文件中读取大量的数据时，最好的方法之一就是流式读取，这样将把一个文件作为Readable流的形式打开。• 要从异步从文件传输数据，首先需要通过以下语法创建一个Readable流对象： – fs.createReadStream(path[, options]) • path 文件路径 • options {encoding:””,mode:””,flag:””}• 当你打开Readable文件流以后，可以通过readable事件和read()请求，或通过data事件处理程序轻松地从它读出。 示例代码： 1234567891011121314151617181920212223242526272829303132/** 流式文件读取也适用于一些比较大的文件，可以分多次将文件读取到内存中 */var fs = require(\"fs\");// 创建一个可读流var rs = fs.createReadStream(\"avatar.jpg\");// 创建一个可写流var ws = fs.createWriteStream(\"test.jpg\");// 监听流的打开和关闭rs.once(\"open\", function () &#123; console.log(\"可读流打开了~\")&#125;)rs.once(\"close\", function () &#123; console.log(\"可读流关闭了~\"); // 数据读取完毕，关闭可写流 ws.end();&#125;)ws.once(\"open\", function () &#123; console.log(\"可写流打开了~\")&#125;)ws.once(\"close\", function () &#123; console.log(\"可写流关闭了~\")&#125;)// 如果要读取一个可读流中的数据，必须要为可读流绑定一个data事件，data事件绑定完毕，它会自动开始读取数据rs.on(\"data\", function (data) &#123; console.log(data); // 将读取到的数据写入到可写流中 ws.write(data);&#125;) 利用pipe()实现更简洁的文件复制： 123456789var fs = require(\"fs\");// 创建一个可读流var rs = fs.createReadStream(\"avatar.jpg\");// 创建一个可写流var ws = fs.createWriteStream(\"test.jpg\");// pipe()可以将可读流中的内容，直接输出到可写流中rs.pipe(ws); 其他操作• 验证路径是否存在 – fs.exists(path，callback) – fs.existsSync(path) • 获取文件信息 – fs.stat(path, callback) – fs.statSync(path) • 删除文件 – fs.unlink(path, callback) – fs.unlinkSync(path) • 列出文件 – fs.readdir(path[, options], callback) – fs.readdirSync(path[, options]) • 截断文件 – fs.truncate(path, len, callback) – fs.truncateSync(path, len) • 建立目录 – fs.mkdir(path[, mode], callback) – fs.mkdirSync(path[, mode]) • 删除目录 – fs.rmdir(path, callback) – fs.rmdirSync(path) • 重命名文件和目录（可实现剪切的功能） – fs.rename(oldPath, newPath, callback) – fs.renameSync(oldPath, newPath) • 监视文件更改写入 – fs.watchFile(filename[, options], listener)","tags":[{"name":"jQuery","slug":"jQuery","permalink":"https://sunshine-zwq.gitee.io/tags/jQuery/"},{"name":"Node.js","slug":"Node-js","permalink":"https://sunshine-zwq.gitee.io/tags/Node-js/"}]},{"title":"jQuery包裹节点方法wrap()、wrapAll()、wrapInner()的区别","date":"2020-08-28T16:00:00.000Z","path":"2020/08/29/jQuery包裹节点方法wrap()、wrapAll()、wrapInner()的区别/","text":"1.wrap()方法原始DOM代码： 1234&lt;div id=\"container\"&gt; &lt;div&gt;姓名：小明&lt;/div&gt; &lt;div&gt;年龄：20岁&lt;/div&gt;&lt;/div&gt; 使用wrap()： 1$(\"#container\").wrap('&lt;div class=\"wrapper\"&gt;&lt;/div&gt;'); 处理后DOM代码： 123456&lt;div class=\"wrapper\"&gt; &lt;div id=\"container\"&gt; &lt;div&gt;姓名：小明&lt;/div&gt; &lt;div&gt;年龄：20岁&lt;/div&gt; &lt;/div&gt;&lt;/div&gt; 效果：给$选择器的所有元素外部包裹一层wrapper 2.wrapAll()方法原始DOM代码： 12345&lt;div id=\"container\"&gt; &lt;p&gt;姓名：小明&lt;/p&gt; &lt;p&gt;年龄：20岁&lt;/p&gt; &lt;div&gt;性别：男&lt;div&gt;&lt;/div&gt; 使用wrapAll()： 1$(\"p\").wrapAll('&lt;div class=\"wrapper\"&gt;&lt;/div&gt;'); 处理后DOM代码： 1234567&lt;div id=\"container\"&gt; &lt;div class=\"wrapper\"&gt; &lt;p&gt;姓名：小明&lt;/p&gt; &lt;p&gt;年龄：20岁&lt;/p&gt; &lt;/div&gt; &lt;div&gt;性别：男&lt;div&gt;&lt;/div&gt; 效果：给$选择器的全部匹配元素的外部包裹一层wrapper 3.wrapInner()方法原始DOM代码： 1234&lt;div id=\"container\"&gt; &lt;div&gt;姓名：小明&lt;/div&gt; &lt;div&gt;年龄：20岁&lt;/div&gt;&lt;/div&gt; 使用wrapInner()： 1$(\"#container\").wrapInner('&lt;div class=\"wrapper\"&gt;&lt;/div&gt;'); 处理后DOM代码： 123456&lt;div id=\"container\"&gt; &lt;div class=\"wrapper\"&gt; &lt;div&gt;姓名：小明&lt;/div&gt; &lt;div&gt;年龄：20岁&lt;/div&gt; &lt;/div&gt;&lt;/div&gt; 效果：给$选择器的所有元素内部包裹一层wrapper","tags":[{"name":"前端","slug":"前端","permalink":"https://sunshine-zwq.gitee.io/tags/%E5%89%8D%E7%AB%AF/"},{"name":"jQuery","slug":"jQuery","permalink":"https://sunshine-zwq.gitee.io/tags/jQuery/"}]},{"title":"用apache的ftpserver搭建FTP服务器","date":"2020-08-22T16:00:00.000Z","path":"2020/08/23/用apache的ftpserver搭建FTP服务器/","text":"maven依赖12345&lt;dependency&gt; &lt;groupId&gt;org.apache.ftpserver&lt;/groupId&gt; &lt;artifactId&gt;ftpserver-core&lt;/artifactId&gt; &lt;version&gt;1.1.1&lt;/version&gt;&lt;/dependency&gt; 主要代码12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970import org.apache.ftpserver.FtpServer;import org.apache.ftpserver.FtpServerFactory;import org.apache.ftpserver.ftplet.Authority;import org.apache.ftpserver.listener.ListenerFactory;import org.apache.ftpserver.usermanager.impl.BaseUser;import org.apache.ftpserver.usermanager.impl.WritePermission;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import java.util.ArrayList;import java.util.List;/** * 搭建ftp服务器 * @author zhuwq * @date 2020/8/21 17:27 */public class MyFtpServer &#123; private static Logger logger = LoggerFactory.getLogger(MyFtpServer.class); /** * 启动FTP服务 * @param port 端口 * @param username ftp用户名 * @param password ftp用户密码 * @param homeDirectory 主页目录 * @return */ public static boolean startServer(int port, String username, String password, String homeDirectory)&#123; logger.info(\"MyFtpServer.startServer[port:&#123;&#125;,username:&#123;&#125;,password:&#123;&#125;,homeDirectory:&#123;&#125;]\", port, username, password, homeDirectory); try&#123; FtpServerFactory serverFactory = new FtpServerFactory(); ListenerFactory factory = new ListenerFactory(); //设置监听端口 factory.setPort(port); //替换默认监听 serverFactory.addListener(\"default\", factory.createListener()); //用户名 BaseUser user = new BaseUser(); user.setName(username); //密码 如果不设置密码就是匿名用户 user.setPassword(password); //用户主目录 user.setHomeDirectory(homeDirectory); List&lt;Authority&gt; authorities = new ArrayList&lt;Authority&gt;(); //增加写权限 authorities.add(new WritePermission()); user.setAuthorities(authorities); //增加该用户 serverFactory.getUserManager().save(user); FtpServer server = serverFactory.createServer(); server.start(); logger.info(\"MyFtpServer.startServer success!!!\"); return true; &#125;catch (Exception e)&#123; e.printStackTrace(); logger.error(e.getMessage(), e); return false; &#125; &#125;&#125; 测试代码1234567public static void main(String[] args) &#123; int port = 21; String username = \"admin\"; String password = \"123456\"; String homeDirectory = \"E:\\\\FTPServer\"; MyFtpServer.startServer(port, username, password, homeDirectory); &#125; 参考链接：https://blog.csdn.net/fengsheng5210/article/details/78140746","tags":[{"name":"java","slug":"java","permalink":"https://sunshine-zwq.gitee.io/tags/java/"},{"name":"ftp","slug":"ftp","permalink":"https://sunshine-zwq.gitee.io/tags/ftp/"}]},{"title":"json转换","date":"2020-07-11T16:00:00.000Z","path":"2020/07/12/json转换/","text":"fastjsonjson字符串转JSONObject1JSONObject jsonObject = JSON.parseObject(json); json字符串转对象1Student student = JSONObject.parseObject(json, Student.class); json字符串转List1List&lt;Student&gt; studentList = JSONObject.parseArray(json, Student.class); json字符串转Map1Map&lt;String,String&gt; map = JSONObject.parseObject(json, Map.class); 对象转json字符串1String json = JSON.toJSONString(obj);","tags":[{"name":"json","slug":"json","permalink":"https://sunshine-zwq.gitee.io/tags/json/"}]},{"title":"ECMAScript入门","date":"2020-03-18T16:43:38.000Z","path":"2020/03/19/ECMAScript入门/","text":"基本介绍123456789101112131. 它是一种由ECMA组织（前身为欧洲计算机制造商协会）制定和发布的脚本语言规范2. 而我们学的 JavaScript 是ECMA的实现, 但术语ECMAScript和JavaScript平时表达同一个意思3. JS包含三个部分： 1). ECMAScript（核心） 2). 扩展&#x3D;&#x3D;&gt;浏览器端 * BOM（浏览器对象模型） * DOM（文档对象模型） 3). 扩展&#x3D;&#x3D;&gt;服务器端 * Node4. ES的几个重要版本 * ES5 : 09年发布 * ES6(ES2015) : 15年发布, 也称为ECMA2015 * ES7(ES2016) : 16年发布, 也称为ECMA2016 (变化不大) ES5严格模式1234567891011121314151. 理解: * 除了正常运行模式(混杂模式)，ES5添加了第二种运行模式：&quot;严格模式&quot;（strict mode）。 * 顾名思义，这种模式使得Javascript在更严格的语法条件下运行2. 目的&#x2F;作用 * 消除Javascript语法的一些不合理、不严谨之处，减少一些怪异行为 * 消除代码运行的一些不安全之处，为代码的安全运行保驾护航 * 为未来新版本的Javascript做好铺垫3. 使用 * 在全局或函数的第一条语句定义为: &#39;use strict&#39;; * 如果浏览器不支持, 只解析为一条简单的语句, 没有任何副作用4. 语法和行为改变 * 必须用var声明变量 * 禁止自定义的函数中的this指向window * 创建eval作用域 * 对象不能有重名的属性 示例代码： 12345678910111213141516171819202122&lt;script type=\"text/javascript\"&gt; 'use strict'; // username = 'kobe'; var username = 'kobe'; console.log(username); function Person (name, age) &#123; this.name = name; this.age = age; &#125; // Person('kobe', 41); new Person('kobe', 41); var str = 'NBA'; eval('var str = \"CBA\"; alert(str)'); alert(str); var obj = &#123; username: 'kobe', // username: 'wade' &#125;&lt;/script&gt; JSON对象12341. JSON.stringify(obj&#x2F;arr) * js对象(数组)转换为json对象(数组)2. JSON.parse(json) * json对象(数组)转换为js对象(数组) Object扩展12345678910111213ES5给Object扩展了一些静态方法, 常用的2个:1. Object.create(prototype, [descriptors]) * 作用: 以指定对象为原型创建新的对象 * 为新的对象指定新的属性, 并对属性进行描述 - value : 指定值 - writable : 标识当前属性值是否是可修改的, 默认为false - configurable: 标识当前属性是否可以被删除 默认为false - enumerable： 标识当前属性是否能用for in 枚举 默认为false2. Object.defineProperties(object, descriptors) * 作用: 为指定对象定义扩展多个属性 * get ：用来获取当前属性值的回调函数（需要取值时才会调用，“惰性求值”） * set ：修改当前属性值得触发的回调函数，并且实参即为修改后的值 * 存取器属性：setter,getter一个用来存值，一个用来取值 示例代码： 12345678910111213141516171819202122232425262728293031323334353637var obj = &#123;username: 'damu', age: 30&#125;;var obj1 = &#123;&#125;;obj1 = Object.create(obj, &#123; sex: &#123; value: '男', writable: true, configurable: true, enumerable: true &#125;&#125;);console.log(obj1.sex);obj1.sex = '女';console.log(obj1.sex);// delete obj1.sex;console.log(obj1);for(var i in obj1)&#123; console.log(i);&#125;var obj2 = &#123;firstName: 'kobe', lastName: 'bryant'&#125;;Object.defineProperties(obj2, &#123; fullName: &#123; get: function()&#123;// 获取扩展属性的值（获取扩展属性值时get会自动调用） return this.firstName + ' ' + this.lastName; &#125;, set: function(data)&#123;// 监听扩展属性，当扩展属性发生变化的时候会自动调用（变化后的值作为实参传入） var names = data.split(' '); this.firstName = names[0]; this.lastName = names[1]; &#125; &#125;&#125;)console.log(obj2.fullName);obj2.fullName = 'tim duncan';console.log(obj2.fullName);console.log(obj2.lastName); 123对象本身的两个方法* get propertyName()&#123;&#125; 用来得到当前属性值的回调函数* set propertyName()&#123;&#125; 用来监视当前属性值变化的回调函数 示例代码： 123456789101112131415var obj = &#123; firstName: 'curry', lastName: 'stephen', get fullName()&#123; return this.firstName + ' ' + this.lastName; &#125;, set fullName(data)&#123; var names = data.split(' '); this.firstName = names[0]; this.lastName = names[1]; &#125;&#125;;console.log(obj);obj.fullName = 'kobe bryant';console.log(obj.fullName); Array扩展123451. Array.prototype.indexOf(value) : 得到值在数组中的第一个下标2. Array.prototype.lastIndexOf(value) : 得到值在数组中的最后一个下标3. Array.prototype.forEach(function(item, index)&#123;&#125;) : 遍历数组4. Array.prototype.map(function(item, index)&#123;&#125;) : 遍历数组返回一个新的数组，返回加工之后的值5. Array.prototype.filter(function(item, index)&#123;&#125;) : 遍历过滤出一个新的子数组， 返回条件为true的值 示例代码： 12345678910111213141516171819202122232425/* 需求: 1. 输出第一个6的下标 2. 输出最后一个6的下标 3. 输出所有元素的值和下标 4. 根据arr产生一个新数组,要求每个元素都比原来大10 5. 根据arr产生一个新数组, 返回的每个元素要大于4 */var arr = [2,4,3,1,2,6,5,4];console.log(arr.indexOf(4));console.log(arr.lastIndexOf(4));arr.forEach(function(item, index)&#123; console.log(item, index);&#125;)var arr1 = arr.map(function (item, index) &#123; return item + 10;&#125;)console.log(arr1);var arr2 = arr.filter(function (item, index) &#123; return item &gt; 4;&#125;)console.log(arr2); Function扩展1234561. Function.prototype.bind(obj) : * 作用: 将函数内的this绑定为obj, 并将函数返回2. 面试题: 区别bind()与call()和apply()? * 都能指定函数中的this * call()&#x2F;apply()是立即调用函数 * bind()是将函数返回 示例代码： 123456789101112131415161718192021var obj = &#123;username: 'kobe'&#125;;function foo(data)&#123; console.log(this, data);&#125;// 直接调用foo方法打印的this是Window// foo();// call和apply的方法作用一样，区别在于传参的方式foo.call(obj, 33);// 直接从第2个参数开始，依次传入foo.apply(obj, [33]);// 第二个参数必须是数组，参数放在数组里// bind的特点：绑定完this不会立即调用当前的函数，而是将函数返回var bar = foo.bind(obj);bar();// bind的传参方式和call一样foo.bind(obj, 33)();// 应用举例setTimeout(function()&#123; console.log(this);&#125;.bind(obj), 1000); ES6（常用）let关键字1234567891. 作用: * 与var类似, 用于声明一个变量2. 特点: * 在块作用域内有效 * 不能重复声明 * 不会预处理（即不能在声明之前使用，会抛出异常，而var在声明前使用值是undefined）, 不存在提升3. 应用: * 循环遍历加监听 * 使用let取代var是趋势 示例代码： 1234567891011121314151617181920212223242526272829303132333435// console.log(username);let username = 'kobe';// let username = 'wade';console.log(username);let btns = document.getElementsByTagName('button');for(var i = 0; i &lt; btns.length; i++)&#123; var btn = btns[i]; btn.onclick = function () &#123; // 打印出来的都是3 alert(i); &#125;&#125;// 解决方法1：用闭包函数btns = document.getElementsByTagName('button');for(var i = 0; i &lt; btns.length; i++)&#123; var btn = btns[i]; (function(i)&#123; btn.onclick = function () &#123; // 打印出来的都是3 alert(i); &#125; &#125;)(i)&#125;// 解决方法2：用let关键字btns = document.getElementsByTagName('button');for(let i = 0; i &lt; btns.length; i++)&#123; var btn = btns[i]; btn.onclick = function () &#123; // 打印出来的都是3 alert(i); &#125;&#125; const关键字12345671. 作用: * 定义一个常量2. 特点: * 不能修改 * 其它特点同let3. 应用: * 保存不用改变的数据 解构赋值123456781. 理解: * 从对象或数组中提取数据, 并赋值给变量(多个)2. 对象的解构赋值 let &#123;n, a&#125; &#x3D; &#123;n:&#39;tom&#39;, a:12&#125;3. 数组的解构赋值 let [a,b] &#x3D; [1, &#39;atguigu&#39;];4. 用途 * 给多个形参赋值 示例代码： 1234567891011121314let obj = &#123;username: 'kobe', age: 39&#125;;// let username = obj.username;// let age = obj.age;let &#123;username, age&#125; = obj;console.log(username, age);let arr = [1,3,5,'abc',true];let [,,a,b] = arr;console.log(a, b);function foo(&#123;username, age&#125;)&#123;// &#123;username, age&#125; = obj console.log(username, age);&#125;foo(obj); 模板字符串1231. 模板字符串 : 简化字符串的拼接 * 模板字符串必须用 &#96;&#96; 包含 * 变化的部分使用$&#123;xxx&#125;定义 示例代码： 12345let obj = &#123;username: 'kobe', age: 39&#125;;let str = '我的名字叫：' + obj.username + '，我今年的年龄是：' + obj.age;console.log(str);str = `我的名字叫：$&#123;obj.username&#125;，我今年的年龄是：$&#123;obj.age&#125;`;console.log(str); 简化的对象写法1234567891011简化的对象写法* 省略同名的属性值* 省略方法的function* 例如: let x &#x3D; 1; let y &#x3D; 2; let point &#x3D; &#123; x, y, setX (x) &#123;this.x &#x3D; x&#125; &#125;; 箭头函数123456789101112131415* 作用: 定义匿名函数* 基本语法: * 没有参数: () &#x3D;&gt; console.log(&#39;xxxx&#39;) * 一个参数: i &#x3D;&gt; i+2 * 大于一个参数: (i,j) &#x3D;&gt; i+j * 函数体不用大括号: 默认返回结果 * 函数体如果有多个语句, 需要用&#123;&#125;包围，若有需要返回的内容，需要手动返回* 使用场景: 多用来定义回调函数* 箭头函数的特点： 1、简洁 2、箭头函数没有自己的this，箭头函数的this不是调用的时候决定的，而是在定义的时候处在的对象就是它的this 3、扩展理解： 箭头函数的this看外层的是否有函数， 如果有，外层函数的this就是内部箭头函数的this， 如果没有，则this是window。 示例代码： 123456789101112131415161718192021222324252627282930313233// 不同传参的情况// 1、没有形参let fun = () =&gt; console.log('我是箭头函数');fun();// 2、只有1个形参，()可以省略let fun2 = a =&gt; console.log(a);fun2('aaa');// 3、两个及以上形参，()不能省略let fun3 = (x, y) =&gt; console.log(x, y);fun3(25, 36);// 不同函数体的情况// 1、函数体只有一条语句或是表达式的时候，&#123;&#125;可以省略。会自动返回语句执行的结果或是表达式的结果let fun4 = (x, y) =&gt; x + y;console.log(fun4(24, 36));// 2、函数体不止一条语句或表达式的情况下，&#123;&#125;不可以省略let fun5 = (x, y) =&gt; &#123; console.log(x, y); return x + y;&#125;console.log(fun5(35, 50));let obj = &#123; name: '箭头函数', // getName()&#123; getName: () =&gt; &#123; btn2.onclick = () =&gt; &#123; console.log(this); &#125; &#125;&#125;// 等价于 obj.getName = () =&gt; &#123;&#125;，所以this是Window对象obj.getName(); 三点运算符12345678910111213141516171819* 用途1. rest(可变)参数 * 用来取代arguments 但比 arguments 灵活,只能是最后部分形参参数 function fun(...values) &#123; console.log(arguments); arguments.forEach(function (item, index) &#123; console.log(item, index); &#125;); console.log(values); values.forEach(function (item, index) &#123; console.log(item, index); &#125;) &#125; fun(1,2,3);2. 扩展运算符 let arr1 &#x3D; [1,3,5]; let arr2 &#x3D; [2,...arr1,6]; console.log(arr2); console.log(...arr2); 形参默认值12345* 形参的默认值----当不传入参数的时候默认使用形参里的默认值function Point(x &#x3D; 1,y &#x3D; 2) &#123; this.x &#x3D; x; this.y &#x3D; y;&#125; Promise对象123456789101112131415161718192021222324252627282930313233341. 理解: * Promise对象: 代表了未来某个将要发生的事件(通常是一个异步操作) * 有了promise对象, 可以将异步操作以同步的流程表达出来, 避免了层层嵌套的回调函数(俗称&#39;回调地狱&#39;) * ES6的Promise是一个构造函数, 用来生成promise实例2. 使用promise基本步骤(2步): * 创建promise对象 let promise &#x3D; new Promise((resolve, reject) &#x3D;&gt; &#123; &#x2F;&#x2F;初始化promise状态为 pending &#x2F;&#x2F;执行异步操作 if(异步操作成功) &#123; resolve(value);&#x2F;&#x2F;修改promise的状态为fullfilled &#125; else &#123; reject(errMsg);&#x2F;&#x2F;修改promise的状态为rejected &#125; &#125;) * 调用promise的then() promise.then( result &#x3D;&gt; console.log(result), errorMsg &#x3D;&gt; alert(errorMsg) )3. promise对象的3个状态 * pending: 初始化状态 * fullfilled: 成功状态 * rejected: 失败状态4. 应用: * 使用promise实现超时处理 * 使用promise封装处理ajax请求 let request &#x3D; new XMLHttpRequest(); request.onreadystatechange &#x3D; function () &#123; &#125; request.responseType &#x3D; &#39;json&#39;; request.open(&quot;GET&quot;, url); request.send(); 示例代码： 12345678910111213141516171819202122// 创建promise对象let promise = new Promise((resolve, reject) =&gt; &#123; // 初始化promise状态：pending: 初始化 console.log('111'); // 执行异步操作，通常是发送ajax请求、开启定时器 setTimeout(function () &#123; console.log('333'); // 根据异步任务的返回结果去修改promise状态 // 异步任务执行成功 resolve('哈哈');// 修改promise的状态为 fullfilled: 成功的状态 // 异步任务执行失败 // reject('555');// 修改promise的状态为 rejected: 失败的状态 &#125;, 2000);&#125;)console.log('222');promise.then((data) =&gt; &#123;// 成功的回调 console.log(data, '成功了！')&#125;, (error) =&gt; &#123;// 失败的回调 console.log(error, '失败了。。。')&#125;) 应用案例： 123456789101112131415161718192021222324252627282930313233343536373839404142// 定义获取新闻的函数function getNews(url)&#123; let promise = new Promise((resolve, reject) =&gt; &#123; // 状态：初始化 // 执行异步任务 // 创建xmlHttp实例对象 let xmlHttp = new XMLHttpRequest(); // 绑定监听 readyState xmlHttp.onreadystatechange = function()&#123; if(xmlHttp.readyState === 4)&#123; if(xmlHttp.status == 200)&#123;// 请求成功 // 修改状态 resolve(xmlHttp.responseText);// 修改promise的状态为成功的状态 &#125;else&#123;// 请求失败 reject('暂时没有新闻内容'); &#125; &#125; &#125; // open 设置请求的方式以及url xmlHttp.open('GET', url); // 发送 xmlHttp.send(); &#125;) return promise;&#125;getNews('http://localhost:3000/news?id=2').then((data) =&gt; &#123; console.log(data); // 发送请求获取评论内容准备url let commentsUrl = JSON.parse(data).commentsUrl; let url = 'http://localhost:3000' + commentsUrl; // 发送请求 return getNews(url);&#125;, (error) =&gt; &#123; console.log(error);&#125;).then((data) =&gt; &#123; console.log(data);&#125;, (error) =&gt; &#123;&#125;) Symbol123456789101112131415161718192021前言：ES5中对象的属性名都是字符串，容易造成重名，污染环境Symbol： 概念：ES6中的添加了一种原始数据类型symbol(已有的原始数据类型：String, Number, boolean, null, undefined, 对象) 特点： 1、Symbol属性对应的值是唯一的，解决命名冲突问题 2、Symbol值不能与其他数据进行计算，包括同字符串拼串 3、for in, for of遍历时不会遍历symbol属性。 使用： 1、调用Symbol函数得到symbol值 let symbol &#x3D; Symbol(); let obj &#x3D; &#123;&#125;; obj[symbol] &#x3D; &#39;hello&#39;; 2、传参标识 let symbol &#x3D; Symbol(&#39;one&#39;); let symbol2 &#x3D; Symbol(&#39;two&#39;); console.log(symbol);&#x2F;&#x2F; Symbol(&#39;one&#39;) console.log(symbol2);&#x2F;&#x2F; Symbol(&#39;two&#39;) 3、内置Symbol值 * 除了定义自己使用的Symbol值以外，ES6还提供了11个内置的Symbol值，指向语言内部使用的方法。 - Symbol.iterator * 对象的Symbol.iterator属性，指向该对象的默认遍历器方法 示例代码： 1234567891011121314151617181920// 创建Symbol属性值let symbol = Symbol();console.log(symbol);let obj = &#123;username: 'kobe', age: 39&#125;;obj[symbol] = 'hello';console.log(obj);// for in, for of遍历时不会遍历symbol属性for(let i in obj)&#123; console.log(i);&#125;let symbol2 = Symbol('one');let symbol3 = Symbol('two');console.log(symbol2 == symbol3);// falseconsole.log(symbol2, symbol3);// 可以去定义常量const Person_key = Symbol('person_key');console.log(Person_key); Iterator遍历器12345678910111213141516171819概念： iterator是一种接口机制，为各种不同的数据结构提供统一的访问机制作用： 1、为各种数据结构，提供一个统一的、简便的访问接口； 2、使得数据结构的成员能够按某种次序排列 3、ES6创造了一种新的遍历命令for...of循环，Iterator接口主要供for...of消费。工作原理： - 创建一个指针对象(遍历器对象)，指向数据结构的起始位置。 - 第一次调用next方法，指针自动指向数据结构的第一个成员 - 接下来不断调用next方法，指针会一直往后移动，直到指向最后一个成员 - 每调用next方法返回的是一个包含value和done的对象，&#123;value: 当前成员的值,done: 布尔值&#125; * value表示当前成员的值，done对应的布尔值表示当前的数据的结构是否遍历结束。 * 当遍历结束的时候返回的value值是undefined，done值为false原生具备iterator接口的数据(可用for of遍历) 1、Array 2、arguments 3、set容器 4、map容器 5、String 。。。 实现模拟 Iterator 遍历器： 1234567891011121314151617// 模拟指针对象（遍历器对象）function myIterator(arr)&#123;// iterator接口 let nextIndex = 0;// 记录指针的位置 return &#123; next: function()&#123; return nextIndex &lt; arr.length ? &#123;value: arr[nextIndex++], done: false&#125; : &#123;value: undefined, done: true&#125;; &#125; &#125;&#125;// 准备一个数据let arr = [1, 4, 65, 'abc'];let iteratorObj = myIterator(arr);console.log(iteratorObj.next());console.log(iteratorObj.next());console.log(iteratorObj.next());console.log(iteratorObj.next());console.log(iteratorObj.next()); 示例代码： 12345678910111213141516let arr = [1, 4, 65, 'abc'];// 将iterator接口部署到指定的数据类型上，可以使用for of去循环遍历// 数组、字符串、arguments、set容器、map容器for(let i of arr)&#123; console.log(i);&#125;let str = 'abcdefg';for(let i of str)&#123; console.log(i);&#125;function fun()&#123; for(let i of arguments)&#123; console.log(i); &#125;&#125;fun(1,4,5,'abc'); 扩展： 1234567891011121314151617181920212223242526272829303132333435// 对象的Symbol.iterator属性，指向该对象的默认遍历器方法// 等同于在指定的数据内结构上部署了iterator接口，// 当使用for of去遍历某一个数据结构时，首先先去找Symbol.iterator，找到了就去遍历，没有找到的话不能遍历 ==》 xxx is not iterablelet targetData = &#123; 0: 'a', 1: 'b', 2: 'c', length: 3, [Symbol.iterator]: function() &#123; let nextIndex = 0;// 记录指针的位置 return &#123; next: () =&gt; &#123; return nextIndex &lt; this.length ? &#123;value: this[nextIndex++], done: false&#125; : &#123;value: undefined, done: true&#125;; &#125; &#125; &#125;&#125;// 定义了Symbol.iterator之后，Object也可以用for of遍历了for(let i of targetData)&#123; console.log(i);&#125;// 用Symbol.iterator去迭代let numbers = [1,2,3,4,5];let iterator = numbers[Symbol.iterator]();console.log(iterator.next().value);console.log(iterator.next().value);// 使用三点运算符、解构赋值，默认去调用iterator接口let arr2 = [1, 6];let arr3 = [2, 3, 4, 5];arr2 = [1, ...arr3, 6];console.log(arr2);let [a, b] = arr2;console.log(a, b); Generator函数123456789101112131415161718Generator函数 概念： 1、ES6提供的解决异步编程的方案之一 2、Generator函数是一个状态机，内部封装了不同状态的数据， 3、用来生成遍历器对象 4、可暂停函数(惰性求值), yield可暂停，next方法可启动。每次返回的是yield后的表达式结果 特点： 1、function 与函数名之间有一个星号 2、内部用yield表达式来定义不同的状态 例如： function* generatorExample()&#123; let result &#x3D; yield &#39;hello&#39;; &#x2F;&#x2F; 状态值为hello yield &#39;generator&#39;; &#x2F;&#x2F; 状态值为generator &#125; 3、generator函数返回的是指针对象，而不会执行函数内部逻辑 4、调用next方法函数内部逻辑开始执行，遇到yield表达式停止，返回&#123;value: yield后的表达式结果&#x2F;undefined, done: false&#x2F;true&#125; 5、再次调用next方法会从上一次停止时的yield处开始，直到最后 6、yield语句返回结果通常为undefined， 当调用next方法时传参内容会作为启动时yield语句的返回值。 示例代码： 12345678910111213141516171819202122232425function* myGenerator()&#123; console.log('开始执行'); let result = yield 'hello'; console.log(result);// 打印结果==》传入的参数aaa console.log('暂停后，再次执行'); yield 'generator'; console.log('遍历完毕'); return '返回的结果';&#125;let mg = myGenerator();// 返回的是指针对象console.log(mg);console.log(mg.next());// &#123;value: \"hello\", done: false&#125;console.log(mg.next('传入的参数aaa'));// &#123;value: \"generator\", done: false&#125;console.log(mg.next());// &#123;value: \"返回的结果\", done: true&#125;// 对象的symbol.iterator属性 指向遍历器对象let obj = &#123;username: 'kobe', age: 39&#125;;obj[Symbol.iterator] = function* myTest()&#123; yield 1 yield 2 yield 3&#125;for(let i of obj)&#123; console.log(i);&#125; 应用案例： 12345678910111213141516171819202122/* * 需求： * 1、发送ajax请求获取新闻内容 * 2、新闻内容获取成功后再次发送请求，获取对应的新闻评论内容 * 3、新闻内容获取失败则不需要再次发送请求。 * */ function getNews(url)&#123; $.get(url, function (data)&#123; console.log(data); let url = 'http://localhost:3000' + data.commentsUrl; SX.next(url); &#125;) &#125; function* sendXml()&#123; let url = yield getNews('http://localhost:3000/news?id=3'); yield getNews(url); &#125; // 获取遍历器对象 let SX = sendXml(); SX.next(); async函数12345678910111213async函数(源自ES2017)概念： 真正意义上去解决异步回调的问题，同步流程表达异步操作本质： Generator的语法糖语法： async function foo()&#123; await 异步操作; await 异步操作； &#125;特点： 1、不需要像Generator去调用next方法，遇到await等待，当前的异步操作完成就往下执行 2、返回的总是Promise对象，可以用then方法进行下一步操作 3、async取代Generator函数的星号*，await取代Generator的yield 4、语意上更为明确，使用简单，经临床验证，暂时没有任何副作用 示例代码： 12345678910111213// async基本使用function foo()&#123; return new Promise(resolve =&gt; &#123; setTimeout(resolve, 2000); &#125;)&#125;async function test()&#123; console.log('开始执行', new Date().toTimeString()); await foo(); console.log('执行完毕。。。', new Date().toTimeString());&#125;test(); 应用案例： 12345678910111213141516171819// 获取新闻内容async function getNews(url)&#123; return new Promise((resolve, reject) =&gt; &#123; $.ajax(&#123; method: 'GET', url, success: data =&gt; resolve(data), error: error =&gt; reject(error) &#125;) &#125;)&#125;async function sendXml()&#123; let result = await getNews('http://localhost:3000/news?id=3'); console.log(result); result = await getNews('http://localhost:3000' + result.commentsUrl); console.log(result);&#125;sendXml(); class面向对象1234561. 通过class定义类&#x2F;实现类的继承2. 在类中通过constructor定义构造方法3. 通过new来创建类的实例4. 通过extends来实现类的继承5. 通过super调用父类的构造方法6. 重写从父类中继承的一般方法 示例代码： 12345678910111213141516171819202122232425262728293031// 定义一个人物的类class Person&#123; // 类的构造方法 constructor(name, age)&#123; this.name = name; this.age = age; &#125; // 类的一般方法 showName()&#123; console.log(this.name, this.age); &#125;&#125;let person = new Person('kobe', 39);console.log(person);person.showName();// 子类class StarPerson extends Person&#123; constructor(name, age, salary)&#123; super(name, age);// 调用父类的构造方法 this.salary = salary; &#125; // 子类的方法重写 showName()&#123; console.log(this.name, this.age, this.salary); &#125;&#125;let p1 = new StarPerson('wade', 36, 100000000);console.log(p1);p1.showName(); ModuleES6（其他）字符串扩展12341. includes(str) : 判断是否包含指定的字符串2. startsWith(str) : 判断是否以指定字符串开头3. endsWith(str) : 判断是否以指定字符串结尾4. repeat(count) : 重复指定次数 示例代码： 123456let str = 'abc';console.log(str.includes('t'));console.log(str.includes('a'));console.log(str.startsWith('a'));console.log(str.endsWith('f'));console.log(str.repeat(3));// abcabcabc 数值扩展1234561. 二进制与八进制数值表示法: 二进制用0b, 八进制用0o2. Number.isFinite(i) : 判断是否是有限大的数3. Number.isNaN(i) : 判断是否是NaN4. Number.isInteger(i) : 判断是否是整数5. Number.parseInt(str) : 将字符串转换为对应的数值6. Math.trunc(i) : 直接去除小数部分 示例代码： 123456789console.log(0b1010);// 10console.log(0o56);// 46console.log(Number.isFinite(Infinity));// falseconsole.log(Number.isNaN(NaN));// trueconsole.log(Number.isInteger(123.12));// falseconsole.log(Number.isInteger(123.0));// trueconsole.log(Number.parseInt('123abc222'));// 123console.log(Number.parseInt('abc222'));// NaNconsole.log(Math.trunc(123.12));// 123 数组扩展12341. Array.from(v) : 将伪数组对象或可遍历对象转换为真数组2. Array.of(v1, v2, v3) : 将一系列值转换成数组3. find(function(value, index, arr)&#123;return true&#125;) : 找出第一个满足条件返回true的元素4. findIndex(function(value, index, arr)&#123;return true&#125;) : 找出第一个满足条件返回true的元素下标 示例代码： 123456789101112131415161718let btns = document.getElementsByTagName('button');console.log(btns);Array.from(btns).forEach(function(item, index)&#123; console.log(item);&#125;)let arr = Array.of(1,3,'abc',true);console.log(arr);let arr2 = [2,3,4,2,5,7,3,6,5];let result = arr2.find(function(item, index)&#123; return item &gt; 4;&#125;)console.log(result);result = arr2.findIndex(function(item, index)&#123; return item &gt; 4;&#125;)console.log(result); Object扩展12345671. Object.is(v1, v2) * 判断2个数据是否完全相等（其实是用字符串比较）2. Object.assign(target, source1, source2..) * 将源对象的属性复制到目标对象上3. 直接操作 __proto__ 属性 let obj2 &#x3D; &#123;&#125;; obj2.__proto__ &#x3D; obj1; 示例代码： 12345678910111213141516console.log(0 == -0);// trueconsole.log(NaN == NaN);// falseconsole.log(Object.is(0, -0));// falseconsole.log(Object.is(NaN, NaN));// truelet obj = &#123;&#125;;let obj1 = &#123;username: 'iverson', age:42&#125;;let obj2 = &#123;sex: '男'&#125;;Object.assign(obj, obj1, obj2);console.log(obj);let obj3 = &#123;&#125;;let obj4 = &#123;qian: 5000000&#125;;obj3.__proto__ = obj4;console.log(obj3);console.log(obj3.qian); 深度克隆123456789101112131415161718192021221、数据类型： * 数据分为基本的数据类型(String, Number, boolean, Null, Undefined)和对象数据类型 - 基本数据类型： 特点： 存储的是该对象的实际数据 - 对象数据类型： 特点： 存储的是该对象在栈中引用，真实的数据存放在堆内存里2、复制数据 - 基本数据类型存放的就是实际的数据，可直接复制 let number2 &#x3D; 2; let number1 &#x3D; number2; - 克隆数据：对象&#x2F;数组 1、区别： 浅拷贝&#x2F;深度拷贝 判断： 拷贝是否产生了新的数据还是拷贝的是数据的引用 知识点：对象数据存放的是对象在栈内存的引用，直接复制的是对象的引用 let obj &#x3D; &#123;username: &#39;kobe&#39;&#125; let obj1 &#x3D; obj; &#x2F;&#x2F; obj1 复制了obj在栈内存的引用 2、常用的拷贝技术 1). arr.concat(): 数组浅拷贝 2). arr.slice(): 数组浅拷贝 3). JSON.parse(JSON.stringify(arr&#x2F;obj)): 数组或对象深拷贝, 但不能处理函数数据 4). 浅拷贝包含函数数据的对象&#x2F;数组 5). 深拷贝包含函数数据的对象&#x2F;数组 示例代码： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960// 不会影响原数据let str = 'abcd';let str2 = str;console.log(str2);str2 = '';console.log(str);let bool1 = true;let bool2 = bool1;bool2 = false;console.log(bool1);// 拷贝数组/对象，没有生成新的数据而是复制了一份引用let obj = &#123;username: 'kobe', age: 39&#125;;let obj2 = obj;console.log(obj2);obj2.username = 'wade';console.log(obj.username);let arr = [1, 4, &#123;username: 'kobe', age: 39&#125;];let arr2 = arr;arr2[0] = 'abcd';console.log(arr, arr2);/** * 拷贝数据： * 基本数据类型： * 拷贝后会生成一份新的数据，修改拷贝以后的数据不会影响原数据 * 对象/数组： * 拷贝后不会生成新的数据，而是拷贝的引用。修改拷贝以后的数据会影响原来的数据 * * 拷贝数据的方法： * 1.直接赋值给一个变量 // 浅拷贝 * 2.Object.assign() // 浅拷贝 * 3.Array.prototype.concat() // 浅拷贝 * 4.Array.prototype.slice() // 浅拷贝 * 5.JSON.parse(JSON.stringify()) // 深拷贝（深度克隆），但不能处理函数数据 * * 浅拷贝（对象/数组） * 特点：拷贝的引用，修改拷贝以后的数据会影响原数据，使得原数据不安全 * 深拷贝（深度克隆） * 特点：拷贝的时候生成新数据，修改拷贝以后的数据不会影响原数据 */&#123;let obj = &#123;username: 'kobe'&#125;;let obj2 = Object.assign(obj);console.log(obj2);obj.username = 'wade';console.log(obj2);let arr = [1, 3, &#123;username: 'kobe'&#125;, function fun()&#123;&#125;];let arr2 = arr.concat();arr2[0] = 2;// 这个修改不影响arr的第一个元素，因为是复制的基本类型arr2[2].username = 'wade';// 这个修改会影响原数据，因为复制是对象的引用console.log(arr);let arr3 = arr.slice();arr3[2].username = 'iverson';// 会影响console.log(arr);let arr4 = JSON.parse(JSON.stringify(arr));console.log(arr4);arr4[2].username = 'duncan';// 不影响console.log(arr, arr4); 实现深度克隆前的知识储备： 12345678910111213141516171819202122/** * 思考：如何实现深度拷贝（克隆） * 即使有对象/数组，也可以继续遍历对象/数组拿到里边每一项值，直到拿到的是基本数据类型，然后再去复制，就是深度拷贝 * * 如何判断数据类型：arr --&gt; Array null --&gt; Null * 1.typeof返回的数据类型：String, Number, Boolean, Undefined, Object, Function * 2.Object.prototype.toString.call(this) */let result= 'abcd';result = null;result = [1, 3];console.log(Object.prototype.toString.call(result).slice(8, -1));// for in循环，对象（属性名） 数组（下标）let obj6 = &#123;username: 'kobe', age: 39&#125;;for (let i in obj6)&#123; console.log(i);&#125;let arr6 = [1, 3, 'abc'];for (let i in arr6)&#123; console.log(i);&#125; 实现深度克隆： 123456789101112131415161718192021222324252627282930313233343536373839404142// 定义检测数据类型的功能函数function checkType(target)&#123; return Object.prototype.toString.call(target).slice(8, -1);&#125;// 实现深度克隆 --&gt; 对象/数组function clone(target)&#123; // 判断拷贝的数据类型 // 初始化变量result成为最终克隆的数据 let result, targetType = checkType(target); if(targetType === 'Object')&#123; result = &#123;&#125;; &#125;else if(targetType === 'Array')&#123; result = []; &#125;else&#123; return target; &#125; // 遍历目标数据 for(let i in target)&#123; // 获取遍历数据结构的每一项值 let value = target[i]; // 判断目标结构里的每一项值是否存在对象/数组 if(checkType(value) === 'Object' || checkType(value) === 'Array')&#123;// 对象/数组里嵌套了对象/数组 // 继续遍历获取到的value值 result[i] = clone(value); &#125;else&#123;// 获取到的value值是基本的数据类型或函数 result[i] = value; &#125; &#125; return result;&#125;let arr7 = [1, 2, &#123;username: 'kobe', age:39&#125;];let arr8 = clone(arr7);console.log(arr8);arr8[2].username = 'wade';console.log(arr7, arr8);let obj7 = &#123;username: 'kobe', age: 39&#125;;let obj8 = clone(obj7);console.log(obj8);obj8.username = 'wade';console.log(obj7, obj8); Set和Map12345678910111213141516171. Set容器 : 无序不可重复的多个value的集合体 * Set() * Set(array) * add(value) * delete(value) * has(value) * clear() * size2. Map容器 : 无序的 key不重复的多个key-value的集合体 * Map() * Map(array) * set(key, value)&#x2F;&#x2F;添加 * get(key) * delete(key) * has(key) * clear() * size 示例代码： 123456789101112131415161718let set = new Set([1,2,4,5,2,3,6]);console.log(set);set.add(7);console.log(set.size, set);console.log(set.has(8));// falseconsole.log(set.has(7));// trueset.delete(4);console.log(set);set.clear();console.log(set);let map = new Map([['username', 'kobe'], [36, 'age']]);console.log(map);map.set(78, 'haha');console.log(map);map.delete(36);console.log(map);console.log(map.size); for of循环123456for(let value of target)&#123;&#125;循环遍历 1. 遍历数组 2. 遍历Set 3. 遍历Map 4. 遍历字符串 5. 遍历伪数组 示例代码： 123456789101112131415// 数组去重let arr = [1,2,4,5,5,6,2];let arr1 = arr;arr = [];let set = new Set(arr1);for (let i of set)&#123; arr.push(i);&#125;console.log(arr);// 遍历伪数组let btns = document.getElementsByTagName('button');for(let i of btns)&#123; console.log(i);&#125; ES7121. 指数运算符(幂): **2. Array.prototype.includes(value) : 判断数组中是否包含指定value 示例代码： 123console.log(3 ** 3);// 27let arr = [1,4,5,6,'abc'];console.log(arr.includes(6));// true","tags":[{"name":"前端","slug":"前端","permalink":"https://sunshine-zwq.gitee.io/tags/%E5%89%8D%E7%AB%AF/"},{"name":"ECMAScript","slug":"ECMAScript","permalink":"https://sunshine-zwq.gitee.io/tags/ECMAScript/"}]}]